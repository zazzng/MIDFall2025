import os
import json
import subprocess
import threading
import time
import random
import numpy as np
from openai import OpenAI
from dotenv import load_dotenv
import cv2
import cv2.aruco as aruco
from PIL import Image, ImageDraw, ImageFont

# ============================================
# 0. ê³µí†µ ì„¤ì •
# ============================================
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

TTS_MODEL = "gpt-4o-mini-tts"   # ìŒì„± ìƒì„± ëª¨ë¸
TEXT_MODEL = "gpt-4o-mini"      # ëŒ€ì‚¬ ìƒì„± ëª¨ë¸

ALLOWED_VOICES = {
    "alloy", "echo", "fable", "onyx", "nova", "shimmer",
    "coral", "verse", "ballad", "ash", "sage", "marin", "cedar"
}

# í˜„ì¬ ìƒíƒœ (ë°°ê²½ / ìºë¦­í„°)
CURRENT_BG_BOOK_CODE = None      # í˜„ì¬ ë°°ê²½ì´ ëœ ì±… ì½”ë“œ
CURRENT_BG_INFO = None           # í˜„ì¬ ë°°ê²½ ì •ë³´
CURRENT_CHA1_INFO = None         # í˜„ì¬ cha1 ìºë¦­í„° dict
CURRENT_CHA2_INFO = None         # í˜„ì¬ cha2 ìºë¦­í„° dict

# í˜„ì¬ ì¬ìƒ ì¤‘ì¸ ì˜¤ë””ì˜¤ í”„ë¡œì„¸ìŠ¤ ì¶”ì 
_current_audio_processes = []  # í˜„ì¬ ì¬ìƒ ì¤‘ì¸ ëª¨ë“  ì˜¤ë””ì˜¤ í”„ë¡œì„¸ìŠ¤
_audio_processes_lock = threading.Lock()  # ì˜¤ë””ì˜¤ í”„ë¡œì„¸ìŠ¤ ë¦¬ìŠ¤íŠ¸ ë³´í˜¸ìš© ë½
_should_stop_audio = False  # ì˜¤ë””ì˜¤ ì¬ìƒ ì¤‘ë‹¨ í”Œë˜ê·¸
_stop_audio_lock = threading.Lock()  # ì¤‘ë‹¨ í”Œë˜ê·¸ ë³´í˜¸ìš© ë½

# ë¹„ë””ì˜¤ í”Œë ˆì´ì–´ (ìŠ¤ë ˆë“œ ê¸°ë°˜)
class VideoPlayer:
    """OpenCV ê¸°ë°˜ ë¹„ë””ì˜¤ í”Œë ˆì´ì–´ (ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ë¬´í•œ ë£¨í”„ ì¬ìƒ)"""
    
    def __init__(self):
        self.current_video_path = None
        self.video_cap = None
        self.next_video_path = None
        self.frame = None
        self.lock = threading.Lock()
        self.running = False
        self.thread = None
        self.fade_alpha = 1.0  # í˜ì´ë“œ ì•ŒíŒŒ ê°’ (0.0 ~ 1.0)
        self.is_fading = False  # í˜ì´ë“œ ì¤‘ì¸ì§€ ì—¬ë¶€
        self.fade_duration = 0.5  # í˜ì´ë“œ ì§€ì† ì‹œê°„ (ì´ˆ)
        self.fade_start_time = None
        self.overlay_video_cap = None  # ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ch1 (ìºë¦­í„° ì›€ì§ì„)
        self.overlay_video_path = None  # ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ch1 ê²½ë¡œ
        self.overlay_video_cap2 = None  # ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ch2 (ìºë¦­í„° ì›€ì§ì„)
        self.overlay_video_path2 = None  # ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ch2 ê²½ë¡œ
        self.bg_fps = 30.0  # ë°°ê²½ ë¹„ë””ì˜¤ FPS (ê¸°ë³¸ê°’)
        self.overlay_fps = 30.0  # ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ch1 FPS (ê¸°ë³¸ê°’)
        self.overlay_fps2 = 30.0  # ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ch2 FPS (ê¸°ë³¸ê°’)
        self.last_frame_time = None  # ë§ˆì§€ë§‰ í”„ë ˆì„ í‘œì‹œ ì‹œê°„
        self.frame_accumulator = 0.0  # í”„ë ˆì„ ëˆ„ì  ì‹œê°„ (ë“œë¡­ ë³´ìƒìš©)
        self.current_subtitle_text = None  # í˜„ì¬ ìë§‰ í…ìŠ¤íŠ¸ (ì˜ˆ: "toad: Haha")
        self.current_subtitle_lock = threading.Lock()  # ìë§‰ ì •ë³´ ë³´í˜¸ìš© ë½
        
        # í°íŠ¸ ìºì‹œ (ì„±ëŠ¥ ìµœì í™”)
        self._subtitle_cache = {}  # (text, width, font_scale) -> lines
        self._last_frame_size = None  # ë§ˆì§€ë§‰ í”„ë ˆì„ í¬ê¸° (í°íŠ¸ ì¬ê³„ì‚° ë°©ì§€)
    
    def _play_loop(self):
        """ë¹„ë””ì˜¤ ì¬ìƒ ë£¨í”„ (ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰)"""
        import time as time_module
        while self.running:
            loop_start_time = time_module.perf_counter()
            
            # ë¹„ë””ì˜¤ ì „í™˜ ì²˜ë¦¬ (í˜ì´ë“œì™€ ë…ë¦½ì ìœ¼ë¡œ, ì¦‰ì‹œ ì²˜ë¦¬)
            next_path = None
            old_cap_to_release = None
            with self.lock:
                if self.next_video_path == "":
                    # í˜ì´ë“œ ì•„ì›ƒ ìš”ì²­
                    elapsed = time_module.time() - self.fade_start_time if self.fade_start_time else 0
                    if elapsed >= self.fade_duration:
                        # í˜ì´ë“œ ì•„ì›ƒ ì™„ë£Œ: ë¹„ë””ì˜¤ í•´ì œ
                        if self.video_cap:
                            old_cap_to_release = self.video_cap
                            self.video_cap = None
                            self.current_video_path = None
                        self.next_video_path = None
                        self.is_fading = False
                        self.fade_alpha = 1.0
                        self.fade_start_time = None
                elif self.next_video_path is not None:
                    # ë¹„ë””ì˜¤ ì „í™˜ ìš”ì²­
                    next_path = self.next_video_path
                    self.next_video_path = None  # ì¦‰ì‹œ í´ë¦¬ì–´í•˜ì—¬ ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€
            
            # lock ë°–ì—ì„œ ë¹„ë””ì˜¤ í•´ì œ (í˜ì´ë“œ ì•„ì›ƒ)
            if old_cap_to_release is not None:
                try:
                    if old_cap_to_release.isOpened():
                        old_cap_to_release.release()
                except:
                    pass
            
            if next_path is not None:
                # ë¹„ë””ì˜¤ ì „í™˜ ì¦‰ì‹œ ì²˜ë¦¬
                old_cap = None
                with self.lock:
                    old_cap = self.video_cap
                    self.video_cap = None  # ë¨¼ì € Noneìœ¼ë¡œ ì„¤ì •í•˜ì—¬ _play_loopê°€ ê²€ì€ í”„ë ˆì„ í‘œì‹œ
                
                # lock ë°–ì—ì„œ ê¸°ì¡´ ë¹„ë””ì˜¤ í•´ì œ
                if old_cap is not None:
                    try:
                        if old_cap.isOpened():
                            old_cap.release()
                    except:
                        pass
                
                # ìƒˆ ë¹„ë””ì˜¤ ì—´ê¸° (lock ë°–ì—ì„œ, ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŒ)
                new_cap = cv2.VideoCapture(next_path)
                if new_cap.isOpened():
                    new_cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
                    fps = new_cap.get(cv2.CAP_PROP_FPS)
                    # ë¹„ë””ì˜¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì—´ë¦° í›„ì—ë§Œ ê²½ë¡œì™€ ìº¡ì²˜ ê°ì²´ ì„¤ì •
                    with self.lock:
                        self.current_video_path = next_path
                        self.bg_fps = fps if fps > 0 else 30.0
                        self.video_cap = new_cap
                    print(f"ğŸ¬ ë¹„ë””ì˜¤ ì „í™˜ ì™„ë£Œ: {os.path.basename(next_path)} (FPS: {self.bg_fps:.2f})")
                else:
                    print(f"âŒ ë¹„ë””ì˜¤ë¥¼ ì—´ ìˆ˜ ì—†ìŒ: {next_path}")
                    with self.lock:
                        self.video_cap = None
                        self.current_video_path = None
                        self.bg_fps = 30.0
            
            # í˜ì´ë“œ íš¨ê³¼ ê³„ì‚° (ì‹œê° íš¨ê³¼ë§Œ)
            fade_alpha = 1.0
            if self.is_fading and self.fade_start_time:
                elapsed = time_module.time() - self.fade_start_time
                if elapsed < self.fade_duration:
                    # í˜ì´ë“œ ì•„ì›ƒ: 1.0 -> 0.0
                    fade_alpha = 1.0 - (elapsed / self.fade_duration)
                elif elapsed < self.fade_duration * 2:
                    # í˜ì´ë“œ ì¸: 0.0 -> 1.0
                    fade_alpha = (elapsed - self.fade_duration) / self.fade_duration
                else:
                    # í˜ì´ë“œ ì™„ë£Œ
                    with self.lock:
                        self.is_fading = False
                        self.fade_alpha = 1.0
                        self.fade_start_time = None
            
            # í”„ë ˆì„ ì½ê¸° ë° ì²˜ë¦¬ (lock ìµœì†Œí™”)
            frame = None
            with self.lock:
                # ë¹„ë””ì˜¤ ìº¡ì²˜ ê°ì²´ ì°¸ì¡°ë§Œ ê°€ì ¸ì˜¤ê¸° (lock ì•ˆì—ì„œ ìµœì†Œí•œë§Œ)
                # ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ëŠ” ì§ì ‘ ì°¸ì¡°í•˜ì§€ ì•Šê³ , ë§¤ë²ˆ lock ì•ˆì—ì„œ í™•ì¸
                video_cap = self.video_cap
                self.fade_alpha = fade_alpha
            
            # ë¹„ë””ì˜¤ê°€ ì—†ìœ¼ë©´ ê²€ì€ í”„ë ˆì„ ìƒì„±
            if video_cap is None:
                # ê²€ì€ í”„ë ˆì„ ìƒì„± (ê¸°ë³¸ í•´ìƒë„ 1280x720)
                frame = np.zeros((720, 1280, 3), dtype=np.uint8)
                # í˜ì´ë“œ íš¨ê³¼ ì ìš© (í˜ì´ë“œ ì•„ì›ƒ ì¤‘ì´ë©´ ê²€ì€ í™”ë©´ ìœ ì§€)
                if self.is_fading and fade_alpha < 1.0:
                    # í˜ì´ë“œ ì•„ì›ƒ ì¤‘ì´ë©´ ê²€ì€ í™”ë©´
                    pass  # ì´ë¯¸ ê²€ì€ í”„ë ˆì„ì´ë¯€ë¡œ ì¶”ê°€ ì²˜ë¦¬ ë¶ˆí•„ìš”
                # ê²€ì€ í”„ë ˆì„ì€ ì˜¤ë²„ë ˆì´ ì—†ì´ ë°”ë¡œ ì €ì¥
                with self.lock:
                    self.frame = frame
                # ê¸°ë³¸ í”„ë ˆì„ ê°„ê²© ì„¤ì • (30 FPS)
                frame_interval = 1.0 / 30.0
                # í”„ë ˆì„ ì²˜ë¦¬ ì‹œê°„ ê³ ë ¤í•˜ì—¬ ì •í™•í•œ íƒ€ì´ë°ìœ¼ë¡œ ì¬ìƒ
                elapsed = time_module.perf_counter() - loop_start_time
                sleep_time = max(0, frame_interval - elapsed)
                if sleep_time > 0:
                    if sleep_time < 0.001:
                        time_module.sleep(0)
                    else:
                        time_module.sleep(sleep_time)
                continue  # ë‹¤ìŒ ë£¨í”„ë¡œ
            
            # video_capì´ ìˆì§€ë§Œ ì—´ë ¤ìˆì§€ ì•Šì€ ê²½ìš°ë„ ì²´í¬
            try:
                is_opened = video_cap.isOpened()
            except:
                is_opened = False
            
            if not is_opened:
                # ê²€ì€ í”„ë ˆì„ ìƒì„± (ê¸°ë³¸ í•´ìƒë„ 1280x720)
                frame = np.zeros((720, 1280, 3), dtype=np.uint8)
                # í˜ì´ë“œ íš¨ê³¼ ì ìš© (í˜ì´ë“œ ì•„ì›ƒ ì¤‘ì´ë©´ ê²€ì€ í™”ë©´ ìœ ì§€)
                if self.is_fading and fade_alpha < 1.0:
                    # í˜ì´ë“œ ì•„ì›ƒ ì¤‘ì´ë©´ ê²€ì€ í™”ë©´
                    pass  # ì´ë¯¸ ê²€ì€ í”„ë ˆì„ì´ë¯€ë¡œ ì¶”ê°€ ì²˜ë¦¬ ë¶ˆí•„ìš”
                # ê²€ì€ í”„ë ˆì„ì€ ì˜¤ë²„ë ˆì´ ì—†ì´ ë°”ë¡œ ì €ì¥
                with self.lock:
                    self.frame = frame
                # ê¸°ë³¸ í”„ë ˆì„ ê°„ê²© ì„¤ì • (30 FPS)
                frame_interval = 1.0 / 30.0
                # í”„ë ˆì„ ì²˜ë¦¬ ì‹œê°„ ê³ ë ¤í•˜ì—¬ ì •í™•í•œ íƒ€ì´ë°ìœ¼ë¡œ ì¬ìƒ
                elapsed = time_module.perf_counter() - loop_start_time
                sleep_time = max(0, frame_interval - elapsed)
                if sleep_time > 0:
                    if sleep_time < 0.001:
                        time_module.sleep(0)
                    else:
                        time_module.sleep(sleep_time)
                continue  # ë‹¤ìŒ ë£¨í”„ë¡œ
            else:
                # ì‹¤ì œ ë¹„ë””ì˜¤ FPSì— ë§ì¶° í”„ë ˆì„ ê°„ê²© ì¡°ì • (ë¨¼ì € ê³„ì‚°)
                with self.lock:
                    overlay_cap = self.overlay_video_cap
                    overlay_cap2 = self.overlay_video_cap2
                
                # ì˜¤ë²„ë ˆì´ê°€ ì—†ì„ ë•ŒëŠ” ë°°ê²½ ë¹„ë””ì˜¤ FPSë§Œ ì‚¬ìš©
                if overlay_cap is None and overlay_cap2 is None:
                    # ì˜¤ë²„ë ˆì´ê°€ ì—†ìœ¼ë©´ ë°°ê²½ ë¹„ë””ì˜¤ì˜ ì‹¤ì œ FPS ì‚¬ìš©
                    target_fps = self.bg_fps if self.bg_fps > 0 else 30.0
                else:
                    # ì˜¤ë²„ë ˆì´ê°€ ìˆìœ¼ë©´ ê°€ì¥ ë†’ì€ FPS ì‚¬ìš© (ë™ê¸°í™”ë¥¼ ìœ„í•´)
                    target_fps = max(self.bg_fps, 
                                   self.overlay_fps if overlay_cap and overlay_cap.isOpened() else 0,
                                   self.overlay_fps2 if overlay_cap2 and overlay_cap2.isOpened() else 0)
                    if target_fps <= 0:
                        target_fps = self.bg_fps if self.bg_fps > 0 else 30.0  # ê¸°ë³¸ê°’ì€ ë°°ê²½ ë¹„ë””ì˜¤ FPS
                
                frame_interval = 1.0 / target_fps
                
                # lock ë°–ì—ì„œ í”„ë ˆì„ ì½ê¸° (ë¹„ë””ì˜¤ I/OëŠ” ëŠë¦´ ìˆ˜ ìˆìŒ)
                ret, frame = video_cap.read()
                if not ret:
                    # ë¹„ë””ì˜¤ ëë‚˜ë©´ ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°€ê¸° (ë¬´í•œ ë£¨í”„)
                    with self.lock:
                        if self.video_cap:
                            self.video_cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                    ret, frame = video_cap.read()
                
                if ret:
                    # í˜ì´ë“œ íš¨ê³¼ ì ìš©
                    if self.is_fading and fade_alpha < 1.0:
                        black_frame = frame.copy()
                        black_frame.fill(0)
                        frame = cv2.addWeighted(frame, fade_alpha, black_frame, 1.0 - fade_alpha, 0)
                    
                    # í˜ì´ë“œ ì¤‘ì¼ ë•ŒëŠ” ì˜¤ë²„ë ˆì´ë¥¼ í‘œì‹œí•˜ì§€ ì•ŠìŒ (ê¹Œë§Œ í™”ë©´ì— ìºë¦­í„°ê°€ ë³´ì´ì§€ ì•Šë„ë¡)
                    if not (self.is_fading and fade_alpha < 1.0):
                        # ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ì²˜ë¦¬ ìˆœì„œ: ch2 ë¨¼ì € (ë’¤ ë ˆì´ì–´), ch1 ë‚˜ì¤‘ (ì• ë ˆì´ì–´)
                        # ch2 ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ì²˜ë¦¬ (ë’¤ ë ˆì´ì–´) - ë§¤ë²ˆ lockì—ì„œ ìµœì‹  ì°¸ì¡° ê°€ì ¸ì˜¤ê¸°
                        overlay_cap2 = None
                        overlay_ret2 = False
                        overlay_frame2 = None
                        
                        with self.lock:
                            if self.overlay_video_cap2 is not None:
                                try:
                                    # ì°¸ì¡°ë¥¼ ê°€ì ¸ì˜¤ê³  ì¦‰ì‹œ ìœ íš¨ì„± í™•ì¸ (ì•ˆì „í•˜ê²Œ)
                                    cap2_ref = self.overlay_video_cap2
                                    if cap2_ref is not None:
                                        try:
                                            if cap2_ref.isOpened():
                                                overlay_cap2 = cap2_ref
                                            else:
                                                self.overlay_video_cap2 = None
                                        except:
                                            # isOpened() í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ (ë¹„ë””ì˜¤ê°€ í•´ì œë˜ëŠ” ì¤‘ì¼ ìˆ˜ ìˆìŒ)
                                            self.overlay_video_cap2 = None
                                except:
                                    self.overlay_video_cap2 = None
                        
                        if overlay_cap2 is not None:
                            try:
                                # ë¹„ë””ì˜¤ ìº¡ì²˜ê°€ ì—¬ì „íˆ ìœ íš¨í•œì§€ í™•ì¸
                                try:
                                    if not overlay_cap2.isOpened():
                                        overlay_ret2 = False
                                        overlay_frame2 = None
                                        with self.lock:
                                            if self.overlay_video_cap2 == overlay_cap2:
                                                self.overlay_video_cap2 = None
                                    else:
                                        overlay_ret2, overlay_frame2 = overlay_cap2.read()
                                        if not overlay_ret2:
                                            try:
                                                overlay_cap2.set(cv2.CAP_PROP_POS_FRAMES, 0)
                                                overlay_ret2, overlay_frame2 = overlay_cap2.read()
                                            except:
                                                overlay_ret2 = False
                                                overlay_frame2 = None
                                except:
                                    # isOpened() ë˜ëŠ” read() ì¤‘ ì˜¤ë¥˜ (ë¹„ë””ì˜¤ê°€ í•´ì œë˜ëŠ” ì¤‘ì¼ ìˆ˜ ìˆìŒ)
                                    overlay_ret2 = False
                                    overlay_frame2 = None
                                    with self.lock:
                                        if self.overlay_video_cap2 == overlay_cap2:
                                            self.overlay_video_cap2 = None
                            except Exception as e:
                                # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
                                overlay_ret2 = False
                                overlay_frame2 = None
                                with self.lock:
                                    if self.overlay_video_cap2 == overlay_cap2:
                                        self.overlay_video_cap2 = None
                            
                            if overlay_ret2 and overlay_cap2 is not None and overlay_frame2 is not None:
                                try:
                                    # ì˜¤ë²„ë ˆì´ í”„ë ˆì„ í¬ê¸°ë¥¼ ë°°ê²½ í”„ë ˆì„ í¬ê¸°ì— ë§ì¶¤
                                    if overlay_frame2.shape[:2] != frame.shape[:2]:
                                        overlay_frame2 = cv2.resize(overlay_frame2, (frame.shape[1], frame.shape[0]), interpolation=cv2.INTER_LINEAR)
                                    
                                    # ì•ŒíŒŒ ì±„ë„ì´ ìˆìœ¼ë©´ ì•ŒíŒŒ ë¸”ë Œë”©, ì—†ìœ¼ë©´ ì¼ë°˜ ì˜¤ë²„ë ˆì´
                                    if len(overlay_frame2.shape) == 3 and overlay_frame2.shape[2] == 4:
                                        # RGBA -> BGR ë³€í™˜
                                        overlay_bgr2 = overlay_frame2[:, :, :3]
                                        # ì•ŒíŒŒ ë§ˆìŠ¤í¬ ì¶”ì¶œ (uint8)
                                        alpha2 = overlay_frame2[:, :, 3]
                                        # ì•ŒíŒŒê°€ 0ì´ ì•„ë‹Œ ì˜ì—­ë§Œ ë¸”ë Œë”© (ì„±ëŠ¥ ìµœì í™”)
                                        mask2_alpha = alpha2 > 0
                                        if np.any(mask2_alpha):
                                            # ì•ŒíŒŒë¥¼ floatë¡œ ë³€í™˜ (0-1 ë²”ìœ„)
                                            alpha2_f = alpha2.astype(np.float32) / 255.0
                                            alpha_3d2 = alpha2_f[:, :, None]  # np.newaxis ëŒ€ì‹  None ì‚¬ìš©
                                            # ì•ŒíŒŒ ë¸”ë Œë”© (ë²¡í„°í™”ëœ ì—°ì‚°)
                                            frame = (frame.astype(np.float32) * (1 - alpha_3d2) + overlay_bgr2.astype(np.float32) * alpha_3d2).astype(np.uint8)
                                    elif len(overlay_frame2.shape) == 3:
                                        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë§ˆìŠ¤í¬ ìƒì„± ë° ë¸”ë Œë”©
                                        mask2 = cv2.cvtColor(overlay_frame2, cv2.COLOR_BGR2GRAY)
                                        _, mask2 = cv2.threshold(mask2, 1, 255, cv2.THRESH_BINARY)
                                        # ë§ˆìŠ¤í¬ê°€ ìˆëŠ” ì˜ì—­ë§Œ ì˜¤ë²„ë ˆì´ ë³µì‚¬ (ë” ë¹ ë¦„)
                                        cv2.copyTo(overlay_frame2, mask2, frame)
                                except Exception as e:
                                    print(f"âš ï¸ ch2 ì˜¤ë²„ë ˆì´ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                        
                        # ch1 ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ì²˜ë¦¬ (ì• ë ˆì´ì–´ - ë§ˆì§€ë§‰ì— ì ìš©í•˜ì—¬ í•­ìƒ ì•ì— í‘œì‹œ)
                        # ë§¤ë²ˆ lockì—ì„œ ìµœì‹  ì°¸ì¡° ê°€ì ¸ì˜¤ê¸°
                        overlay_cap = None
                        overlay_ret = False
                        overlay_frame = None
                        
                        with self.lock:
                            if self.overlay_video_cap is not None:
                                try:
                                    # ì°¸ì¡°ë¥¼ ê°€ì ¸ì˜¤ê³  ì¦‰ì‹œ ìœ íš¨ì„± í™•ì¸ (ì•ˆì „í•˜ê²Œ)
                                    cap_ref = self.overlay_video_cap
                                    if cap_ref is not None:
                                        try:
                                            if cap_ref.isOpened():
                                                overlay_cap = cap_ref
                                            else:
                                                self.overlay_video_cap = None
                                        except:
                                            # isOpened() í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ (ë¹„ë””ì˜¤ê°€ í•´ì œë˜ëŠ” ì¤‘ì¼ ìˆ˜ ìˆìŒ)
                                            self.overlay_video_cap = None
                                except:
                                    self.overlay_video_cap = None
                        
                        if overlay_cap is not None:
                            try:
                                # ë¹„ë””ì˜¤ ìº¡ì²˜ê°€ ì—¬ì „íˆ ìœ íš¨í•œì§€ í™•ì¸
                                try:
                                    if not overlay_cap.isOpened():
                                        overlay_ret = False
                                        overlay_frame = None
                                        with self.lock:
                                            if self.overlay_video_cap == overlay_cap:
                                                self.overlay_video_cap = None
                                    else:
                                        overlay_ret, overlay_frame = overlay_cap.read()
                                        if not overlay_ret:
                                            try:
                                                overlay_cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                                                overlay_ret, overlay_frame = overlay_cap.read()
                                            except:
                                                overlay_ret = False
                                                overlay_frame = None
                                except:
                                    # isOpened() ë˜ëŠ” read() ì¤‘ ì˜¤ë¥˜ (ë¹„ë””ì˜¤ê°€ í•´ì œë˜ëŠ” ì¤‘ì¼ ìˆ˜ ìˆìŒ)
                                    overlay_ret = False
                                    overlay_frame = None
                                    with self.lock:
                                        if self.overlay_video_cap == overlay_cap:
                                            self.overlay_video_cap = None
                            except Exception as e:
                                # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
                                overlay_ret = False
                                overlay_frame = None
                                with self.lock:
                                    if self.overlay_video_cap == overlay_cap:
                                        self.overlay_video_cap = None
                            
                            if overlay_ret and overlay_cap is not None and overlay_frame is not None:
                                try:
                                    # ì˜¤ë²„ë ˆì´ í”„ë ˆì„ í¬ê¸°ë¥¼ ë°°ê²½ í”„ë ˆì„ í¬ê¸°ì— ë§ì¶¤
                                    if overlay_frame.shape[:2] != frame.shape[:2]:
                                        overlay_frame = cv2.resize(overlay_frame, (frame.shape[1], frame.shape[0]), interpolation=cv2.INTER_LINEAR)
                                    
                                    # ì•ŒíŒŒ ì±„ë„ì´ ìˆìœ¼ë©´ ì•ŒíŒŒ ë¸”ë Œë”©, ì—†ìœ¼ë©´ ì¼ë°˜ ì˜¤ë²„ë ˆì´
                                    if len(overlay_frame.shape) == 3 and overlay_frame.shape[2] == 4:
                                        # RGBA -> BGR ë³€í™˜
                                        overlay_bgr = overlay_frame[:, :, :3]
                                        # ì•ŒíŒŒ ë§ˆìŠ¤í¬ ì¶”ì¶œ (uint8)
                                        alpha = overlay_frame[:, :, 3]
                                        # ì•ŒíŒŒê°€ 0ì´ ì•„ë‹Œ ì˜ì—­ë§Œ ë¸”ë Œë”© (ì„±ëŠ¥ ìµœì í™”)
                                        mask = alpha > 0
                                        if np.any(mask):
                                            # ì•ŒíŒŒë¥¼ floatë¡œ ë³€í™˜ (0-1 ë²”ìœ„)
                                            alpha_f = alpha.astype(np.float32) / 255.0
                                            alpha_3d = alpha_f[:, :, None]  # np.newaxis ëŒ€ì‹  None ì‚¬ìš©
                                            # ì•ŒíŒŒ ë¸”ë Œë”© (ë²¡í„°í™”ëœ ì—°ì‚°) - ch1ì€ í•­ìƒ ì• ë ˆì´ì–´
                                            frame = (frame.astype(np.float32) * (1 - alpha_3d) + overlay_bgr.astype(np.float32) * alpha_3d).astype(np.uint8)
                                    elif len(overlay_frame.shape) == 3:
                                        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë§ˆìŠ¤í¬ ìƒì„± ë° ë¸”ë Œë”©
                                        mask = cv2.cvtColor(overlay_frame, cv2.COLOR_BGR2GRAY)
                                        _, mask = cv2.threshold(mask, 1, 255, cv2.THRESH_BINARY)
                                        # ë§ˆìŠ¤í¬ê°€ ìˆëŠ” ì˜ì—­ë§Œ ì˜¤ë²„ë ˆì´ ë³µì‚¬ (ë” ë¹ ë¦„) - ch1ì€ í•­ìƒ ì• ë ˆì´ì–´
                                        cv2.copyTo(overlay_frame, mask, frame)
                                except Exception as e:
                                    print(f"âš ï¸ ch1 ì˜¤ë²„ë ˆì´ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                            elif overlay_cap is None:
                                # ë””ë²„ê¹…: ch1 ì˜¤ë²„ë ˆì´ê°€ Noneì¸ ê²½ìš° (ì²« í”„ë ˆì„ì—ì„œë§Œ ì¶œë ¥)
                                pass
                    
                    # ìµœì¢… í”„ë ˆì„ ì €ì¥ (lock ì•ˆì—ì„œ)
                    with self.lock:
                        self.frame = frame
            
                # í”„ë ˆì„ ì²˜ë¦¬ ì‹œê°„ ê³ ë ¤í•˜ì—¬ ì •í™•í•œ íƒ€ì´ë°ìœ¼ë¡œ ì¬ìƒ (perf_counter ì‚¬ìš©)
                elapsed = time_module.perf_counter() - loop_start_time
                sleep_time = max(0, frame_interval - elapsed)
            
            # í”„ë ˆì„ ë“œë¡­ ë³´ìƒ: ì²˜ë¦¬ ì‹œê°„ì´ í”„ë ˆì„ ê°„ê²©ë³´ë‹¤ ê¸¸ë©´ ë‹¤ìŒ í”„ë ˆì„ì„ ì¦‰ì‹œ ì½ê¸°
            if elapsed > frame_interval * 1.5:
                # í”„ë ˆì„ì´ ë„ˆë¬´ ëŠ¦ìœ¼ë©´ ëˆ„ì  ì‹œê°„ ì´ˆê¸°í™”í•˜ê³  ê³„ì† ì§„í–‰
                self.frame_accumulator = 0.0
                # ë‹¤ìŒ í”„ë ˆì„ì„ ì¦‰ì‹œ ì½ê¸° ìœ„í•´ sleep ê±´ë„ˆë›°ê¸°
            else:
                # ì •ìƒì ì¸ ê²½ìš° sleep
                if sleep_time > 0:
                    # ì‘ì€ sleep ì‹œê°„ì€ ë” ì •í™•í•˜ê²Œ ì²˜ë¦¬
                    if sleep_time < 0.001:
                        time_module.sleep(0)  # yield to other threads
                    else:
                        time_module.sleep(sleep_time)
    
    def start(self):
        """í”Œë ˆì´ì–´ ì‹œì‘"""
        if not self.running:
            self.running = True
            self.thread = threading.Thread(target=self._play_loop, daemon=True)
            self.thread.start()
    
    def set_overlay_video(self, overlay_path: str):
        """ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ch1 ì„¤ì • (ë°°ê²½ ìœ„ì— í‘œì‹œë  ìºë¦­í„° ì›€ì§ì„)"""
        # ê¸°ì¡´ ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ í•´ì œ (lock ë°–ì—ì„œ ë¨¼ì € í•´ì œ)
        old_cap = None
        with self.lock:
            old_cap = self.overlay_video_cap
            self.overlay_video_cap = None  # ë¨¼ì € Noneìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì¬ìƒ ë£¨í”„ì—ì„œ ì‚¬ìš©í•˜ì§€ ì•Šë„ë¡
            self.overlay_video_path = None
        
        # lock ë°–ì—ì„œ í•´ì œ (ì¬ìƒ ë£¨í”„ì™€ì˜ ì¶©ëŒ ë°©ì§€)
        # ì§§ì€ ëŒ€ê¸°ë¡œ ì¬ìƒ ë£¨í”„ê°€ ì°¸ì¡°ë¥¼ ë†“ë„ë¡ í•¨
        import time
        time.sleep(0.1)  # ì¬ìƒ ë£¨í”„ê°€ í˜„ì¬ í”„ë ˆì„ ì²˜ë¦¬ë¥¼ ì™„ë£Œí•  ì‹œê°„ ì œê³µ
        
        if old_cap is not None:
            try:
                # ì•ˆì „í•˜ê²Œ í•´ì œ
                if hasattr(old_cap, 'isOpened'):
                    try:
                        if old_cap.isOpened():
                            old_cap.release()
                    except:
                        pass  # ì´ë¯¸ í•´ì œë˜ì—ˆê±°ë‚˜ ì˜¤ë¥˜ ë°œìƒ
                else:
                    try:
                        old_cap.release()
                    except:
                        pass
            except:
                pass  # í•´ì œ ì¤‘ ì˜¤ë¥˜ëŠ” ë¬´ì‹œ
            finally:
                old_cap = None
        
        if overlay_path and os.path.exists(overlay_path):
            with self.lock:
                self.overlay_video_path = overlay_path
                self.overlay_video_cap = cv2.VideoCapture(overlay_path)
                if not self.overlay_video_cap.isOpened():
                    print(f"âŒ ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ë¥¼ ì—´ ìˆ˜ ì—†ìŒ: {overlay_path}")
                    self.overlay_video_cap = None
                    self.overlay_video_path = None
                    self.overlay_fps = 30.0  # ê¸°ë³¸ê°’
                else:
                    # ë¹„ë””ì˜¤ ìº¡ì²˜ ìµœì í™” ì„¤ì •
                    self.overlay_video_cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
                    # ë¹„ë””ì˜¤ë¥¼ ì²˜ìŒë¶€í„° ì¬ìƒí•˜ë„ë¡ ì„¤ì •
                    self.overlay_video_cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                    # FPS ì •ë³´ë¥¼ ffprobeë¡œ ë¨¼ì € ì‹œë„
                    try:
                        probe_cmd = [
                            "ffprobe", "-v", "error", "-select_streams", "v:0",
                            "-show_entries", "stream=r_frame_rate",
                            "-of", "default=noprint_wrappers=1:nokey=1",
                            overlay_path
                        ]
                        result = subprocess.run(probe_cmd, capture_output=True, text=True, timeout=2)
                        if result.returncode == 0:
                            fps_str = result.stdout.strip()
                            if '/' in fps_str:
                                num, den = map(int, fps_str.split('/'))
                                self.overlay_fps = num / den if den > 0 else 30.0
                            else:
                                self.overlay_fps = float(fps_str) if fps_str else 30.0
                        else:
                            fps = self.overlay_video_cap.get(cv2.CAP_PROP_FPS)
                            self.overlay_fps = fps if fps > 0 else 30.0
                    except:
                        fps = self.overlay_video_cap.get(cv2.CAP_PROP_FPS)
                        self.overlay_fps = fps if fps > 0 else 30.0
                    print(f"ğŸ¬ ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ch1 ì„¤ì • ì™„ë£Œ: {overlay_path} (FPS: {self.overlay_fps:.2f}, ì—´ë¦¼: {self.overlay_video_cap.isOpened()})")
        else:
            with self.lock:
                self.overlay_video_cap = None
                self.overlay_video_path = None
    
    def set_overlay_video2(self, overlay_path: str):
        """ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ch2 ì„¤ì • (ë°°ê²½ ìœ„ì— í‘œì‹œë  ìºë¦­í„° ì›€ì§ì„)"""
        # ê¸°ì¡´ ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ch2 í•´ì œ (lock ë°–ì—ì„œ ë¨¼ì € í•´ì œ)
        old_cap2 = None
        with self.lock:
            old_cap2 = self.overlay_video_cap2
            self.overlay_video_cap2 = None  # ë¨¼ì € Noneìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì¬ìƒ ë£¨í”„ì—ì„œ ì‚¬ìš©í•˜ì§€ ì•Šë„ë¡
            self.overlay_video_path2 = None
        
        # lock ë°–ì—ì„œ í•´ì œ (ì¬ìƒ ë£¨í”„ì™€ì˜ ì¶©ëŒ ë°©ì§€)
        # ì§§ì€ ëŒ€ê¸°ë¡œ ì¬ìƒ ë£¨í”„ê°€ ì°¸ì¡°ë¥¼ ë†“ë„ë¡ í•¨
        import time
        time.sleep(0.1)  # ì¬ìƒ ë£¨í”„ê°€ í˜„ì¬ í”„ë ˆì„ ì²˜ë¦¬ë¥¼ ì™„ë£Œí•  ì‹œê°„ ì œê³µ
        
        if old_cap2 is not None:
            try:
                # ì•ˆì „í•˜ê²Œ í•´ì œ
                if hasattr(old_cap2, 'isOpened'):
                    try:
                        if old_cap2.isOpened():
                            old_cap2.release()
                    except:
                        pass  # ì´ë¯¸ í•´ì œë˜ì—ˆê±°ë‚˜ ì˜¤ë¥˜ ë°œìƒ
                else:
                    try:
                        old_cap2.release()
                    except:
                        pass
            except:
                pass  # í•´ì œ ì¤‘ ì˜¤ë¥˜ëŠ” ë¬´ì‹œ
            finally:
                old_cap2 = None
        
        if overlay_path and os.path.exists(overlay_path):
            with self.lock:
                self.overlay_video_path2 = overlay_path
                self.overlay_video_cap2 = cv2.VideoCapture(overlay_path)
                if not self.overlay_video_cap2.isOpened():
                    print(f"âŒ ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ch2ë¥¼ ì—´ ìˆ˜ ì—†ìŒ: {overlay_path}")
                    self.overlay_video_cap2 = None
                    self.overlay_video_path2 = None
                    self.overlay_fps2 = 30.0  # ê¸°ë³¸ê°’
                else:
                    # ë¹„ë””ì˜¤ ìº¡ì²˜ ìµœì í™” ì„¤ì •
                    self.overlay_video_cap2.set(cv2.CAP_PROP_BUFFERSIZE, 1)
                    # ë¹„ë””ì˜¤ë¥¼ ì²˜ìŒë¶€í„° ì¬ìƒí•˜ë„ë¡ ì„¤ì •
                    self.overlay_video_cap2.set(cv2.CAP_PROP_POS_FRAMES, 0)
                    # FPS ì •ë³´ë¥¼ ffprobeë¡œ ë¨¼ì € ì‹œë„
                    try:
                        probe_cmd = [
                            "ffprobe", "-v", "error", "-select_streams", "v:0",
                            "-show_entries", "stream=r_frame_rate",
                            "-of", "default=noprint_wrappers=1:nokey=1",
                            overlay_path
                        ]
                        result = subprocess.run(probe_cmd, capture_output=True, text=True, timeout=2)
                        if result.returncode == 0:
                            fps_str = result.stdout.strip()
                            if '/' in fps_str:
                                num, den = map(int, fps_str.split('/'))
                                self.overlay_fps2 = num / den if den > 0 else 30.0
                            else:
                                self.overlay_fps2 = float(fps_str) if fps_str else 30.0
                        else:
                            fps = self.overlay_video_cap2.get(cv2.CAP_PROP_FPS)
                            self.overlay_fps2 = fps if fps > 0 else 30.0
                    except:
                        fps = self.overlay_video_cap2.get(cv2.CAP_PROP_FPS)
                        self.overlay_fps2 = fps if fps > 0 else 30.0
                    print(f"ğŸ¬ ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ch2 ì„¤ì • ì™„ë£Œ: {overlay_path} (FPS: {self.overlay_fps2:.2f}, ì—´ë¦¼: {self.overlay_video_cap2.isOpened()})")
        else:
            with self.lock:
                self.overlay_video_cap2 = None
                self.overlay_video_path2 = None
    
    def clear_overlay_video(self):
        """ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ëª¨ë‘ ì œê±°"""
        # ê¸°ì¡´ ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ í•´ì œ (lock ë°–ì—ì„œ ë¨¼ì € í•´ì œ)
        old_cap = None
        old_cap2 = None
        with self.lock:
            old_cap = self.overlay_video_cap
            old_cap2 = self.overlay_video_cap2
            self.overlay_video_cap = None  # ë¨¼ì € Noneìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì¬ìƒ ë£¨í”„ì—ì„œ ì‚¬ìš©í•˜ì§€ ì•Šë„ë¡
            self.overlay_video_cap2 = None
            self.overlay_video_path = None
            self.overlay_video_path2 = None
        
        # lock ë°–ì—ì„œ í•´ì œ (ì¬ìƒ ë£¨í”„ì™€ì˜ ì¶©ëŒ ë°©ì§€)
        import time
        time.sleep(0.1)  # ì¬ìƒ ë£¨í”„ê°€ í˜„ì¬ í”„ë ˆì„ ì²˜ë¦¬ë¥¼ ì™„ë£Œí•  ì‹œê°„ ì œê³µ
        
        if old_cap is not None:
            try:
                if hasattr(old_cap, 'isOpened'):
                    try:
                        if old_cap.isOpened():
                            old_cap.release()
                    except:
                        pass
                else:
                    try:
                        old_cap.release()
                    except:
                        pass
            except:
                pass
            finally:
                old_cap = None
        
        if old_cap2 is not None:
            try:
                if hasattr(old_cap2, 'isOpened'):
                    try:
                        if old_cap2.isOpened():
                            old_cap2.release()
                    except:
                        pass
                else:
                    try:
                        old_cap2.release()
                    except:
                        pass
            except:
                pass
            finally:
                old_cap2 = None
        
        print("ğŸ¬ ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ëª¨ë‘ ì œê±°")
    
    def stop(self):
        """í”Œë ˆì´ì–´ ì¤‘ì§€"""
        self.running = False
        if self.thread:
            self.thread.join(timeout=1.0)
        with self.lock:
            if self.video_cap:
                self.video_cap.release()
                self.video_cap = None
            if self.overlay_video_cap:
                self.overlay_video_cap.release()
                self.overlay_video_cap = None
            if self.overlay_video_cap2:
                self.overlay_video_cap2.release()
                self.overlay_video_cap2 = None
            self.frame = None
    
    def set_video(self, video_path: str):
        """ë¹„ë””ì˜¤ íŒŒì¼ ë³€ê²½ (í˜ì´ë“œ íš¨ê³¼ì™€ í•¨ê»˜ ë¶€ë“œëŸ¬ìš´ ì „í™˜). Noneì„ ì „ë‹¬í•˜ë©´ í˜ì´ë“œ ì•„ì›ƒ (ê²€ì€ í™”ë©´)"""
        if video_path is None:
            # Noneì´ë©´ í˜ì´ë“œ ì•„ì›ƒ (ê²€ì€ í™”ë©´)
            with self.lock:
                self.next_video_path = ""  # ë¹ˆ ë¬¸ìì—´ë¡œ í˜ì´ë“œ ì•„ì›ƒ í‘œì‹œ
                self.is_fading = True
                self.fade_start_time = time.time()
            return
        
        # ì²« ë²ˆì§¸ ë¹„ë””ì˜¤ì¸ì§€ í™•ì¸
        with self.lock:
            is_first = (self.current_video_path is None)
        
        if is_first:
            # ì²« ë²ˆì§¸ ë¹„ë””ì˜¤ëŠ” í˜ì´ë“œ ì—†ì´ ë°”ë¡œ ì‹œì‘
            new_cap = cv2.VideoCapture(video_path)
            if new_cap.isOpened():
                new_cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
                fps = new_cap.get(cv2.CAP_PROP_FPS)
                with self.lock:
                    self.current_video_path = video_path
                    self.bg_fps = fps if fps > 0 else 30.0
                    self.video_cap = new_cap
                print(f"ğŸ¬ ì²« ë¹„ë””ì˜¤ ì‹œì‘: {os.path.basename(video_path)} (FPS: {self.bg_fps:.2f})")
            else:
                print(f"âŒ ë¹„ë””ì˜¤ë¥¼ ì—´ ìˆ˜ ì—†ìŒ: {video_path}")
                with self.lock:
                    self.video_cap = None
                    self.bg_fps = 30.0
        else:
            # ë‹¤ìŒ ë¹„ë””ì˜¤ë¡œ ì „í™˜ (í˜ì´ë“œ íš¨ê³¼)
            with self.lock:
                self.next_video_path = video_path
                self.is_fading = True
                self.fade_start_time = time.time()
    
    def set_subtitle(self, subtitle_text: str):
        """ìë§‰ í…ìŠ¤íŠ¸ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."""
        with self.current_subtitle_lock:
            self.current_subtitle_text = subtitle_text
    
    def clear_subtitle(self):
        """ìë§‰ì„ ì§€ì›ë‹ˆë‹¤."""
        with self.current_subtitle_lock:
            self.current_subtitle_text = None
    
    def _wrap_text_cv2(self, text, font_scale, thickness, max_width):
        """OpenCVë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ í™”ë©´ ë„ˆë¹„ì— ë§ê²Œ ì¤„ë°”ê¿ˆ (ìºì‹œ ì‚¬ìš©)."""
        cache_key = (text, max_width, font_scale)
        if cache_key in self._subtitle_cache:
            return self._subtitle_cache[cache_key]
        
        font = cv2.FONT_HERSHEY_SIMPLEX
        words = text.split()
        lines = []
        current_line = ""
        
        for word in words:
            test_line = current_line + (" " if current_line else "") + word
            (text_width, text_height), baseline = cv2.getTextSize(test_line, font, font_scale, thickness)
            
            if text_width <= max_width:
                current_line = test_line
            else:
                if current_line:
                    lines.append(current_line)
                current_line = word
        
        if current_line:
            lines.append(current_line)
        
        if len(lines) == 0:
            lines = [text]
        elif len(lines) > 2:
            lines = lines[:2]
        
        self._subtitle_cache[cache_key] = lines
        return lines
    
    def _draw_subtitle(self, frame):
        """í”„ë ˆì„ì— ìë§‰ì„ ê·¸ë¦½ë‹ˆë‹¤ (ì œì¼ ìœ„ ë ˆì´ì–´). OpenCV ê¸°ë³¸ í°íŠ¸ ì‚¬ìš© (ìµœê³  ì„±ëŠ¥)."""
        with self.current_subtitle_lock:
            subtitle_text = self.current_subtitle_text
        
        # ìë§‰ì´ ì—†ìœ¼ë©´ í”„ë ˆì„ ê·¸ëŒ€ë¡œ ë°˜í™˜
        if subtitle_text is None or subtitle_text == "":
            return frame
        
        h, w = frame.shape[:2]
        frame_size = (h, w)
        
        # í”„ë ˆì„ í¬ê¸°ê°€ ë°”ë€Œë©´ ìºì‹œ í´ë¦¬ì–´
        if self._last_frame_size != frame_size:
            self._subtitle_cache.clear()
            self._last_frame_size = frame_size
        
        frame_with_subtitle = frame.copy()
        
        # OpenCV ê¸°ë³¸ í°íŠ¸ ì‚¬ìš© (PILë³´ë‹¤ í›¨ì”¬ ë¹ ë¦„)
        font = cv2.FONT_HERSHEY_SIMPLEX
        line_type = cv2.LINE_AA
        
        # ì¼ë°˜ ìë§‰ ê·¸ë¦¬ê¸° (í•˜ë‹¨)
        if subtitle_text and subtitle_text != "":
            font_scale = h / 720.0 * 0.8  # 720p ê¸°ì¤€ìœ¼ë¡œ ìŠ¤ì¼€ì¼ë§
            thickness = max(1, int(h / 360.0))
            max_width = int(w * 0.9)
            
            lines = self._wrap_text_cv2(subtitle_text, font_scale, thickness, max_width)
            
            # ê° ì¤„ì˜ ë†’ì´ ê³„ì‚°
            line_height = 0
            for line in lines:
                (text_width, text_height), baseline = cv2.getTextSize(line, font, font_scale, thickness)
                line_height = max(line_height, text_height)
            
            line_spacing = int(line_height * 0.3)
            total_height = len(lines) * line_height + (len(lines) - 1) * line_spacing
            y_start = h - 64 - total_height
            
            # ê° ì¤„ì„ ê·¸ë¦¬ê¸°
            for i, line in enumerate(lines):
                (text_width, text_height), baseline = cv2.getTextSize(line, font, font_scale, thickness)
                x = (w - text_width) // 2
                y = y_start + i * (line_height + line_spacing) + text_height
                
                # ê²€ì€ìƒ‰ stroke (ì™¸ê³½ì„ ) ê·¸ë¦¬ê¸° - 8ë°©í–¥ë§Œ
                stroke_width = 2
                stroke_offsets = [
                    (-stroke_width, -stroke_width), (-stroke_width, 0), (-stroke_width, stroke_width),
                    (0, -stroke_width), (0, stroke_width),
                    (stroke_width, -stroke_width), (stroke_width, 0), (stroke_width, stroke_width)
                ]
                for dx, dy in stroke_offsets:
                    cv2.putText(frame_with_subtitle, line, (x + dx, y + dy), font, font_scale,
                               (0, 0, 0), thickness + 1, line_type)
                
                # í°ìƒ‰ fill (ë³¸ë¬¸) ê·¸ë¦¬ê¸°
                cv2.putText(frame_with_subtitle, line, (x, y), font, font_scale,
                           (255, 255, 255), thickness, line_type)
        
        return frame_with_subtitle
    
    def get_frame(self):
        """í˜„ì¬ í”„ë ˆì„ ê°€ì ¸ì˜¤ê¸°"""
        with self.lock:
            if self.frame is not None:
                frame = self.frame.copy()
                # ìë§‰ ê·¸ë¦¬ê¸° (ì œì¼ ìœ„ ë ˆì´ì–´)
                frame = self._draw_subtitle(frame)
                return frame
        return None

# ì „ì—­ ë¹„ë””ì˜¤ í”Œë ˆì´ì–´ ì¸ìŠ¤í„´ìŠ¤
VIDEO_PLAYER = VideoPlayer()

# ë°°ê²½ ë¹„ë””ì˜¤ ì„¤ì •
BG_VIDEO_DIR = "bg_video"
BOOK_TO_VIDEO = {
    "BJBJ": "10bgBJBJ.mov",
    "PSJ": "11bgPSJ.mov",
    "DGJ": "13bgDGJ.mov",
    "HBJ": "17bgHBJ.mov",
    "JWCJ": "19bgJWCJ.mov",
    "KWJ": "3bgKWJ.mov",
    "OGJJ": "5bgOGJJ.mov",
    "JHHRJ": "6bgJHHRJ.mov",
    "SCJ": "7bgSCJ.mov",
}
# ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ íŒŒì¼ëª… ë§¤í•‘ (íŒŒì¼ëª…ê³¼ ì¼ì¹˜)
BOOK_TO_OVERLAY_CODE = {
    "BJBJ": "BJBJ",
    "PSJ": "PSJ",  # ë°•ì”¨ì „ -> PSJ (íŒŒì¼ëª…ê³¼ ì¼ì¹˜)
    "DGJ": "DGJ",  # ë‘ê»ì „ -> DGJ (íŒŒì¼ëª…ê³¼ ì¼ì¹˜)
    "HBJ": "HBJ",
    "JWCJ": "JWCJ",
    "KWJ": "KWJ",
    "OGJJ": "OGJJ",
    "JHHRJ": "JHHRJ",
    "SCJ": "SCJ",
}

# Interactions í´ë” ê²½ë¡œ
INTERACTIONS_DIR = "Interactions"


def get_overlay_video_path(bg_book_code: str, char_num: int, char_book_code: str) -> str:
    """
    ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        bg_book_code: ë°°ê²½ ì±… ì½”ë“œ (ì˜ˆ: "SCJ", "HBJ")
        char_num: ìºë¦­í„° ë²ˆí˜¸ (1 ë˜ëŠ” 2)
        char_book_code: ìºë¦­í„° ì±… ì½”ë“œ (ì˜ˆ: "SCJ", "HBJ")
    
    Returns:
        ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ (ì˜ˆ: "Interactions/bgSCJ/bgSCJ_ch1_HBJ.mov")
    """
    overlay_code = BOOK_TO_OVERLAY_CODE.get(char_book_code, char_book_code)
    filename = f"bg{bg_book_code}_ch{char_num}_{overlay_code}.mov"
    return os.path.join(INTERACTIONS_DIR, f"bg{bg_book_code}", filename)

def measure_character_height(overlay_path: str) -> tuple[int, int]:
    """
    ìºë¦­í„° ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ì˜ ë†’ì´ì™€ í‚¤ ì¤‘ì•™ì ì„ ì¸¡ì •í•©ë‹ˆë‹¤ (íˆ¬ëª… ë¶€ë¶„ ì œì™¸).
    
    Args:
        overlay_path: ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
    
    Returns:
        (ìºë¦­í„°ì˜ ì‹¤ì œ ë†’ì´, í‚¤ ì¤‘ì•™ì  Y ì¢Œí‘œ) íŠœí”Œ
    """
    if not os.path.exists(overlay_path):
        return (0, 0)
    
    try:
        cap = cv2.VideoCapture(overlay_path)
        if not cap.isOpened():
            return (0, 0)
        
        # ì²« í”„ë ˆì„ ì½ê¸°
        ret, frame = cap.read()
        cap.release()
        
        if not ret or frame is None:
            return (0, 0)
        
        frame_height = frame.shape[0]
        
        # RGBA ë˜ëŠ” BGR í™•ì¸
        if len(frame.shape) == 3 and frame.shape[2] == 4:
            # RGBA: ì•ŒíŒŒ ì±„ë„ ì‚¬ìš©
            alpha = frame[:, :, 3]
            # ê° í–‰ì—ì„œ ì•ŒíŒŒê°€ 0ì´ ì•„ë‹Œ í”½ì…€ì´ ìˆëŠ”ì§€ í™•ì¸
            rows_with_content = np.any(alpha > 0, axis=1)
        else:
            # BGR: ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜í•˜ì—¬ ê²€ì€ìƒ‰ì´ ì•„ë‹Œ ë¶€ë¶„ ì°¾ê¸°
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            rows_with_content = np.any(gray > 0, axis=1)
        
        # ë‚´ìš©ì´ ìˆëŠ” ì²« í–‰ê³¼ ë§ˆì§€ë§‰ í–‰ ì°¾ê¸°
        if not np.any(rows_with_content):
            # ë‚´ìš©ì´ ì—†ìœ¼ë©´ ì „ì²´ ë†’ì´ ë°˜í™˜, ì¤‘ì•™ì ì€ í”„ë ˆì„ ì¤‘ì•™
            return (frame_height, frame_height // 2)
        
        first_row = np.argmax(rows_with_content)
        last_row = len(rows_with_content) - 1 - np.argmax(rows_with_content[::-1])
        
        height = last_row - first_row + 1
        # í‚¤ ì¤‘ì•™ì : first_rowì™€ last_rowì˜ ì¤‘ê°„ì 
        center_y = (first_row + last_row) // 2
        
        return (height, center_y)
    except Exception as e:
        print(f"âš ï¸ ìºë¦­í„° ë†’ì´ ì¸¡ì • ì˜¤ë¥˜: {e}")
        return (0, 0)

# ============================================
# 1. ì„¤ì • íŒŒì¼ ë¡œë“œ
# ============================================
def load_json(path: str):
    if not os.path.exists(path):
        raise FileNotFoundError(f"{path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)

CHARACTERS = load_json("characters_tone.json")
BACKGROUNDS = load_json("backgrounds.json")

# ì±… ì½”ë“œ â†’ cha1 / cha2 ì—­í•  í‚¤ ë§¤í•‘
ROLE_MAP = {
    "SCJ": {"cha1": "simcheong",    "cha2": "simbongsa"},
    "HBJ": {"cha1": "heungbu",      "cha2": "nolbu"},
    "BJBJ": {"cha1": "turtle",      "cha2": "rabbit"},
    "OGJJ": {"cha1": "onggojip",    "cha2": "onggojip"},
    "JWCJ": {"cha1": "jeonwoochi",  "cha2": "jeonwoochi"},
    "JHHRJ": {"cha1": "sister_older",    "cha2": "ghost"},
    "PSJ": {"cha1": "ugly",         "cha2": "pretty"},
    "DGJ": {"cha1": "toad",         "cha2": "fox"},
    "KWJ": {"cha1": "kimwon",       "cha2": "monster"}
}

# ============================================
# ArUco ë§ˆì»¤ ì„¤ì •
# ============================================
ARUCO_DICTIONARY = aruco.getPredefinedDictionary(aruco.DICT_5X5_1000)
ARUCO_MARKER_SIZE = 200  # pixels

# ë§ˆì»¤ ID â†’ ì±… ì½”ë“œ ë§¤í•‘
MARKER_TO_BOOK = {
    1: "KWJ",      # 03_KWJ
    2: "PSJ",      # 11_PSJ
    6: "DGJ",      # 13_DGJ
    7: "JHHRJ",    # 06_JHHRJ
    8: "JWCJ",     # 19_JWCJ
    9: "HBJ",      # 17_HBJ
    10: "OGJJ",    # 05_OGJJ
    11: "SCJ",     # 07_SCJ
    12: "BJBJ",    # 10_BJBJ
}

# ë§ˆì»¤ ID â†’ íŒŒì¼ëª… ë§¤í•‘
MARKER_NAMES = {
    1: "03_KWJ",
    2: "11_PSJ",
    6: "13_DGJ",
    7: "06_JHHRJ",
    8: "19_JWCJ",
    9: "17_HBJ",
    10: "05_OGJJ",
    11: "07_SCJ",
    12: "10_BJBJ",
}


def generate_aruco_markers(output_dir: str = "markers"):
    """
    ArUco ë§ˆì»¤ ì´ë¯¸ì§€ë“¤ì„ ìƒì„±í•˜ì—¬ ì§€ì •ëœ í´ë”ì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    os.makedirs(output_dir, exist_ok=True)
    
    for marker_id, name in MARKER_NAMES.items():
        marker_image = aruco.generateImageMarker(ARUCO_DICTIONARY, marker_id, ARUCO_MARKER_SIZE)
        filename = os.path.join(output_dir, f"{name}.png")
        cv2.imwrite(filename, marker_image)
        print(f"âœ… Saved ArUco marker: {filename}")
    
    print(f"\nğŸ¯ ì´ {len(MARKER_NAMES)}ê°œì˜ ArUco ë§ˆì»¤ê°€ '{output_dir}' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


def get_book_code_from_marker(marker_id: int) -> str | None:
    """
    ArUco ë§ˆì»¤ IDë¡œë¶€í„° ì±… ì½”ë“œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    return MARKER_TO_BOOK.get(marker_id)

# ============================================
# 2. Background ê´€ë ¨
# ============================================
def get_background(book_code: str):
    return BACKGROUNDS.get(book_code)

# ë°°ê²½ ì‚¬ìš´ë“œ ë° ìŒì•… ì¬ìƒ
BG_SOUND_DIR = "bg_sound"
BG_MUSIC_DIR = "bg_music"
# bg_sound íŒŒì¼ëª… ë§¤í•‘
BOOK_TO_BG_SOUND = {
    "BJBJ": "10_BJBJ_bg_sound.wav",
    "PSJ": "11_BSJ_bg_sound.wav",
    "DGJ": "13_DGJ_bg_sound.wav",
    "HBJ": "17_HBJ_bg_sound.wav",
    "JWCJ": "19_JWCJ_bg_sound.wav",
    "KWJ": "3_KWJ_bg_sound.wav",
    "OGJJ": "5_OGJJ_bg_sound.wav",
    "JHHRJ": "6_JHHRJ_bg_sound.wav",
    "SCJ": "7_SCJ_bg_sound.wav"
}
# bg_music íŒŒì¼ëª… ë§¤í•‘
BOOK_TO_BG_MUSIC = {
    "BJBJ": "10_BJBJ_bg_music.wav",
    "PSJ": "11_BSJ_bg_music.wav",
    "DGJ": "13_DGJ_bg_music.wav",
    "HBJ": "17_HBJ_bg_music.wav",
    "JWCJ": "19_JWCJ_bg_music.wav",
    "KWJ": "3_KWJ_bg_music.wav",
    "JHHRJ": "6_JHHRJ_bg_music.wav",
    "SCJ": "7_SCJ_bg_music.wav"
}

# í˜„ì¬ ì¬ìƒ ì¤‘ì¸ bg ì˜¤ë””ì˜¤ í”„ë¡œì„¸ìŠ¤ ë° ìŠ¤ë ˆë“œ
_current_bg_sound_process = None
_current_bg_music_process = None
_bg_audio_playing = False  # bg ì˜¤ë””ì˜¤ ì¬ìƒ ë£¨í”„ í”Œë˜ê·¸
_bg_audio_thread = None  # bg ì˜¤ë””ì˜¤ ì¬ìƒ ìŠ¤ë ˆë“œ

# í˜„ì¬ ì¬ìƒ ì¤‘ì¸ ë°°ê²½ ì¶”ì 
_current_bg_music_book_code = None

def play_background_music(book_code: str):
    """
    ì±… ì½”ë“œì— í•´ë‹¹í•˜ëŠ” bg_soundì™€ bg_musicì„ ë™ì‹œì— ë¬´í•œ ë£¨í”„ë¡œ ì¬ìƒí•©ë‹ˆë‹¤.
    ì´ë¯¸ ê°™ì€ ë°°ê²½ì´ ì¬ìƒ ì¤‘ì´ë©´ ì¬ìƒí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    """
    global _current_bg_sound_process, _current_bg_music_process, _bg_audio_playing, _bg_audio_thread, _current_bg_music_book_code
    
    # ì´ë¯¸ ê°™ì€ ë°°ê²½ì´ ì¬ìƒ ì¤‘ì´ë©´ ì¬ìƒí•˜ì§€ ì•ŠìŒ
    if _current_bg_music_book_code == book_code and _bg_audio_playing:
        print(f"ğŸµ ë°°ê²½ ìŒì•…ì´ ì´ë¯¸ ì¬ìƒ ì¤‘ì…ë‹ˆë‹¤: {book_code} (ì¬ìƒí•˜ì§€ ì•ŠìŒ)")
        return
    
    # ê¸°ì¡´ bg ì˜¤ë””ì˜¤ ì¤‘ì§€
    _bg_audio_playing = False
    if _current_bg_sound_process is not None:
        try:
            _current_bg_sound_process.terminate()
            _current_bg_sound_process.wait(timeout=1)
        except:
            try:
                _current_bg_sound_process.kill()
            except:
                pass
        _current_bg_sound_process = None
    
    if _current_bg_music_process is not None:
        try:
            _current_bg_music_process.terminate()
            _current_bg_music_process.wait(timeout=1)
        except:
            try:
                _current_bg_music_process.kill()
            except:
                pass
        _current_bg_music_process = None
    
    # bg_sound íŒŒì¼ ê²½ë¡œ í™•ì¸
    bg_sound_file = BOOK_TO_BG_SOUND.get(book_code)
    bg_sound_path = None
    if bg_sound_file:
        bg_sound_path = os.path.join(BG_SOUND_DIR, bg_sound_file)
        if not os.path.exists(bg_sound_path):
            print(f"âš ï¸ bg_sound íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {bg_sound_path}")
            bg_sound_path = None
    
    # bg_music íŒŒì¼ ê²½ë¡œ í™•ì¸
    bg_music_file = BOOK_TO_BG_MUSIC.get(book_code)
    bg_music_path = None
    if bg_music_file:
        bg_music_path = os.path.join(BG_MUSIC_DIR, bg_music_file)
        if not os.path.exists(bg_music_path):
            print(f"âš ï¸ bg_music íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {bg_music_path}")
            bg_music_path = None
    
    if bg_sound_path is None and bg_music_path is None:
        print(f"ğŸµ '{book_code}'ì— í•´ë‹¹í•˜ëŠ” ë°°ê²½ ì˜¤ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ìŒëŸ‰ì„ ì ˆë°˜ìœ¼ë¡œ ì¡°ì ˆí•œ ì„ì‹œ íŒŒì¼ ìƒì„±
    import tempfile
    temp_dir = tempfile.gettempdir()
    temp_bg_sound = None
    temp_bg_music = None
    
    if bg_sound_path:
        temp_bg_sound = os.path.join(temp_dir, f"bg_sound_{book_code}_{os.getpid()}.wav")
        try:
            # ffmpegë¡œ ìŒëŸ‰ 50%ë¡œ ì¡°ì ˆ
            subprocess.run(
                ["ffmpeg", "-y", "-i", bg_sound_path,
                 "-af", "volume=0.5",
                 temp_bg_sound],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
                check=True,
                timeout=5
            )
        except Exception as e:
            print(f"âš ï¸ bg_sound ìŒëŸ‰ ì¡°ì ˆ ì‹¤íŒ¨, ì›ë³¸ íŒŒì¼ ì‚¬ìš©: {e}")
            temp_bg_sound = bg_sound_path  # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì‚¬ìš©
    
    if bg_music_path:
        temp_bg_music = os.path.join(temp_dir, f"bg_music_{book_code}_{os.getpid()}.wav")
        try:
            # ffmpegë¡œ ìŒëŸ‰ 50%ë¡œ ì¡°ì ˆ
            subprocess.run(
                ["ffmpeg", "-y", "-i", bg_music_path,
                 "-af", "volume=0.5",
                 temp_bg_music],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
                check=True,
                timeout=5
            )
        except Exception as e:
            print(f"âš ï¸ bg_music ìŒëŸ‰ ì¡°ì ˆ ì‹¤íŒ¨, ì›ë³¸ íŒŒì¼ ì‚¬ìš©: {e}")
            temp_bg_music = bg_music_path  # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì‚¬ìš©
    
    # í˜„ì¬ ë°°ê²½ ì±… ì½”ë“œ ê¸°ë¡
    _current_bg_music_book_code = book_code
    
    # afplayë¡œ ë¬´í•œ ë£¨í”„ ì¬ìƒ (ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ)
    def play_bg_audio_loop():
        global _current_bg_sound_process, _current_bg_music_process, _bg_audio_playing, _current_bg_music_book_code
        _bg_audio_playing = True
        
        bg_sound_file_to_play = temp_bg_sound
        bg_music_file_to_play = temp_bg_music
        
        while _bg_audio_playing:
            try:
                # bg_soundì™€ bg_musicì„ ë™ì‹œì— ì¬ìƒ
                if bg_sound_file_to_play:
                    _current_bg_sound_process = subprocess.Popen(
                        ["afplay", bg_sound_file_to_play],
                        stdout=subprocess.DEVNULL,
                        stderr=subprocess.DEVNULL
                    )
                
                if bg_music_file_to_play:
                    _current_bg_music_process = subprocess.Popen(
                        ["afplay", bg_music_file_to_play],
                        stdout=subprocess.DEVNULL,
                        stderr=subprocess.DEVNULL
                    )
                
                # ë‘ í”„ë¡œì„¸ìŠ¤ ì¤‘ í•˜ë‚˜ë¼ë„ ëë‚˜ë©´ ë‹¤ì‹œ ì‹œì‘ (ë¬´í•œ ë£¨í”„)
                if _current_bg_sound_process:
                    _current_bg_sound_process.wait()
                if _current_bg_music_process:
                    _current_bg_music_process.wait()
                
                # ì¬ìƒì´ ëë‚˜ë©´ ë‹¤ì‹œ ì‹œì‘ (ë¬´í•œ ë£¨í”„) - ë‹¨, _bg_audio_playingì´ Trueì¼ ë•Œë§Œ
            except Exception as e:
                if _bg_audio_playing:  # ì¤‘ì§€ ìš”ì²­ì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ì˜¤ë¥˜ ì¶œë ¥
                    print(f"âš ï¸ ë°°ê²½ ì˜¤ë””ì˜¤ ì¬ìƒ ì˜¤ë¥˜: {e}")
                break
        
        # ìŠ¤ë ˆë“œ ì¢…ë£Œ ì‹œ ì„ì‹œ íŒŒì¼ ì‚­ì œ
        if temp_bg_sound and temp_bg_sound != bg_sound_path and os.path.exists(temp_bg_sound):
            try:
                os.remove(temp_bg_sound)
            except:
                pass
        if temp_bg_music and temp_bg_music != bg_music_path and os.path.exists(temp_bg_music):
            try:
                os.remove(temp_bg_music)
            except:
                pass
    
    _bg_audio_thread = threading.Thread(target=play_bg_audio_loop, daemon=False)
    _bg_audio_thread.start()
    
    if bg_sound_path:
        print(f"ğŸµ bg_sound ì¬ìƒ ì‹œì‘ (ìŒëŸ‰ 50%): {bg_sound_path}")
    if bg_music_path:
        print(f"ğŸµ bg_music ì¬ìƒ ì‹œì‘ (ìŒëŸ‰ 50%): {bg_music_path}")

def stop_background_music():
    """bg_soundì™€ bg_musicì„ ì¤‘ì§€í•©ë‹ˆë‹¤."""
    global _current_bg_sound_process, _current_bg_music_process, _bg_audio_playing, _bg_audio_thread, _current_bg_music_book_code
    
    # ì¬ìƒ ë£¨í”„ ì¤‘ì§€
    _bg_audio_playing = False
    _current_bg_music_book_code = None
    
    # í˜„ì¬ ì¬ìƒ ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤ ì¤‘ì§€
    if _current_bg_sound_process is not None:
        try:
            _current_bg_sound_process.terminate()
            _current_bg_sound_process.wait(timeout=1)
        except:
            try:
                _current_bg_sound_process.kill()
            except:
                pass
        _current_bg_sound_process = None
    
    if _current_bg_music_process is not None:
        try:
            _current_bg_music_process.terminate()
            _current_bg_music_process.wait(timeout=1)
        except:
            try:
                _current_bg_music_process.kill()
            except:
                pass
        _current_bg_music_process = None
    
    # ìŠ¤ë ˆë“œê°€ ì¢…ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸° (ìµœëŒ€ 2ì´ˆ)
    if _bg_audio_thread is not None and _bg_audio_thread.is_alive():
        _bg_audio_thread.join(timeout=2)
        if _bg_audio_thread.is_alive():
            # ìŠ¤ë ˆë“œê°€ ì¢…ë£Œë˜ì§€ ì•Šìœ¼ë©´ ê°•ì œ ì¢…ë£ŒëŠ” ë¶ˆê°€ëŠ¥í•˜ì§€ë§Œ, í”„ë¡œì„¸ìŠ¤ëŠ” ì´ë¯¸ ì¤‘ì§€ë¨
            pass
        _bg_audio_thread = None
    
    print("ğŸµ ë°°ê²½ ìŒì•… ì¤‘ì§€ë¨")


def stop_background_video():
    """í˜„ì¬ ì¬ìƒ ì¤‘ì¸ ë°°ê²½ ë¹„ë””ì˜¤ë¥¼ ì¤‘ì§€í•©ë‹ˆë‹¤."""
    VIDEO_PLAYER.stop()
    print("ğŸ¬ ë°°ê²½ ë¹„ë””ì˜¤ ì¤‘ì§€ë¨")


def play_background_video(book_code: str):
    """
    ì±… ì½”ë“œì— í•´ë‹¹í•˜ëŠ” ë°°ê²½ ë¹„ë””ì˜¤ë¥¼ ë¬´í•œ ë£¨í”„ë¡œ ì¬ìƒí•©ë‹ˆë‹¤.
    ê°™ì€ ìœˆë„ìš°ì—ì„œ ë¶€ë“œëŸ½ê²Œ ì „í™˜ë©ë‹ˆë‹¤.
    """
    # ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ í™•ì¸
    video_file = BOOK_TO_VIDEO.get(book_code)
    if video_file is None:
        print(f"ğŸ¬ '{book_code}'ì— í•´ë‹¹í•˜ëŠ” ë°°ê²½ ë¹„ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    video_path = os.path.join(BG_VIDEO_DIR, video_file)
    if not os.path.exists(video_path):
        print(f"ğŸ¬ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {video_path}")
        return
    
    # VideoPlayerë¥¼ í†µí•´ ë¹„ë””ì˜¤ ì „í™˜ (ê°™ì€ ìœˆë„ìš°ì—ì„œ ë¶€ë“œëŸ½ê²Œ)
    VIDEO_PLAYER.set_video(video_path)
    
    # ë¹„ë””ì˜¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì„¤ì •ë˜ê³  ì¬ìƒ ì¤‘ì¸ì§€ í™•ì¸ (ì¬ì‹œë„ ë¡œì§)
    # ì£¼ì˜: set_videoê°€ next_video_pathë§Œ ì„¤ì •í•˜ê³  _play_loopì—ì„œ ë‚˜ì¤‘ì— 
    # ë¹„ë””ì˜¤ ì „í™˜ì´ ì™„ë£Œë  ë•Œê¹Œì§€ ì¶©ë¶„íˆ ê¸°ë‹¤ë ¤ì•¼ í•¨
    import time
    max_retries = 20  # ìµœëŒ€ 2ì´ˆ ëŒ€ê¸° (í˜ì´ë“œ íš¨ê³¼ ê³ ë ¤)
    retry_delay = 0.1  # 0.1ì´ˆë§ˆë‹¤ í™•ì¸
    is_playing = False
    
    for attempt in range(max_retries):
        time.sleep(retry_delay)
        with VIDEO_PLAYER.lock:
            video_cap = VIDEO_PLAYER.video_cap
            current_path = VIDEO_PLAYER.current_video_path
            next_path = VIDEO_PLAYER.next_video_path
        
        # next_video_pathê°€ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ ì•„ì§ ì „í™˜ ì¤‘
        if next_path == video_path:
            # ì „í™˜ ëŒ€ê¸° ì¤‘
            continue
        
        # ë¹„ë””ì˜¤ ìº¡ì²˜ ê°ì²´ê°€ ìˆê³  ì—´ë ¤ìˆëŠ”ì§€ í™•ì¸
        if video_cap is not None:
            try:
                if video_cap.isOpened() and current_path == video_path:
                    is_playing = True
                    break
            except:
                # isOpened() í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ì‹œ ë‹¤ìŒ ì‹œë„
                pass
        elif current_path == video_path:
            # ê²½ë¡œëŠ” ë§ì§€ë§Œ video_capì´ ì•„ì§ None (ì „í™˜ ì¤‘)
            continue
    
    if is_playing:
        print(f"âœ… ë°°ê²½ ë¹„ë””ì˜¤ ì¬ìƒ ì¤‘: {video_file} (ë¬´í•œ ë£¨í”„)")
    else:
        # ìµœì¢… í™•ì¸ (ê²½ë¡œë§Œ í™•ì¸)
        with VIDEO_PLAYER.lock:
            final_path = VIDEO_PLAYER.current_video_path
            final_next = VIDEO_PLAYER.next_video_path
        if final_path == video_path:
            print(f"âœ… ë°°ê²½ ë¹„ë””ì˜¤ ì„¤ì • ì™„ë£Œ: {video_file} (ì¬ìƒ í™•ì¸ ì¤‘...)")
        elif final_next == video_path:
            print(f"â³ ë°°ê²½ ë¹„ë””ì˜¤ ì „í™˜ ëŒ€ê¸° ì¤‘: {video_file} (í˜ì´ë“œ íš¨ê³¼ ì§„í–‰ ì¤‘...)")
        else:
            print(f"âš ï¸ ë°°ê²½ ë¹„ë””ì˜¤ ì¬ìƒ í™•ì¸ ì‹¤íŒ¨: {video_file} (í˜„ì¬: {final_path}, ë‹¤ìŒ: {final_next})")

def get_interaction_profile(bg_info: dict, character: dict = None, is_cha1: bool = False) -> dict:
    """
    backgrounds.json ì•ˆì— ë¯¸ë¦¬ ì •ì˜í•´ ë‘”
    interaction_label / interaction_summary / interaction_emotionsë¥¼ ê°€ì ¸ì˜¨ë‹¤.
    interaction_emotionsëŠ” 10ê°€ì§€ ê°ì • ì˜µì…˜ ë¦¬ìŠ¤íŠ¸ë¡œ, LLMì´ ìºë¦­í„° ì„±ê²©ì— ë§ê²Œ ì„ íƒí•œë‹¤.
    
    Args:
        bg_info: ë°°ê²½ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        character: ìºë¦­í„° ì •ë³´ ë”•ì…”ë„ˆë¦¬ (ì„ íƒì )
        is_cha1: Trueë©´ cha1, Falseë©´ cha2 (ì„ íƒì )
    """
    if bg_info is None:
        return {
            "label": "neutral",
            "summary": "A neutral situation with no special context",
            "emotion_options": ["mild curiosity", "calm observation", "quiet interest"]
        }

    # interaction ë¬¸ìì—´ì—ì„œ Character1/Character2 êµ¬ë¶„ ì¶”ì¶œ
    interaction_str = bg_info.get("interaction", "")
    interaction_summary = bg_info.get("interaction_summary", "")
    
    # Character1/Character2 êµ¬ë¶„ì´ ìˆëŠ” ê²½ìš° íŒŒì‹±
    if character is not None:
        # cha1ì¸ì§€ cha2ì¸ì§€ í™•ì¸
        if is_cha1:
            char_marker = "Character1"
        else:
            char_marker = "Character2"
        
        # interaction ë¬¸ìì—´ì—ì„œ í•´ë‹¹ ìºë¦­í„°ì˜ interaction ì¶”ì¶œ
        if char_marker in interaction_str:
            # "(Character1)...(Character2)" í˜•ì‹ íŒŒì‹±
            import re
            # Character1ê³¼ Character2 ë¶€ë¶„ ì¶”ì¶œ
            pattern1 = r'\(Character1\)([^,)]+?)(?:\(Character2\)|$)'
            pattern2 = r'\(Character2\)([^,)]+?)(?:\(Character1\)|$)'
            
            if is_cha1:
                match = re.search(pattern1, interaction_str)
                if match:
                    interaction_str = match.group(1).strip()
            else:
                match = re.search(pattern2, interaction_str)
                if match:
                    interaction_str = match.group(1).strip()
            
            # summaryë„ ìºë¦­í„°ì— ë§ê²Œ ì¡°ì • (ê°„ë‹¨í•œ ë²„ì „)
            if is_cha1 and "Character1" in interaction_summary:
                # Character1 ê´€ë ¨ ë¶€ë¶„ë§Œ ì¶”ì¶œí•˜ê±°ë‚˜ ìš”ì•½
                pass  # summaryëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ë˜, interaction_strì´ ë” ì¤‘ìš”
            elif not is_cha1 and "Character2" in interaction_summary:
                pass  # summaryëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©

    # interaction_emotionsëŠ” ì´ì œ ë¦¬ìŠ¤íŠ¸
    emotions_data = bg_info.get("interaction_emotions", [])
    if isinstance(emotions_data, list):
        emotion_options = emotions_data
    else:
        # í˜¹ì‹œ ë¬¸ìì—´ì´ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        emotion_options = [emotions_data]

    return {
        "label": bg_info.get("interaction_label", "neutral"),
        "summary": interaction_summary,  # ì›ë³¸ summary ì‚¬ìš©
        "interaction": interaction_str,  # íŒŒì‹±ëœ interaction ì¶”ê°€
        "emotion_options": emotion_options
    }

# ============================================
# 3. Character ê´€ë ¨
# ============================================
def build_character(book_code: str, role_key: str) -> dict:
    data = CHARACTERS[book_code][role_key]

    gender = data["gender"]
    age = data["age"]
    base_desc = data["base_personality"]
    raw_voice = data.get("voice", "alloy")
    speed = data.get("speed", 1.0)

    voice = raw_voice if raw_voice in ALLOWED_VOICES else "alloy"

    personality = base_desc

    return {
        "book_code": book_code,
        "role_key": role_key,
        "gender": gender,
        "age": age,
        "voice": voice,
        "personality": personality,
        "speed": speed,
    }

def build_sisters_pair() -> tuple[dict, dict]:
    older = build_character("JHHRJ", "sister_older")
    younger = build_character("JHHRJ", "sister_younger")
    return older, younger

# ============================================
# 4. í…ìŠ¤íŠ¸ LLMìœ¼ë¡œ ëŒ€ì‚¬ ìƒì„±
# ============================================
def _clean_line(text: str) -> str:
    if not text:
        return ""
    line = text.strip().splitlines()[0]
    line = line.strip().strip("ã€Œã€\"'â€œâ€â€˜â€™")
    return line


def generate_action_line(character: dict, bg_info: dict) -> str:
    """
    ë°°ê²½/ì¸í„°ë™ì…˜ì„ ë³´ê³  ìºë¦­í„°ê°€ ê·¸ í–‰ë™ì„ í•˜ê¸° ì§ì „ì— í•˜ëŠ” í•œ ë§ˆë””.
    â†’ ìµœëŒ€í•œ ì§§ê³  êµ¬ì–´ì²´, ì‚¬ëŒ ë§ì²˜ëŸ¼.
    """
    place = bg_info.get("background", "")
    action = bg_info.get("interaction", "")
    profile = get_interaction_profile(bg_info)
    emotion_list = "\n".join([f"  - {e}" for e in profile['emotion_options']])

    # ìºë¦­í„°ì˜ speech_patterns ê°€ì ¸ì˜¤ê¸°
    char_data = CHARACTERS.get(character['book_code'], {}).get(character['role_key'], {})
    speech_patterns = char_data.get('speech_patterns', {})
    speaking_style = speech_patterns.get('speaking_style', '')
    frequent_expressions = speech_patterns.get('frequent_expressions', [])[:15]  # ìƒìœ„ 15ê°œë§Œ
    endings_from_dialogues = speech_patterns.get('endings_from_dialogues', [])[:10]  # ìƒìœ„ 10ê°œë§Œ
    common_words = speech_patterns.get('common_words', [])[:10]  # ìƒìœ„ 10ê°œë§Œ
    analysis = char_data.get('analysis_from_dialogues', {})
    
    # ë¶„ì„ ê²°ê³¼ í¬ë§·íŒ…
    formality_info = ', '.join(analysis.get('formality_indicators', [])[:3]) if analysis.get('formality_indicators') else ''
    emotional_keywords = ', '.join([e.split(':')[0] for e in analysis.get('emotional_keywords', [])[:5]]) if analysis.get('emotional_keywords') else ''
    dialect_info = ', '.join([d.split(':')[0] for d in analysis.get('dialect_indicators', [])]) if analysis.get('dialect_indicators') else ''

    system = (
        "ë‹¹ì‹ ì€ í•œêµ­ ì˜›ì´ì•¼ê¸° ì† ë“±ì¥ì¸ë¬¼ì´ ì‹¤ì œë¡œ ë§í•˜ëŠ” ëŒ€ì‚¬ë¥¼ ì“°ëŠ” ì‘ê°€ì…ë‹ˆë‹¤. "
        "ëŒ€ë³¸ì´ë‚˜ ë‚˜ë ˆì´ì…˜ì´ ì•„ë‹ˆë¼, ì‚¬ëŒì´ ì…ìœ¼ë¡œ íˆ­ íŠ€ì–´ë‚˜ì˜¤ê²Œ ë§í•˜ëŠ” í•œêµ­ì–´ êµ¬ì–´ì²´ë¥¼ ë§Œë“œì„¸ìš”."
    )

    user = f"""
ë°°ê²½ ì¥ì†Œ: {place}
ë°°ê²½ ì¸í„°ë™ì…˜: {action}

ì¥ë©´ ë¶„ìœ„ê¸°:
- ìš”ì•½: {profile['summary']}
- ê°€ëŠ¥í•œ ê°ì •ë“¤ (ìºë¦­í„° ì„±ê²©ì— ë§ëŠ” ê²ƒì„ ì„ íƒí•˜ì„¸ìš”):
{emotion_list}

ìºë¦­í„° ì„¤ì •(ì˜ì–´): {character['personality']}
ìºë¦­í„° ì •ë³´: {character['age']}ì‚´ {character['gender']}
ìºë¦­í„° ë§íˆ¬ ìŠ¤íƒ€ì¼: {speaking_style}

ìºë¦­í„° ë§íˆ¬ íŠ¹ì§• (ì‹¤ì œ ëŒ€ì‚¬ ë¶„ì„ ê²°ê³¼):
{f"- ìì£¼ ì‚¬ìš©í•˜ëŠ” í‘œí˜„: {', '.join(frequent_expressions) if frequent_expressions else 'ì—†ìŒ'}"}
{f"- ì‹¤ì œ ëŒ€ì‚¬ì—ì„œ ìì£¼ ì“°ëŠ” ì–´ë¯¸: {', '.join(endings_from_dialogues) if endings_from_dialogues else 'ì—†ìŒ'}"}
{f"- ìì£¼ ì‚¬ìš©í•˜ëŠ” ë‹¨ì–´: {', '.join(common_words) if common_words else 'ì—†ìŒ'}"}
{f"- ê²©ì‹/ê³µì†ë„: {formality_info if formality_info else 'ì—†ìŒ'}"}
{f"- ê°ì • í†¤: {emotional_keywords if emotional_keywords else 'ì—†ìŒ'}"}
{f"- ë°©ì–¸ íŠ¹ì§•: {dialect_info if dialect_info else 'ì—†ìŒ'}"}

ìƒí™©:
- ì´ ìºë¦­í„°ê°€ ì§€ê¸ˆ '{action}'ì„(ë¥¼) í•˜ê¸° ì§ì „ì…ë‹ˆë‹¤.
- ìœ„ ê°ì • ì˜µì…˜ ì¤‘ ì´ ìºë¦­í„°ì˜ ì„±ê²©ì— ê°€ì¥ ì–´ìš¸ë¦¬ëŠ” ê°ì •ì„ ì„ íƒí•˜ê³ , ê·¸ ê°ì •ì„ ë‹´ì•„ ì§§ê²Œ í•œ ë§ˆë””ë¥¼ í•©ë‹ˆë‹¤.

ë§íˆ¬ ê·œì¹™:
- ìœ„ì˜ "ìºë¦­í„° ë§íˆ¬ íŠ¹ì§•"ì— ë‚˜ì˜¨ ì‹¤ì œ ëŒ€ì‚¬ ë¶„ì„ ê²°ê³¼ë¥¼ ë°˜ë“œì‹œ ì°¸ê³ í•˜ì—¬ ë§íˆ¬ë¥¼ ì •í™•íˆ ì¬í˜„í•˜ì„¸ìš”.
- ìì£¼ ì‚¬ìš©í•˜ëŠ” í‘œí˜„ê³¼ ì–´ë¯¸ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í™œìš©í•˜ì„¸ìš”.
- ë¬¸ì–´ì²´(ì˜ˆ: '~ê²ƒì´ë‹¤', '~í•©ë‹ˆë‹¤')ë¥¼ ì ˆëŒ€ ì“°ì§€ ë§ˆì„¸ìš”.
- ìì—°ìŠ¤ëŸ¬ìš´ êµ¬ì–´ì²´ë§Œ ì“°ì„¸ìš”. (ì˜ˆ: '~ê±°ì•¼', '~í•˜ëŠ” ê±´ê°€?', '~í•´ë³¼ê¹Œ', '~í•˜ë„¤ìš”' ë“±)
- ìºë¦­í„°ì˜ ë§íˆ¬ ìŠ¤íƒ€ì¼ì„ ì •í™•íˆ ë”°ë¥´ì„¸ìš”. íŠ¹íˆ '~ì´ê¸°ì•¼' ê°™ì€ ë¹„ë¬¸ë²•ì  í‘œí˜„ì„ ì“°ì§€ ë§ê³  '~ì´ì§€' ê°™ì€ ì˜¬ë°”ë¥¸ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”.
- ë„ˆë¬´ ê¸¸ê²Œ ì„¤ëª…í•˜ì§€ ë§ê³ , 1~2ì´ˆ ì•ˆì— ë§í•  ìˆ˜ ìˆì„ ì •ë„ì˜ ì§§ì€ í•œ ë¬¸ì¥ìœ¼ë¡œ.
- ëŠë‚Œí‘œë‚˜ ë¬¼ìŒí‘œëŠ” ì¨ë„ ë˜ì§€ë§Œ, ë¬¸ì¥ì€ í•˜ë‚˜ë§Œ.
- ë”°ì˜´í‘œ( ", ã€ ã€ ë“±)ëŠ” ì“°ì§€ ë§ˆì„¸ìš”.

ì¶œë ¥:
- ì¡°ê±´ì„ ì§€í‚¤ëŠ” í•œêµ­ì–´ í•œ ë¬¸ì¥ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
"""

    resp = client.responses.create(
        model=TEXT_MODEL,
        input=[
            {"role": "system", "content": system},
            {"role": "user", "content": user}
        ],
        max_output_tokens=50,
        temperature=0.7  # ë„ˆë¬´ íŠ€ì§€ ì•Šê²Œ ì•½ê°„ ë‚®ì¶¤
    )
    return _clean_line(resp.output_text)


def generate_first_dialogue_line(char_a: dict, bg_info: dict, is_cha1: bool = False) -> str:
    """
    ê°™ì€ ë°°ê²½/ì¸í„°ë™ì…˜ì—ì„œ char_aê°€ ë¨¼ì € í•œ ë§ˆë””ë¥¼ ìƒì„±.
    â†’ ì§§ê³  êµ¬ì–´ì²´.
    Avoid any narration or book-style phrases. The line must sound like spontaneous spoken Korean, not a written script.
    Add small hesitations (ì˜ˆ: 'ì•„...', 'ìŒ...') when appropriate, only if it fits the character.

    Args:
        char_a: ì²« ë²ˆì§¸ ìºë¦­í„° ì •ë³´ ë”•ì…”ë„ˆë¦¬
        bg_info: ë°°ê²½ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        is_cha1: Trueë©´ cha1, Falseë©´ cha2
    """
    place = bg_info.get("background", "")
    profile = get_interaction_profile(bg_info, char_a, is_cha1)
    # íŒŒì‹±ëœ interaction ì‚¬ìš© (ì—†ìœ¼ë©´ ì›ë³¸ ì‚¬ìš©)
    action = profile.get("interaction", bg_info.get("interaction", ""))
    emotion_list = "\n".join([f"  - {e}" for e in profile['emotion_options']])

    char_a_data = CHARACTERS.get(char_a['book_code'], {}).get(char_a['role_key'], {})
    char_a_speech = char_a_data.get('speech_patterns', {})
    char_a_style = char_a_speech.get('speaking_style', '')
    char_a_expressions = char_a_speech.get('frequent_expressions', [])[:15]
    char_a_endings = char_a_speech.get('endings_from_dialogues', [])[:10]
    char_a_words = char_a_speech.get('common_words', [])[:10]
    char_a_analysis = char_a_data.get('analysis_from_dialogues', {})
    
    system_a = (
        "ë‹¹ì‹ ì€ í•œêµ­ ì˜›ì´ì•¼ê¸° ì† ë“±ì¥ì¸ë¬¼ì´ ì‹¤ì œë¡œ ë§í•˜ëŠ” ëŒ€ì‚¬ë¥¼ ì“°ëŠ” ì‘ê°€ì…ë‹ˆë‹¤. "
        "ì²« ë²ˆì§¸ ì¸ë¬¼ì´ ë‹¤ë¥¸ ì¸ë¬¼(ë‘ ë²ˆì§¸ ì¸ë¬¼)ì—ê²Œ ë§ì„ ê±´ë„¤ëŠ” ì§§ì€ í•œ ë§ˆë””ë¥¼ ë§Œë“œì„¸ìš”. "
        "í˜¼ì£ë§ì´ ì•„ë‹ˆë¼ ìƒëŒ€ë°©ì—ê²Œ ë§ì„ ê±°ëŠ” ëŒ€í™”ì—¬ì•¼ í•©ë‹ˆë‹¤."
    )
    user_a = f"""
ë°°ê²½ ì¥ì†Œ: {place}
ë°°ê²½ ì¸í„°ë™ì…˜: {action}

ì¥ë©´ ë¶„ìœ„ê¸°:
- ìš”ì•½: {profile['summary']}
- ê°€ëŠ¥í•œ ê°ì •ë“¤ (ìºë¦­í„° ì„±ê²©ì— ë§ëŠ” ê²ƒì„ ì„ íƒí•˜ì„¸ìš”):
{emotion_list}

ì²« ë²ˆì§¸ ì¸ë¬¼ ì„¤ì •(ì˜ì–´): {char_a['personality']}
ì²« ë²ˆì§¸ ì¸ë¬¼ ì •ë³´: {char_a['age']}ì‚´ {char_a['gender']}
ì²« ë²ˆì§¸ ì¸ë¬¼ ë§íˆ¬ ìŠ¤íƒ€ì¼: {char_a_style}

ì²« ë²ˆì§¸ ì¸ë¬¼ ë§íˆ¬ íŠ¹ì§• (ì‹¤ì œ ëŒ€ì‚¬ ë¶„ì„ ê²°ê³¼):
{f"- ìì£¼ ì‚¬ìš©í•˜ëŠ” í‘œí˜„: {', '.join(char_a_expressions) if char_a_expressions else 'ì—†ìŒ'}"}
{f"- ì‹¤ì œ ëŒ€ì‚¬ì—ì„œ ìì£¼ ì“°ëŠ” ì–´ë¯¸: {', '.join(char_a_endings) if char_a_endings else 'ì—†ìŒ'}"}
{f"- ìì£¼ ì‚¬ìš©í•˜ëŠ” ë‹¨ì–´: {', '.join(char_a_words) if char_a_words else 'ì—†ìŒ'}"}

ìƒí™©:
- ì²« ë²ˆì§¸ ì¸ë¬¼ì´ '{action}' ì¥ë©´ ì†ì—ì„œ ìœ„ ê°ì • ì¤‘ ìì‹ ì˜ ì„±ê²©ì— ë§ëŠ” ê²ƒì„ ëŠë¼ë©° ì§§ê²Œ ë§í•©ë‹ˆë‹¤.
- í˜¼ì£ë§ì´ ì•„ë‹ˆë¼, ê°™ì€ ì¥ë©´ì— ìˆëŠ” ë‘ ë²ˆì§¸ ì¸ë¬¼ì—ê²Œ ë§ì„ ê±°ëŠ” ëŒ€í™”ì…ë‹ˆë‹¤.
- ë‘ ë²ˆì§¸ ì¸ë¬¼ì´ ë“£ê³  ë°˜ì‘í•  ìˆ˜ ìˆë„ë¡, ì§ˆë¬¸ì´ë‚˜ ì œì•ˆ, ê´€ì°° ë“±ì„ í¬í•¨í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
- ë°°ê²½ ì¥ì†Œì™€ ì¸í„°ë™ì…˜ì„ ê³ ë ¤í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê³  ë§¥ë½ì— ë§ëŠ” ëŒ€ì‚¬ë¥¼ ìƒì„±í•˜ì„¸ìš”.
- ì˜ˆë¥¼ ë“¤ì–´, í† ë¼ ê°™ì€ ì¥ë‚œê¾¸ëŸ¬ê¸° ìºë¦­í„°ëŠ” 'ê³ ë°±í•  ê¸°íšŒ' ê°™ì€ ì´ìƒí•œ í‘œí˜„ì„ ì“°ì§€ ë§ê³ , 
  í˜„ì¬ ìƒí™©ê³¼ ë°°ê²½ì— ë§ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ë§ì„ ì‚¬ìš©í•˜ì„¸ìš”.

ë§íˆ¬ ê·œì¹™:
- ìœ„ì˜ "ì²« ë²ˆì§¸ ì¸ë¬¼ ë§íˆ¬ íŠ¹ì§•"ì— ë‚˜ì˜¨ ì‹¤ì œ ëŒ€ì‚¬ ë¶„ì„ ê²°ê³¼ë¥¼ ë°˜ë“œì‹œ ì°¸ê³ í•˜ì—¬ ë§íˆ¬ë¥¼ ì •í™•íˆ ì¬í˜„í•˜ì„¸ìš”.
- ìì£¼ ì‚¬ìš©í•˜ëŠ” í‘œí˜„ê³¼ ì–´ë¯¸ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í™œìš©í•˜ì„¸ìš”.
- ë¬¸ì–´ì²´(ì˜ˆ: '~ê²ƒì´ë‹¤', '~í•©ë‹ˆë‹¤') ëŒ€ì‹  ìì—°ìŠ¤ëŸ¬ìš´ êµ¬ì–´ì²´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
- ìºë¦­í„°ì˜ ë§íˆ¬ ìŠ¤íƒ€ì¼ì„ ì •í™•íˆ ë”°ë¥´ì„¸ìš”. íŠ¹íˆ '~ì´ê¸°ì•¼' ê°™ì€ ë¹„ë¬¸ë²•ì  í‘œí˜„ì„ ì“°ì§€ ë§ê³  '~ì´ì§€' ê°™ì€ ì˜¬ë°”ë¥¸ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”.
- '~ì´ê¸°ì—ìš”' ê°™ì€ ë¹„ë¬¸ë²•ì  í‘œí˜„ì„ ì“°ì§€ ë§ê³  '~ì´ì—ìš”' ê°™ì€ ì˜¬ë°”ë¥¸ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”.
- ë§¥ë½ì— ë§ì§€ ì•ŠëŠ” ì´ìƒí•œ í‘œí˜„(ì˜ˆ: 'ê³ ë°±í•  ê¸°íšŒ', 'ì•„ë²„ì§€í•œí…Œ ê³ ë°±' ë“±)ì„ í”¼í•˜ê³ , 
  í˜„ì¬ ë°°ê²½ê³¼ ì¸í„°ë™ì…˜ì— ìì—°ìŠ¤ëŸ½ê²Œ ì–´ìš¸ë¦¬ëŠ” ëŒ€ì‚¬ë¥¼ ìƒì„±í•˜ì„¸ìš”.
- ìµœëŒ€í•œ ì§§ê³  ê°„ë‹¨í•˜ê²Œ, ì¼ìƒ ëŒ€í™”ì²˜ëŸ¼. (ì˜ˆ: '~í• ê¹Œ?', '~í•˜ëŠ” ê±°ì§€', '~ê°™ì€ë°' ë“±)
- í•œ ë¬¸ì¥ë§Œ, 1~2ì´ˆì— ë§í•  ìˆ˜ ìˆëŠ” ê¸¸ì´.
- ë”°ì˜´í‘œëŠ” ì“°ì§€ ë§ˆì„¸ìš”.
"""
    resp_a = client.responses.create(
        model=TEXT_MODEL,
        input=[
            {"role": "system", "content": system_a},
            {"role": "user", "content": user_a}
        ],
        max_output_tokens=50,
        temperature=0.7
    )
    line_a = _clean_line(resp_a.output_text)
    return line_a


def generate_second_dialogue_line(char_b: dict, line_a: str, bg_info: dict) -> str:
    """
    char_bê°€ char_aì˜ ë§(line_a)ì— ë°˜ì‘í•˜ëŠ” í•œ ë§ˆë””ë¥¼ ìƒì„±.
    â†’ ì§§ê³  êµ¬ì–´ì²´.
    """
    place = bg_info.get("background", "")
    action = bg_info.get("interaction", "")
    profile = get_interaction_profile(bg_info)
    emotion_list = "\n".join([f"  - {e}" for e in profile['emotion_options']])

    char_b_data = CHARACTERS.get(char_b['book_code'], {}).get(char_b['role_key'], {})
    char_b_speech = char_b_data.get('speech_patterns', {})
    char_b_style = char_b_speech.get('speaking_style', '')
    char_b_expressions = char_b_speech.get('frequent_expressions', [])[:15]
    char_b_endings = char_b_speech.get('endings_from_dialogues', [])[:10]
    char_b_words = char_b_speech.get('common_words', [])[:10]
    char_b_analysis = char_b_data.get('analysis_from_dialogues', {})
    
    system_b = (
        "ë‹¹ì‹ ì€ í•œêµ­ ì˜›ì´ì•¼ê¸° ì† ë‘ ì¸ë¬¼ì´ ì‹¤ì œë¡œ ì£¼ê³ ë°›ëŠ” ëŒ€í™”ë¥¼ ì“°ëŠ” ì‘ê°€ì…ë‹ˆë‹¤. "
        "ë‘ ë²ˆì§¸ ì¸ë¬¼ì´ ì²« ë²ˆì§¸ ì¸ë¬¼ì˜ ë§ì„ ë“£ê³  ì§ì ‘ì ìœ¼ë¡œ ë°˜ì‘í•˜ëŠ” ì§§ì€ í•œ ë§ˆë””ë¥¼ ë§Œë“œì„¸ìš”. "
        "ë°˜ë“œì‹œ ì²« ë²ˆì§¸ ì¸ë¬¼ì—ê²Œ ë§ì„ ê±°ëŠ” ëŒ€ë‹µì´ì–´ì•¼ í•˜ë©°, í˜¼ì£ë§ì´ ì•„ë‹Œ ëŒ€í™”ì—¬ì•¼ í•©ë‹ˆë‹¤."
    )
    user_b = f"""
ë°°ê²½ ì¥ì†Œ: {place}
ë°°ê²½ ì¸í„°ë™ì…˜: {action}
ì¥ë©´ ë¶„ìœ„ê¸° ìš”ì•½: {profile['summary']}
ê°€ëŠ¥í•œ ê°ì •ë“¤ (ìºë¦­í„° ì„±ê²©ì— ë§ëŠ” ê²ƒì„ ì„ íƒí•˜ì„¸ìš”):
{emotion_list}

ì²« ë²ˆì§¸ ì¸ë¬¼ì˜ ë§:
"{line_a}"

ë‘ ë²ˆì§¸ ì¸ë¬¼ ì„¤ì •(ì˜ì–´): {char_b['personality']}
ë‘ ë²ˆì§¸ ì¸ë¬¼ ì •ë³´: {char_b['age']}ì‚´ {char_b['gender']}
ë‘ ë²ˆì§¸ ì¸ë¬¼ ë§íˆ¬ ìŠ¤íƒ€ì¼: {char_b_style}

ë‘ ë²ˆì§¸ ì¸ë¬¼ ë§íˆ¬ íŠ¹ì§• (ì‹¤ì œ ëŒ€ì‚¬ ë¶„ì„ ê²°ê³¼):
{f"- ìì£¼ ì‚¬ìš©í•˜ëŠ” í‘œí˜„: {', '.join(char_b_expressions) if char_b_expressions else 'ì—†ìŒ'}"}
{f"- ì‹¤ì œ ëŒ€ì‚¬ì—ì„œ ìì£¼ ì“°ëŠ” ì–´ë¯¸: {', '.join(char_b_endings) if char_b_endings else 'ì—†ìŒ'}"}
{f"- ìì£¼ ì‚¬ìš©í•˜ëŠ” ë‹¨ì–´: {', '.join(char_b_words) if char_b_words else 'ì—†ìŒ'}"}

ì¤‘ìš”í•œ ìƒí™©:
- ë‘ ë²ˆì§¸ ì¸ë¬¼ì€ ìœ„ì˜ ì²« ë²ˆì§¸ ì¸ë¬¼ì˜ ë§ì„ ì§ì ‘ ë“£ê³  ìˆìŠµë‹ˆë‹¤.
- ì²« ë²ˆì§¸ ì¸ë¬¼ì´ ë‘ ë²ˆì§¸ ì¸ë¬¼ì—ê²Œ ë§ì„ ê±´ë„¨ ê²ƒì— ëŒ€í•´, ë‘ ë²ˆì§¸ ì¸ë¬¼ì´ ì²« ë²ˆì§¸ ì¸ë¬¼ì—ê²Œ ì§ì ‘ ëŒ€ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.
- í˜¼ì£ë§ì´ ì•„ë‹ˆë¼ ì²« ë²ˆì§¸ ì¸ë¬¼ì—ê²Œ ë§ì„ ê±°ëŠ” ëŒ€í™”ì—¬ì•¼ í•©ë‹ˆë‹¤.
- ì²« ë²ˆì§¸ ì¸ë¬¼ì˜ ë§ì˜ ë‚´ìš©, í†¤, ì˜ë„ë¥¼ ê³ ë ¤í•˜ì—¬ ì ì ˆíˆ ë°˜ì‘í•˜ì„¸ìš”.
- ë™ì˜, ë°˜ë°•, ì§ˆë¬¸, ì œì•ˆ, ë†€ëŒ ë“± ì²« ë²ˆì§¸ ì¸ë¬¼ì˜ ë§ì— ëŒ€í•œ ìì—°ìŠ¤ëŸ¬ìš´ ë°˜ì‘ì„ ë³´ì—¬ì£¼ì„¸ìš”.
- ì²« ë²ˆì§¸ ì¸ë¬¼ì˜ ë§ì— ì§ì ‘ì ìœ¼ë¡œ ì‘ë‹µí•˜ëŠ” ëŠë‚Œì´ ê°•í•˜ê²Œ ë“œëŸ¬ë‚˜ì•¼ í•©ë‹ˆë‹¤.

ë§íˆ¬ ê·œì¹™:
- ìœ„ì˜ "ë‘ ë²ˆì§¸ ì¸ë¬¼ ë§íˆ¬ íŠ¹ì§•"ì— ë‚˜ì˜¨ ì‹¤ì œ ëŒ€ì‚¬ ë¶„ì„ ê²°ê³¼ë¥¼ ë°˜ë“œì‹œ ì°¸ê³ í•˜ì—¬ ë§íˆ¬ë¥¼ ì •í™•íˆ ì¬í˜„í•˜ì„¸ìš”.
- ìì£¼ ì‚¬ìš©í•˜ëŠ” í‘œí˜„ê³¼ ì–´ë¯¸ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í™œìš©í•˜ì„¸ìš”.
- ì²« ë²ˆì§¸ ì¸ë¬¼ì˜ ë§ì— ì§ì ‘ì ìœ¼ë¡œ ë°˜ì‘í•˜ëŠ” ëŒ€ë‹µì´ì–´ì•¼ í•©ë‹ˆë‹¤.
- ì²« ë²ˆì§¸ ì¸ë¬¼ì˜ ë§ì˜ ë‚´ìš©ì„ ì–¸ê¸‰í•˜ê±°ë‚˜ ì°¸ì¡°í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
- ì˜ˆ: ì²« ë²ˆì§¸ê°€ "~í• ê¹Œ?"ë¼ê³  ë¬¼ìœ¼ë©´ â†’ "ê·¸ë˜, í•´ë³´ì" / "ì•ˆ ë¼" / "~í•˜ëŠ” ê²Œ ì¢‹ê² ì–´" ë“±
- ì˜ˆ: ì²« ë²ˆì§¸ê°€ "~í•´ì•¼ í•´"ë¼ê³  ë§í•˜ë©´ â†’ "ë§ì•„" / "ê·¸ë ‡ì§€ ì•Šì•„" / "~í•˜ëŠ” ê²Œ ë‚˜ì„ ê²ƒ ê°™ì€ë°" ë“±
- ì˜ˆ: ì²« ë²ˆì§¸ê°€ "~í–ˆì–´"ë¼ê³  ë§í•˜ë©´ â†’ "ì •ë§?" / "ê·¸ë˜?" / "~í–ˆêµ¬ë‚˜" ë“±
- ë¬¸ì–´ì²´ ê¸ˆì§€, ìì—°ìŠ¤ëŸ¬ìš´ êµ¬ì–´ì²´ë§Œ. (ì˜ˆ: '~ì§€?', '~ì–ì•„', '~ë¼ë‹ˆê¹Œ', '~í•´ìš”' ë“±)
- ìºë¦­í„°ì˜ ë§íˆ¬ ìŠ¤íƒ€ì¼ì„ ì •í™•íˆ ë”°ë¥´ì„¸ìš”. íŠ¹íˆ '~ì´ê¸°ì•¼' ê°™ì€ ë¹„ë¬¸ë²•ì  í‘œí˜„ì„ ì“°ì§€ ë§ê³  '~ì´ì§€' ê°™ì€ ì˜¬ë°”ë¥¸ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”.
- '~ì´ê¸°ì—ìš”' ê°™ì€ ë¹„ë¬¸ë²•ì  í‘œí˜„ì„ ì“°ì§€ ë§ê³  '~ì´ì—ìš”' ê°™ì€ ì˜¬ë°”ë¥¸ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”.
- í•œ ë¬¸ì¥ë§Œ, ì§§ê²Œ.
- ë”°ì˜´í‘œëŠ” ì“°ì§€ ë§ˆì„¸ìš”.
"""
    resp_b = client.responses.create(
        model=TEXT_MODEL,
        input=[
            {"role": "system", "content": system_b},
            {"role": "user", "content": user_b}
        ],
        max_output_tokens=50,
        temperature=0.7
    )
    line_b = _clean_line(resp_b.output_text)
    return line_b


def generate_dialogue_lines(char_a: dict, char_b: dict, bg_info: dict) -> tuple[str, str]:
    """
    ê°™ì€ ë°°ê²½/ì¸í„°ë™ì…˜ì—ì„œ char_aê°€ ë¨¼ì € í•œ ë§ˆë””,
    char_bê°€ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì„œ í•œ ë§ˆë””.
    â†’ ë‘˜ ë‹¤ ì§§ê³  êµ¬ì–´ì²´.
    (í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€, í•˜ì§€ë§Œ ìˆœì°¨ ìƒì„±/ì¬ìƒì„ ìœ„í•´ generate_first_dialogue_lineê³¼ generate_second_dialogue_lineì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ê¶Œì¥)
    """
    line_a = generate_first_dialogue_line(char_a, bg_info)
    line_b = generate_second_dialogue_line(char_b, line_a, bg_info)
    return line_a, line_b


def generate_surprised_line(character: dict, bg_info: dict) -> str:
    """
    ë°°ê²½ì´ ê°‘ìê¸° ë°”ë€Œì—ˆì„ ë•Œ ë†€ë¼ëŠ” í•œ ë§ˆë””.
    â†’ ê°íƒ„ + ì§§ì€ êµ¬ì–´ì²´.
    """
    place = bg_info.get("background", "")
    action = bg_info.get("interaction", "")
    profile = get_interaction_profile(bg_info)
    emotion_list = "\n".join([f"  - {e}" for e in profile['emotion_options']])

    system = (
        "ë‹¹ì‹ ì€ í•œêµ­ ì˜›ì´ì•¼ê¸° ì† ë“±ì¥ì¸ë¬¼ì´ ê°‘ìê¸° ë‹¤ë¥¸ ì¥ì†Œë¡œ ì´ë™í–ˆì„ ë•Œì˜ ë°˜ì‘ì„ ì“°ëŠ” ì‘ê°€ì…ë‹ˆë‹¤. "
        "ì‹¤ì œ ì‚¬ëŒì´ ë†€ë¼ì„œ íˆ­ ë‚´ë±‰ëŠ” ì§§ì€ í•œêµ­ì–´ í•œ ë§ˆë””ë¥¼ ë§Œë“œì„¸ìš”."
    )

    # ìºë¦­í„°ì˜ speech_patterns ê°€ì ¸ì˜¤ê¸°
    char_data = CHARACTERS.get(character['book_code'], {}).get(character['role_key'], {})
    speech_patterns = char_data.get('speech_patterns', {})
    frequent_expressions = speech_patterns.get('frequent_expressions', [])[:15]
    endings_from_dialogues = speech_patterns.get('endings_from_dialogues', [])[:10]
    common_words = speech_patterns.get('common_words', [])[:10]
    speaking_style = speech_patterns.get('speaking_style', '')
    analysis = char_data.get('analysis_from_dialogues', {})

    user = f"""
ìƒˆ ë°°ê²½ ì¥ì†Œ: {place}
ìƒˆ ë°°ê²½ ì¸í„°ë™ì…˜: {action}
ì¥ë©´ ë¶„ìœ„ê¸° ìš”ì•½: {profile['summary']}
ê°€ëŠ¥í•œ ê°ì •ë“¤ (ìºë¦­í„° ì„±ê²©ì— ë§ëŠ” ê²ƒì„ ì„ íƒí•˜ì„¸ìš”):
{emotion_list}

ìºë¦­í„° ì„¤ì •(ì˜ì–´): {character['personality']}
ìºë¦­í„° ì •ë³´: {character['age']}ì‚´ {character['gender']}
ìºë¦­í„° ë§íˆ¬ ìŠ¤íƒ€ì¼: {speaking_style}

ìºë¦­í„° ë§íˆ¬ íŠ¹ì§• (ì‹¤ì œ ëŒ€ì‚¬ ë¶„ì„ ê²°ê³¼):
{f"- ìì£¼ ì‚¬ìš©í•˜ëŠ” í‘œí˜„: {', '.join(frequent_expressions) if frequent_expressions else 'ì—†ìŒ'}"}
{f"- ì‹¤ì œ ëŒ€ì‚¬ì—ì„œ ìì£¼ ì“°ëŠ” ì–´ë¯¸: {', '.join(endings_from_dialogues) if endings_from_dialogues else 'ì—†ìŒ'}"}
{f"- ìì£¼ ì‚¬ìš©í•˜ëŠ” ë‹¨ì–´: {', '.join(common_words) if common_words else 'ì—†ìŒ'}"}

ìƒí™©:
- ì´ ìºë¦­í„°ëŠ” ë°©ê¸ˆ ì „ê¹Œì§€ ì „í˜€ ë‹¤ë¥¸ ê³³ì— ìˆì—ˆëŠ”ë°,
  ê°‘ìê¸° ì´ ì¥ë©´ìœ¼ë¡œ ìˆœê°„ì´ë™í•˜ë“¯ ì˜®ê²¨ì¡ŒìŠµë‹ˆë‹¤.
- ìœ„ ê°ì • ì¤‘ ìì‹ ì˜ ì„±ê²©ì— ë§ëŠ” ê²ƒì„ ëŠë¼ë©°, ë†€ë¼ê±°ë‚˜ ë‹¹í™©í•˜ê±°ë‚˜ ì‹ ê¸°í•´ì„œ ê°íƒ„ê³¼ í•¨ê»˜ í•œ ë§ˆë””ë¥¼ í•©ë‹ˆë‹¤.
- ë°°ê²½ ì¥ì†Œì™€ ì¸í„°ë™ì…˜ì„ íŒŒì•…í•˜ê³ , ì´ê³³ì—ì„œ ë¬´ìŠ¨ ì¼ì´ ì¼ì–´ë‚˜ëŠ”ì§€ ì´í•´í•œ í›„ ë†€ë¼ì›€ì„ í‘œí˜„í•©ë‹ˆë‹¤.

ë§íˆ¬ ê·œì¹™:
- ìœ„ì˜ "ìºë¦­í„° ë§íˆ¬ íŠ¹ì§•"ì— ë‚˜ì˜¨ ì‹¤ì œ ëŒ€ì‚¬ ë¶„ì„ ê²°ê³¼ë¥¼ ë°˜ë“œì‹œ ì°¸ê³ í•˜ì—¬ ë§íˆ¬ë¥¼ ì •í™•íˆ ì¬í˜„í•˜ì„¸ìš”.
- ìì£¼ ì‚¬ìš©í•˜ëŠ” í‘œí˜„ê³¼ ì–´ë¯¸ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í™œìš©í•˜ì„¸ìš”.
- ì´ ìºë¦­í„°ì˜ ì„±ê²©ê³¼ ë§íˆ¬ ìŠ¤íƒ€ì¼ì— ë§ëŠ” êµ¬ì²´ì ì¸ ê°íƒ„ì‚¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
  ì˜ˆ: ê²ë§ì€ ìºë¦­í„°ëŠ” 'ì–´? ì—¬ê¸°ê°€ ì–´ë””ì§€?', 'ë¬´ì„œìš´ ê³³ì´ë„¤...', 'ì´ìƒí•œ ê³³ì— ì™”ì–´' ë“±
      ìš©ê°í•œ ìºë¦­í„°ëŠ” 'ì˜¤? ì´ê³³ì´ ë°”ë¡œ ê·¸ ê³³ì¸ê°€?', 'í , ì—¬ê¸°ì„œ ë­˜ í•´ì•¼ í•˜ì§€?', 'ë­ì§€, ì´ ë¶„ìœ„ê¸°ëŠ”?' ë“±
      ì¥ë‚œê¾¸ëŸ¬ê¸°ëŠ” 'ì–´? ì´ê±° ì¬ë°Œê² ëŠ”ë°!', 'ì˜¤í˜¸, ì—¬ê¸°ì„œ ë­˜ í•  ìˆ˜ ìˆì„ê¹Œ?', 'ì´ëŸ° ê³³ì´ ìˆì—ˆêµ¬ë‚˜!' ë“±
      ì°¨ë¶„í•œ ìºë¦­í„°ëŠ” 'ì–´ë¼, ì—¬ê¸°ê°€ ì–´ë””ì¼ê¹Œ?', 'ì´ìƒí•˜ë„¤, ë¶„ìœ„ê¸°ê°€ ë‹¬ë¼', 'ìŒ... ì´ê³³ì€ ë­”ê°€ íŠ¹ë³„í•´' ë“±
- 'ì–´ë¼, ì´ê²Œ ë¬´ìŠ¨ ì‹ ê¸°í•œ ì¼ì¸ê°€?', 'ì˜¤í˜¸, ì´ê±° ì¬ë°Œë„¤!' ê°™ì€ ì¼ë°˜ì ì¸ ë©˜íŠ¸ëŠ” í”¼í•˜ê³ , 
  í˜„ì¬ ë°°ê²½ ì¥ì†Œì™€ ì¸í„°ë™ì…˜ì„ êµ¬ì²´ì ìœ¼ë¡œ ì–¸ê¸‰í•˜ëŠ” ë†€ë¼ì›€ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”.
- ë°°ê²½ ì¥ì†Œë‚˜ ì¸í„°ë™ì…˜ì„ ì–¸ê¸‰í•˜ë©´ì„œ ë†€ë¼ì›€ì„ í‘œí˜„í•˜ì„¸ìš”.
- ë¬¸ì–´ì²´ ê¸ˆì§€, ìì—°ìŠ¤ëŸ¬ìš´ êµ¬ì–´ì²´.
- í•œ ë¬¸ì¥, ì ë‹¹í•œ ê¸¸ì´ (1~2ì´ˆì— ë§í•  ìˆ˜ ìˆëŠ” ê¸¸ì´).
- ë”°ì˜´í‘œëŠ” ì“°ì§€ ë§ˆì„¸ìš”.
"""

    resp = client.responses.create(
        model=TEXT_MODEL,
        input=[
            {"role": "system", "content": system},
            {"role": "user", "content": user}
        ],
        max_output_tokens=40,
        temperature=0.7
    )
    return _clean_line(resp.output_text)


def generate_sisters_two_lines(sisters: dict, bg_info: dict) -> tuple[str, str]:
    place = bg_info.get("background", "")
    action = bg_info.get("interaction", "")
    profile = get_interaction_profile(bg_info)
    emotion_list = "\n".join([f"  - {e}" for e in profile['emotion_options']])

    system = (
        "ë‹¹ì‹ ì€ í•œêµ­ ì˜›ì´ì•¼ê¸° 'ì¥í™”í™ë ¨ì „'ì˜ ìë§¤ê°€ ì‹¤ì œë¡œ ì£¼ê³ ë°›ëŠ” ëŒ€ì‚¬ë¥¼ ì“°ëŠ” ì‘ê°€ì…ë‹ˆë‹¤. "
        "ì–¸ë‹ˆì™€ ë™ìƒì´ ì„œë¡œì—ê²Œ í•˜ëŠ” ì§§ì€ êµ¬ì–´ì²´ í•œ ë§ˆë””ì”©, ë‘ ë¬¸ì¥ì„ ë§Œë“œì„¸ìš”."
    )

    user = f"""
ë°°ê²½ ì¥ì†Œ: {place}
ë°°ê²½ ì¸í„°ë™ì…˜: {action}

ì¥ë©´ ë¶„ìœ„ê¸°:
- ìš”ì•½: {profile['summary']}
- ê°€ëŠ¥í•œ ê°ì •ë“¤ (ê° ìë§¤ì˜ ì„±ê²©ì— ë§ëŠ” ê²ƒì„ ì„ íƒí•˜ì„¸ìš”):
{emotion_list}

ìë§¤ ì„¤ì •(ì˜ì–´): {sisters['personality']}
ìë§¤ ì •ë³´: {sisters['age']}ì‚´ {sisters['gender']}

ì¶œë ¥ ê·œì¹™:
- ì²« ë²ˆì§¸ ì¤„: ì–¸ë‹ˆê°€ ë™ìƒì—ê²Œ ë§í•©ë‹ˆë‹¤. ë°˜ë“œì‹œ 'í™ë ¨ì•„' í¬í•¨.
- ë‘ ë²ˆì§¸ ì¤„: ë™ìƒì´ ì–¸ë‹ˆì—ê²Œ ë§í•©ë‹ˆë‹¤. ë°˜ë“œì‹œ 'ì–¸ë‹ˆ' í¬í•¨.
- ë‘ ë¬¸ì¥ ëª¨ë‘ ìì—°ìŠ¤ëŸ¬ìš´ êµ¬ì–´ì²´ì—¬ì•¼ í•©ë‹ˆë‹¤. (ì˜ˆ: '~ê±°ì•¼', '~í•˜ì§€ ë§ˆ', '~í•´ë³¼ê¹Œ' ë“±)
- íŠ¹íˆ '~ì´ê¸°ì•¼' ê°™ì€ ë¹„ë¬¸ë²•ì  í‘œí˜„ì„ ì“°ì§€ ë§ê³  '~ì´ì§€' ê°™ì€ ì˜¬ë°”ë¥¸ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”.
- ë¬¸ì–´ì²´ ê¸ˆì§€, ì„¤ëª… ê¸ˆì§€.
- ê°ê° í•œ ë¬¸ì¥ì”©ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
"""

    resp = client.responses.create(
        model=TEXT_MODEL,
        input=[
            {"role": "system", "content": system},
            {"role": "user", "content": user}
        ],
        max_output_tokens=80,
        temperature=0.7
    )

    lines = [l.strip() for l in resp.output_text.splitlines() if l.strip()]
    if len(lines) >= 2:
        return _clean_line(lines[0]), _clean_line(lines[1])
    elif len(lines) == 1:
        return _clean_line(lines[0]), "ì–¸ë‹ˆ, ë‚˜ë„ ê·¸ëŸ° ê¸°ë¶„ì´ì•¼."
    else:
        return "í™ë ¨ì•„, ë„ˆë¬´ ê±±ì •í•˜ì§€ ë§ˆ.", "ì–¸ë‹ˆ, ê·¸ë˜ë„ ì¢€ ë¬´ì„œì›Œ."


# ============================================
# 5. TTS
# ============================================
def apply_audio_effects(character: dict, input_path: str, output_path: str):
    """
    ìºë¦­í„°ì— ë§ëŠ” ì˜¤ë””ì˜¤ íš¨ê³¼ë¥¼ ì ìš©í•©ë‹ˆë‹¤.
    ì´ í•¨ìˆ˜ëŠ” tts.pyì™€ test_character_voice.pyì—ì„œ ê³µí†µìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.
    ëª¨ë“  ìºë¦­í„°ì˜ ìŒëŸ‰ì„ ë™ì¼í•˜ê²Œ ì •ê·œí™”í•©ë‹ˆë‹¤.
    
    Args:
        character: ìºë¦­í„° ì •ë³´ ë”•ì…”ë„ˆë¦¬ (book_code, role_key í¬í•¨)
        input_path: ì›ë³¸ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        output_path: íš¨ê³¼ê°€ ì ìš©ëœ ì˜¤ë””ì˜¤ íŒŒì¼ ì €ì¥ ê²½ë¡œ
    """
    book_code = character.get("book_code", "")
    role_key = character.get("role_key", "")
    
    # ìŒëŸ‰ ì •ê·œí™”ë¥¼ ìœ„í•œ ì„ì‹œ íŒŒì¼ ê²½ë¡œ
    import tempfile
    temp_dir = tempfile.gettempdir()
    temp_normalized = os.path.join(temp_dir, f"normalized_{os.getpid()}_{id(character)}.wav")
    
    if (book_code == "JHHRJ" and role_key == "ghost") or (book_code == "KWJ" and role_key == "monster"):
        # reverb íš¨ê³¼ ì ìš© (aecho í•„í„° ì‚¬ìš©)
        # ghostì˜ ê²½ìš°: êµ¬ìŠ¬í”„ê³  ìš°ìš¸í•˜ì§€ë§Œ ìì—°ìŠ¤ëŸ¬ìš´ ì²˜ë…€ê·€ì‹  ëª©ì†Œë¦¬
        if book_code == "JHHRJ" and role_key == "ghost":
            # ghost: êµ¬ìŠ¬í”„ê³  ìš°ìš¸í•˜ê³  í•œì´ ì„œë¦° ì²˜ë…€ê·€ì‹  ëª©ì†Œë¦¬
            # íš¨ê³¼: ìì—°ìŠ¤ëŸ¬ìš´ reverb + ì•½ê°„ì˜ pitch ì¡°ì • (ì–´ë‘¡ê³  ìš°ìš¸) + ê³ ì£¼íŒŒ í•„í„°ë§ + equalizer
            # tremoloì™€ delay ì œê±°í•˜ì—¬ ìŒì„±ë³€ì¡° ëŠë‚Œ ìµœì†Œí™”
            audio_filter = (
                "lowpass=f=4000,"
                "aecho=0.8:0.7:80:0.3,"
                "equalizer=f=200:width_type=h:width=300:g=1.5,"
                "equalizer=f=5000:width_type=h:width=2000:g=-2"
            )
            subprocess.run(
                ["ffmpeg", "-y", "-i", input_path,
                 "-af", audio_filter,
                 output_path],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
                check=True
            )
        else:
            # monster: ì¤‘í›„í•˜ê³  ë¬´ê²Œê° ìˆëŠ” ê´´ë¬¼ ëª©ì†Œë¦¬ íš¨ê³¼
            # íš¨ê³¼: ë§¤ìš° ë‚®ì€ í”¼ì¹˜ + ê°•í•œ ë¦¬ë²„ë¸Œ/ì—ì½” + ì €ì£¼íŒŒ ê°•ì¡° + ì¤‘í›„í•œ ëŠë‚Œ
            # 1ë‹¨ê³„: í”¼ì¹˜ë¥¼ ë§¤ìš° ë‚®ì¶¤ (ì†ë„ë¥¼ 0.65ë°°ë¡œ ë‚®ì¶°ì„œ í”¼ì¹˜ ë‚®ì¶¤ - ë” ì¤‘í›„í•˜ê²Œ)
            temp_pitch = os.path.join(os.path.dirname(output_path), f"monster_pitch_{os.getpid()}.wav")
            subprocess.run(
                ["ffmpeg", "-y", "-i", input_path,
                 "-af", "atempo=0.65,asetrate=44100*0.65,aresample=44100",
                 temp_pitch],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
                check=True
            )
            # 2ë‹¨ê³„: ì¤‘í›„í•˜ê³  ë¬´ê²Œê° ìˆëŠ” íš¨ê³¼ ì ìš©
            audio_filter = (
                "equalizer=f=60:width_type=h:width=80:g=10,"  # ë§¤ìš° ë‚®ì€ ì €ì£¼íŒŒ ê°•ì¡° (ê¹Šê³  ì¤‘í›„í•œ ëŠë‚Œ)
                "equalizer=f=120:width_type=h:width=150:g=8,"  # ì €ì£¼íŒŒ ê°•ì¡° (ë¬´ê²Œê°)
                "equalizer=f=250:width_type=h:width=200:g=6,"  # ì¤‘ì €ì£¼íŒŒ ê°•ì¡° (ì¤‘í›„í•¨)
                "equalizer=f=4000:width_type=h:width=3000:g=-5,"  # ê³ ì£¼íŒŒ ì–µì œ (ì–´ë‘¡ê³  ë¬´ê±°ìš´ ëŠë‚Œ)
                "equalizer=f=6000:width_type=h:width=2000:g=-6,"  # ë” ë†’ì€ ê³ ì£¼íŒŒ ì–µì œ
                "lowpass=f=2500,"  # ê³ ì£¼íŒŒ í•„í„°ë§ (ë” ì–´ë‘¡ê²Œ)
                "aecho=0.95:0.95:120:0.6,"  # ë§¤ìš° ê°•í•œ ë¦¬ë²„ë¸Œ (ì¤‘í›„í•œ ê³µê°„ê°)
                #"aecho=0.8:0.8:250:0.4,"  # ì¶”ê°€ ë¦¬ë²„ë¸Œ ë ˆì´ì–´ (ê¹Šì€ ê³µê°„ê°)
                #"aecho=0.6:0.6:400:0.2"  # ë” ê¸´ ë¦¬ë²„ë¸Œ (ì¤‘í›„í•œ ëŠë‚Œ)
            )
            subprocess.run(
                ["ffmpeg", "-y", "-i", temp_pitch,
                 "-af", audio_filter,
                 output_path],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
                check=True
            )
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            try:
                os.remove(temp_pitch)
            except:
                pass
    elif book_code == "SCJ" and role_key == "simcheong":
        # ì‹¬ì²­: ì–´ë¦¬ê³  ëª…ë‘í•˜ê³  ê²°ì—°ì— ê°€ë“ ì°¬ ëª©ì†Œë¦¬
        # íš¨ê³¼: ë†’ì€ pitch (ì–´ë¦¬ê³  ë°ê²Œ) + ë¹ ë¥¸ ì†ë„ (ëª…ë‘í•¨) + ê³ ì£¼íŒŒ ê°•ì¡° (ë§‘ê³  ë°ê²Œ) + vibrato (ìƒë™ê°) + ì €ì£¼íŒŒ ì–µì œ (ê°€ë³ê³  ë°ê²Œ)
        audio_filter = (
            "equalizer=f=3000:width_type=h:width=2000:g=3,"  # ê³ ì£¼íŒŒ ê°•ì¡° (ë§‘ê³  ë°ê²Œ)
            "equalizer=f=5000:width_type=h:width=1500:g=2,"  # ë” ë†’ì€ ê³ ì£¼íŒŒ ê°•ì¡° (ëª…ë‘í•¨)
            "equalizer=f=200:width_type=h:width=300:g=-2,"  # ì €ì£¼íŒŒ ì–µì œ (ê°€ë³ê³  ë°ê²Œ)
            "vibrato=f=5.5:d=0.15,"  # ì•½ê°„ì˜ vibrato (ìƒë™ê°ê³¼ ê²°ì—°í•¨)
            "highpass=f=100"  # ë§¤ìš° ë‚®ì€ ì£¼íŒŒìˆ˜ ì œê±° (ë” ë§‘ê²Œ)
        )
        subprocess.run(
            ["ffmpeg", "-y", "-i", input_path,
             "-af", audio_filter,
             output_path],
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL,
            check=True
        )
    elif book_code == "DGJ":
        if role_key == "fox":
            # ì—¬ìš°: êµí™œí•˜ê³  ë§¤ìš° ê°€ëŠ” ëª©ì†Œë¦¬, ê°„ì‹ ë°° ëŠë‚Œ, ì˜ë‚œì²´
            # pitchë¥¼ ë” ì˜¬ë ¤ì„œ ë§¤ìš° ê°€ëŠ˜ê²Œ, tremolo ì¶”ê°€, ê³ ì£¼íŒŒ ê°•ì¡°ë¡œ ë” ê°€ëŠ” ëŠë‚Œ
            audio_filter = (
                "aresample=44100,"  # pitchë¥¼ 30% ì˜¬ë ¤ì„œ ë” ê°€ëŠ˜ê²Œ
                "equalizer=f=3000:width_type=h:width=2000:g=3,"  # ê³ ì£¼íŒŒ ê°•ì¡° (ê°€ëŠ” ëŠë‚Œ)
                "equalizer=f=5000:width_type=h:width=1500:g=2,"  # ë” ë†’ì€ ê³ ì£¼íŒŒ ê°•ì¡°
                "equalizer=f=200:width_type=h:width=300:g=-2,"  # ì €ì£¼íŒŒ ì–µì œ (ê°€ë³ê³  ê°€ëŠ” ëŠë‚Œ)
                "tremolo=f=3.0:d=0.2"  # tremoloë¡œ êµí™œí•œ ëŠë‚Œ
            )
            subprocess.run(
                ["ffmpeg", "-y", "-i", input_path,
                 "-af", audio_filter,
                 output_path],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
                check=True
            )
        elif role_key == "toad":
            # ë‘êº¼ë¹„: í˜„ëª…í•˜ê³  ì´ëª…í•˜ê³  ë­‰íˆ­í•˜ê³  ë¬µì§í•œ ëª©ì†Œë¦¬
            # pitchë¥¼ ì•½ê°„ ë‚®ì¶°ì„œ ë” ë¬µì§í•˜ê²Œ, bass boostë¡œ ë” ê¹Šê³  ë­‰íˆ­í•œ ëŠë‚Œ
            subprocess.run(
                ["ffmpeg", "-y", "-i", input_path,
                 "-af", "aresample=44100,equalizer=f=100:width_type=h:width=200:g=3",
                 output_path],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
                check=True
            )
        else:
            # ë‹¤ë¥¸ DGJ ìºë¦­í„°ëŠ” ì›ë³¸ ê·¸ëŒ€ë¡œ ì €ì¥
            import shutil
            shutil.copy2(input_path, output_path)
    elif book_code == "OGJJ" and role_key == "onggojip":
        # ì˜¹ê³ ì§‘: ë§¤ìš° ë‚˜ì´ë“  ë‚¨ì ëª©ì†Œë¦¬ (72ì„¸)
        # íš¨ê³¼: ì €ì£¼íŒŒ ê°•ì¡° (ê¹Šê³  ì¤‘í›„í•œ ëŠë‚Œ)
        audio_filter = (
            "equalizer=f=80:width_type=h:width=100:g=4,"  # ë§¤ìš° ë‚®ì€ ì €ì£¼íŒŒ ê°•ì¡° (ê¹Šê³  ë‚˜ì´ë“  ëŠë‚Œ)
            "equalizer=f=150:width_type=h:width=200:g=3,"  # ì €ì£¼íŒŒ ê°•ì¡° (ì¤‘í›„í•¨)
            "equalizer=f=300:width_type=h:width=250:g=2,"  # ì¤‘ì €ì£¼íŒŒ ê°•ì¡° (ê¹Šì€ ëª©ì†Œë¦¬)
            "equalizer=f=4000:width_type=h:width=3000:g=-3,"  # ê³ ì£¼íŒŒ ì•½ê°„ ì–µì œ (ë‚˜ì´ë“  ëŠë‚Œ)
            "lowpass=f=3500"  # ê³ ì£¼íŒŒ í•„í„°ë§ (ë‚˜ì´ë“  ëŠë‚Œ)
        )
        subprocess.run(
            ["ffmpeg", "-y", "-i", input_path,
             "-af", audio_filter,
             output_path],
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL,
            check=True
        )
    elif book_code == "HBJ" and role_key == "nolbu":
        # ë†€ë¶€: ë‚˜ì´ë“  ë‚¨ì ëª©ì†Œë¦¬ (58ì„¸)
        # íš¨ê³¼: ì €ì£¼íŒŒ ê°•ì¡° (ê¹Šê³  ì¤‘í›„í•œ ëŠë‚Œ)
        audio_filter = (
            "equalizer=f=80:width_type=h:width=100:g=4,"  # ë§¤ìš° ë‚®ì€ ì €ì£¼íŒŒ ê°•ì¡° (ê¹Šê³  ë‚˜ì´ë“  ëŠë‚Œ)
            "equalizer=f=150:width_type=h:width=200:g=3,"  # ì €ì£¼íŒŒ ê°•ì¡° (ì¤‘í›„í•¨)
            "equalizer=f=300:width_type=h:width=250:g=2,"  # ì¤‘ì €ì£¼íŒŒ ê°•ì¡° (ê¹Šì€ ëª©ì†Œë¦¬)
            "equalizer=f=4000:width_type=h:width=3000:g=-3,"  # ê³ ì£¼íŒŒ ì•½ê°„ ì–µì œ (ë‚˜ì´ë“  ëŠë‚Œ)
            "lowpass=f=3500"  # ê³ ì£¼íŒŒ í•„í„°ë§ (ë‚˜ì´ë“  ëŠë‚Œ)
        )
        subprocess.run(
            ["ffmpeg", "-y", "-i", input_path,
             "-af", audio_filter,
             output_path],
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL,
            check=True
        )
    else:
        # ì¼ë°˜ ìºë¦­í„°ëŠ” ì›ë³¸ ê·¸ëŒ€ë¡œ ì €ì¥
        import shutil
        shutil.copy2(input_path, output_path)
    
    # ëª¨ë“  ìºë¦­í„°ì— ëŒ€í•´ ìŒëŸ‰ ì •ê·œí™” ì ìš© (íš¨ê³¼ ì ìš© í›„)
    # loudnorm í•„í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  ì˜¤ë””ì˜¤ì˜ ìŒëŸ‰ì„ ë™ì¼í•˜ê²Œ ë§ì¶¤
    try:
        subprocess.run(
            ["ffmpeg", "-y", "-i", output_path,
             "-af", "loudnorm=I=-16:TP=-1.5:LRA=11",
             temp_normalized],
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL,
            check=True,
            timeout=10
        )
        # ì •ê·œí™”ëœ íŒŒì¼ì„ ìµœì¢… ì¶œë ¥ ê²½ë¡œë¡œ ë³µì‚¬
        import shutil
        shutil.move(temp_normalized, output_path)
    except Exception as e:
        # ìŒëŸ‰ ì •ê·œí™” ì‹¤íŒ¨ ì‹œ ì›ë³¸ íŒŒì¼ ì‚¬ìš© (ì˜¤ë¥˜ ë¬´ì‹œ)
        try:
            if os.path.exists(temp_normalized):
                os.remove(temp_normalized)
        except:
            pass


def generate_tts(character: dict, text: str, output_path: str):
    """
    TTSë¥¼ ìƒì„±í•˜ê³  ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    output_pathëŠ” í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€í•˜ì§€ë§Œ ì‹¤ì œë¡œëŠ” ì„ì‹œ íŒŒì¼ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    ë°˜í™˜ê°’: (ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ, ì˜ì–´ ë²ˆì—­ í…ìŠ¤íŠ¸, ìºë¦­í„° ì´ë¦„)
    """
    speaker_tag = f"{character['book_code'].upper()}-{character['role_key'].upper()}"
    
    # ìºë¦­í„° ì´ë¦„ ê°€ì ¸ì˜¤ê¸° (ì˜ì–´ë¡œ)
    role_key = character.get('role_key', '')
    # role_keyë¥¼ ì˜ì–´ ì´ë¦„ìœ¼ë¡œ ë³€í™˜
    character_name_map = {
        'simcheong': 'Simcheong', 'simbongsa': 'Simbongsa',
        'heungbu': 'Heungbu', 'nolbu': 'Nolbu',
        'turtle': 'Turtle', 'rabbit': 'Rabbit',
        'onggojip': 'Onggojip',
        'jeonwoochi': 'Jeonwoochi',
        'sister_older': 'Janghwa', 'sister_younger': 'Hongryeon', 'ghost': 'Ghost',
        'ugly': 'Ugly', 'pretty': 'Pretty',
        'toad': 'Toad', 'fox': 'Fox',
        'kimwon': 'Kimwon', 'monster': 'Monster'
    }
    character_name = character_name_map.get(role_key, role_key.capitalize())
    
    # ì˜ì–´ ë²ˆì—­ ìƒì„±
    english_text = ""
    try:
        translation_resp = client.responses.create(
            model=TEXT_MODEL,
            input=[
                {"role": "system", "content": "You are a translator. Translate the given Korean dialogue to natural English, preserving the character's tone and emotion."},
                {"role": "user", "content": f"Translate this Korean dialogue to English: {text}"}
            ],
            max_output_tokens=50,
            temperature=0.3
        )
        english_text = _clean_line(translation_resp.output_text)
        print(f"ğŸ¤ [{speaker_tag}] line: {text} | {english_text}")
    except Exception as e:
        print(f"ğŸ¤ [{speaker_tag}] line: {text}")
        print(f"âš ï¸ Translation failed: {e}")
        english_text = text  # ë²ˆì—­ ì‹¤íŒ¨ ì‹œ ì›ë¬¸ ì‚¬ìš©

    voice_speed = character.get("speed", 1.0)

    response = client.audio.speech.create(
        model=TTS_MODEL,
        voice=character["voice"],
        input=text,
        response_format="wav",
        speed=voice_speed
    )

    audio_bytes = response.read()

    # ì„ì‹œ íŒŒì¼ì— ì›ë³¸ ì˜¤ë””ì˜¤ ì €ì¥
    import tempfile
    import uuid
    temp_dir = tempfile.gettempdir()
    temp_input = os.path.join(temp_dir, f"tts_temp_{os.getpid()}_{uuid.uuid4().hex[:8]}.wav")
    with open(temp_input, "wb") as f:
        f.write(audio_bytes)
    
    # ìµœì¢… ì¶œë ¥ë„ ì„ì‹œ íŒŒì¼ë¡œ (ì¬ìƒ í›„ ì‚­ì œë¨)
    temp_output = os.path.join(temp_dir, f"tts_output_{os.getpid()}_{uuid.uuid4().hex[:8]}.wav")
    
    # íŠ¹ìˆ˜ ìºë¦­í„° ì˜¤ë””ì˜¤ íš¨ê³¼ ì ìš© (ê³µí†µ í•¨ìˆ˜ ì‚¬ìš©)
    apply_audio_effects(character, temp_input, temp_output)
    
    # ì„ì‹œ ì…ë ¥ íŒŒì¼ ì‚­ì œ
    try:
        os.remove(temp_input)
    except:
        pass

    return temp_output, english_text, character_name



def stop_all_audio():
    """ëª¨ë“  ì¬ìƒ ì¤‘ì¸ ì˜¤ë””ì˜¤ë¥¼ ì¦‰ì‹œ ì¤‘ë‹¨í•©ë‹ˆë‹¤."""
    global _current_audio_processes, _should_stop_audio
    # ì¤‘ë‹¨ í”Œë˜ê·¸ ì„¤ì • (play_audio_sequenceê°€ ë‹¤ìŒ ì˜¤ë””ì˜¤ë¥¼ ì¬ìƒí•˜ì§€ ì•Šë„ë¡)
    with _stop_audio_lock:
        _should_stop_audio = True
    
    # ì¶”ì  ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
    processes_to_kill = []
    with _audio_processes_lock:
        for process in _current_audio_processes:
            try:
                if process.poll() is None:  # í”„ë¡œì„¸ìŠ¤ê°€ ì•„ì§ ì‹¤í–‰ ì¤‘ì´ë©´
                    processes_to_kill.append(process)
            except:
                pass
        _current_audio_processes.clear()
    
    # í”„ë¡œì„¸ìŠ¤ ê°•ì œ ì¢…ë£Œ (terminate + kill)
    # ì£¼ì˜: bg_soundì™€ bg_musicì€ ë³„ë„ë¡œ ê´€ë¦¬ë˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” TTS í”„ë¡œì„¸ìŠ¤ë§Œ ì¢…ë£Œ
    for process in processes_to_kill:
        try:
            process.terminate()
            # ì¦‰ì‹œ kill (ëŒ€ê¸°í•˜ì§€ ì•ŠìŒ)
            try:
                process.kill()
            except:
                pass
        except:
            pass
    
    # ìë§‰ ì§€ìš°ê¸°
    VIDEO_PLAYER.clear_subtitle()
    
    # ì ì‹œ ëŒ€ê¸° í›„ í”Œë˜ê·¸ ë¦¬ì…‹ (ë‹¤ìŒ ì‹œí€€ìŠ¤ê°€ ì‹œì‘ë  ìˆ˜ ìˆë„ë¡)
    import time
    time.sleep(0.05)  # ëŒ€ê¸° ì‹œê°„ ë‹¨ì¶•
    with _stop_audio_lock:
        _should_stop_audio = False
    print("ğŸ”‡ ëª¨ë“  ì˜¤ë””ì˜¤ ì¤‘ë‹¨ë¨")

def play_audio(path: str, blocking: bool = False, subtitle_text: str = None):
    """
    ì˜¤ë””ì˜¤ë¥¼ ì¬ìƒí•©ë‹ˆë‹¤.
    
    Args:
        path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        blocking: Trueë©´ ë™ê¸°ì ìœ¼ë¡œ ì¬ìƒ (ë‹¤ìŒ ì˜¤ë””ì˜¤ê°€ ì¬ìƒ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°), Falseë©´ ë¹„ë™ê¸°ë¡œ ì¬ìƒ
        subtitle_text: ìë§‰ í…ìŠ¤íŠ¸ (ì˜ˆ: "toad: Haha")
    """
    # ì¤‘ë‹¨ í”Œë˜ê·¸ í™•ì¸
    with _stop_audio_lock:
        if _should_stop_audio:
            return  # ì¤‘ë‹¨ í”Œë˜ê·¸ê°€ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ ì¬ìƒí•˜ì§€ ì•ŠìŒ
    
    print(f"ğŸ”Š PLAY AUDIO: {path}")
    
    # ìë§‰ ì„¤ì •
    if subtitle_text:
        VIDEO_PLAYER.set_subtitle(subtitle_text)
    
    def play():
        import tempfile
        temp_dir = tempfile.gettempdir()
        is_temp_file = path.startswith(temp_dir)
        
        try:
            # ì¬ìƒ ì‹œì‘ ì „ ë‹¤ì‹œ í•œ ë²ˆ í™•ì¸
            with _stop_audio_lock:
                if _should_stop_audio:
                    # ì¤‘ë‹¨ëœ ê²½ìš° ì„ì‹œ íŒŒì¼ ì‚­ì œ
                    if is_temp_file:
                        try:
                            os.remove(path)
                        except:
                            pass
                    # ìë§‰ ì§€ìš°ê¸°
                    VIDEO_PLAYER.clear_subtitle()
                    return
            
            process = subprocess.Popen(
                ["afplay", path],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL
            )
            # í”„ë¡œì„¸ìŠ¤ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            with _audio_processes_lock:
                _current_audio_processes.append(process)
            
            process.wait()  # ì¬ìƒ ì™„ë£Œ ëŒ€ê¸°
            
            # ì¬ìƒ ì™„ë£Œ í›„ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì œê±°
            with _audio_processes_lock:
                if process in _current_audio_processes:
                    _current_audio_processes.remove(process)
            
            # ì¬ìƒ ì™„ë£Œ í›„ ìë§‰ ì§€ìš°ê¸°
            VIDEO_PLAYER.clear_subtitle()
            
            # ì¬ìƒ ì™„ë£Œ í›„ ì„ì‹œ íŒŒì¼ ì‚­ì œ
            if is_temp_file:
                try:
                    os.remove(path)
                except:
                    pass
        except Exception as e:
            print(f"âš ï¸ ì˜¤ë””ì˜¤ ì¬ìƒ ì˜¤ë¥˜: {e}")
            with _audio_processes_lock:
                if 'process' in locals() and process in _current_audio_processes:
                    _current_audio_processes.remove(process)
            # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹œë„
            if is_temp_file:
                try:
                    os.remove(path)
                except:
                    pass
    
    if blocking:
        # ë™ê¸°ì ìœ¼ë¡œ ì¬ìƒ (ìˆœì°¨ ì¬ìƒìš©)
        play()
    else:
        # ë¹„ë™ê¸°ë¡œ ì¬ìƒ
        threading.Thread(target=play, daemon=True).start()

def play_audio_sequence(paths: list[str], subtitles: list[str] = None):
    """
    ì—¬ëŸ¬ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ìˆœì°¨ì ìœ¼ë¡œ ì¬ìƒí•©ë‹ˆë‹¤ (ê²¹ì¹˜ì§€ ì•Šê²Œ).
    
    Args:
        paths: ì¬ìƒí•  ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        subtitles: ê° ì˜¤ë””ì˜¤ì— ëŒ€í•œ ìë§‰ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ìë§‰ ì—†ìŒ)
    """
    if subtitles is None:
        subtitles = [None] * len(paths)
    
    def play_sequence():
        for i, path in enumerate(paths):
            # ê° ì˜¤ë””ì˜¤ ì¬ìƒ ì „ì— ì¤‘ë‹¨ í”Œë˜ê·¸ í™•ì¸
            with _stop_audio_lock:
                if _should_stop_audio:
                    remaining = len(paths) - i
                    print(f"ğŸ”‡ ì˜¤ë””ì˜¤ ì‹œí€€ìŠ¤ ì¤‘ë‹¨ë¨ (ë‚¨ì€ íŒŒì¼: {remaining})")
                    VIDEO_PLAYER.clear_subtitle()  # ìë§‰ ì§€ìš°ê¸°
                    return  # ì¤‘ë‹¨ í”Œë˜ê·¸ê°€ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ ì‹œí€€ìŠ¤ ì¤‘ë‹¨
            
            if not os.path.exists(path):
                print(f"âš ï¸ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {path}")
                continue
            
            # ìë§‰ ì„¤ì •
            subtitle = subtitles[i] if i < len(subtitles) else None
            play_audio(path, blocking=True, subtitle_text=subtitle)
            
            # ì¬ìƒ í›„ì—ë„ ì¤‘ë‹¨ í”Œë˜ê·¸ í™•ì¸ (ë‹¤ìŒ ì˜¤ë””ì˜¤ë¡œ ë„˜ì–´ê°€ê¸° ì „)
            with _stop_audio_lock:
                if _should_stop_audio:
                    remaining = len(paths) - i - 1
                    print(f"ğŸ”‡ ì˜¤ë””ì˜¤ ì‹œí€€ìŠ¤ ì¤‘ë‹¨ë¨ (ë‚¨ì€ íŒŒì¼: {remaining})")
                    return  # ì¤‘ë‹¨ í”Œë˜ê·¸ê°€ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ ì‹œí€€ìŠ¤ ì¤‘ë‹¨
    
    # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ìˆœì°¨ ì¬ìƒ (ë‹¤ë¥¸ ì‘ì—…ì„ ë¸”ë¡œí‚¹í•˜ì§€ ì•ŠìŒ)
    threading.Thread(target=play_sequence, daemon=True).start()


# ============================================
# 6. ë©”ì¸ ì§„ì…ì : ì›¹ìº ì—ì„œ book_code + ìˆœì„œ ë„˜ê²¨ì¤„ ë•Œ
# ============================================
def handle_book_input(book_code: str, index_in_sequence: int):
    """
    index_in_sequence ê·œì¹™:

    1: ì´ˆê¸° ë°°ê²½ ì„¤ì •
    2: ì´ˆê¸° cha1 ë“±ì¥ + í•œ ì¤„ ëŒ€ì‚¬
    3: ì´ˆê¸° cha2 ë“±ì¥ + cha1/cha2 ëŒ€í™” (ê° í•œ ì¤„)

    ì´í›„ 4ë¶€í„°ëŠ” 3ê°œ ì£¼ê¸°ë¡œ ë°˜ë³µ:
    4,7,10,... : ë°°ê²½ë§Œ êµì²´ â†’ cha1/cha2 ë‘˜ ë‹¤ ë†€ë¼ëŠ” ëŒ€ì‚¬ í•œ ì¤„ì”©
    5,8,11,... : cha1 êµì²´     â†’ ìƒˆ cha1 + ê¸°ì¡´ cha2 ëŒ€í™” (ê° í•œ ì¤„)
                 (ë‹¨, ìƒˆ cha1ì´ ìë§¤ë©´ ì–¸ë‹ˆ/ë™ìƒ ë‘ ì¤„ + cha2 í•œ ì¤„)
    6,9,12,... : cha2 êµì²´     â†’ ê¸°ì¡´ cha1 + ìƒˆ cha2 ëŒ€í™” (ê° í•œ ì¤„)
    """
    global CURRENT_BG_BOOK_CODE, CURRENT_BG_INFO, CURRENT_CHA1_INFO, CURRENT_CHA2_INFO
    
    # ìƒˆ ë§ˆì»¤ ê°ì§€ ì‹œ ì¦‰ì‹œ ëª¨ë“  ì˜¤ë””ì˜¤ ì¤‘ë‹¨ (ê°€ì¥ ë¨¼ì € ì‹¤í–‰)
    stop_all_audio()

    print("\n==============================")
    print(f"[handle_book_input] book_code={book_code}, index={index_in_sequence}")
    

    # -------------------------
    # 1) index 1: ì´ˆê¸° ë°°ê²½
    # -------------------------
    if index_in_sequence == 1:
        # ì´ì „ ì§„í–‰ ìƒí™© ì¤‘ë‹¨: ëª¨ë“  ì˜¤ë””ì˜¤ ë° bgm ì¤‘ë‹¨
        stop_all_audio()
        stop_background_music()
        bg = get_background(book_code)
        if bg is None:
            print(f"âš  BACKGROUNDSì— ì—†ëŠ” book_code: {book_code}")
            return

        CURRENT_BG_BOOK_CODE = book_code
        CURRENT_BG_INFO = bg
        CURRENT_CHA1_INFO = None
        CURRENT_CHA2_INFO = None

        print(f"[BACKGROUND INIT] {book_code} â†’ {bg.get('background')}")
        play_background_video(book_code)  # ë°°ê²½ ë¹„ë””ì˜¤ ì¬ìƒ (ë¬´í•œ ë£¨í”„, ì˜¤ë””ì˜¤ í¬í•¨)
        play_background_music(book_code)  # ë°°ê²½ ìŒì•… ì¬ìƒ (ë¬´í•œ ë£¨í”„)
        
        # ë°°ê²½ì´ ë°”ë€” ë•Œ ì‚¬ìš´ë“œ ì´í™íŠ¸ë§Œ ì¬ìƒ (ì œëª© ë§í•˜ê¸°ëŠ” ë§ˆì»¤ ê°ì§€ ì‹œì—ë§Œ ì¬ìƒ)
        sound_effect_path = "soundeffect/ES_Dream, Harp - Epidemic Sound.wav"
        
        def play_sound():
            # ES_Dream ì‚¬ìš´ë“œ ì´í™íŠ¸ë¥¼ ìŒëŸ‰ 20%ë¡œ ì²˜ë¦¬í•œ ì„ì‹œ íŒŒì¼ ìƒì„± ë° ì¬ìƒ
            if os.path.exists(sound_effect_path):
                try:
                    os.makedirs("title_saying", exist_ok=True)
                    temp_sound = f"title_saying/temp_sound_{book_code}.wav"
                    subprocess.run(
                        ["ffmpeg", "-y", "-i", sound_effect_path,
                         "-af", "volume=0.2",
                         temp_sound],
                        stdout=subprocess.DEVNULL,
                        stderr=subprocess.DEVNULL,
                        check=True
                    )
                    # ì‚¬ìš´ë“œ ì´í™íŠ¸ ì¬ìƒ
                    subprocess.run(["afplay", temp_sound],
                                 stdout=subprocess.DEVNULL,
                                 stderr=subprocess.DEVNULL)
                    os.remove(temp_sound)
                    print(f"ğŸ”Š ì‚¬ìš´ë“œ íš¨ê³¼ ì¬ìƒ (ìŒëŸ‰ 20%): {sound_effect_path}")
                except Exception as e:
                    print(f"âš ï¸ ì‚¬ìš´ë“œ íš¨ê³¼ ì¬ìƒ ì‹¤íŒ¨: {e}")
        
        # ë¹„ë™ê¸°ë¡œ ì¬ìƒ (ë¸”ë¡œí‚¹ ë°©ì§€)
        threading.Thread(target=play_sound, daemon=True).start()
        return

    # -------------------------
    # 2) index 2: ì´ˆê¸° cha1
    # -------------------------
    if index_in_sequence == 2:
        # (stop_all_audioëŠ” í•¨ìˆ˜ ì‹œì‘ ë¶€ë¶„ì—ì„œ ì´ë¯¸ í˜¸ì¶œë¨)
        if book_code not in ROLE_MAP:
            print(f"âš  ROLE_MAPì— ì—†ëŠ” book_code: {book_code}")
            return
        role_key = ROLE_MAP[book_code]["cha1"]
        if role_key is None:
            print(f"âš  {book_code}ì— cha1 ì •ì˜ ì—†ìŒ")
            return

        cha1 = build_character(book_code, role_key)
        CURRENT_CHA1_INFO = cha1

        # ch1 ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ì„¤ì • (ë°°ê²½ì— ë§ëŠ” í´ë”ì—ì„œ ì°¾ê¸°)
        if CURRENT_BG_BOOK_CODE:
            overlay_path = get_overlay_video_path(CURRENT_BG_BOOK_CODE, 1, book_code)
            print(f"ğŸ” [index 2] ch1 ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ê²½ë¡œ: {overlay_path}")
            print(f"ğŸ” [index 2] ë°°ê²½: {CURRENT_BG_BOOK_CODE}, ìºë¦­í„°: {book_code}")
            if os.path.exists(overlay_path):
                print(f"âœ… íŒŒì¼ ì¡´ì¬ í™•ì¸, ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ì„¤ì • ì¤‘...")
                VIDEO_PLAYER.set_overlay_video(overlay_path)
                # ë¹„ë””ì˜¤ê°€ ì œëŒ€ë¡œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸
                import time
                time.sleep(0.15)  # ë¹„ë””ì˜¤ ì´ˆê¸°í™”ë¥¼ ìœ„í•œ ëŒ€ê¸°
                with VIDEO_PLAYER.lock:
                    is_set = VIDEO_PLAYER.overlay_video_cap is not None and VIDEO_PLAYER.overlay_video_cap.isOpened()
                print(f"ğŸ¬ ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ch1 ì„¤ì • ì™„ë£Œ: {overlay_path} (ì„¤ì •ë¨: {is_set})")
            else:
                print(f"âš ï¸ ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {overlay_path}")
                VIDEO_PLAYER.set_overlay_video(None)

        # ì¥í™”í™ë ¨ì „ì˜ ê²½ìš° ìë§¤ ë‘˜ ë‹¤ ë§í•˜ë„ë¡
        if book_code == "JHHRJ":
            older, younger = build_sisters_pair()
            CURRENT_CHA1_INFO = older
            CURRENT_CHA2_INFO = younger
            
            # ìë§¤ ë‘˜ ë‹¤ ëŒ€ì‚¬ ìƒì„±
            line1, line2 = generate_sisters_two_lines(older, CURRENT_BG_INFO)
            if not line1 or not line2:
                # ëŒ€ì‚¬ ìƒì„± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ëŒ€ì‚¬ ì‚¬ìš©
                line1 = "í™ë ¨ì•„, ì—¬ê¸°ê°€ ì–´ë””ì§€?"
                line2 = "ì–¸ë‹ˆ, ë‚˜ë„ ëª¨ë¥´ê² ì–´."
            
            # ëœë¤ìœ¼ë¡œ ìˆœì„œ ê²°ì • - ëª¨ë“  ëŒ€í™” ìƒì„± í›„ ìˆœì°¨ ì¬ìƒ
            if random.random() < 0.5:
                # ì¥í™” ë¨¼ì €
                out1, out1_eng, out1_name = generate_tts(older, line1, "")
                out2, out2_eng, out2_name = generate_tts(younger, line2, "")
                # ìˆœì°¨ì ìœ¼ë¡œ ì¬ìƒ (ê²¹ì¹˜ì§€ ì•Šê²Œ)
                play_audio_sequence([out1, out2], [f"{out1_name}: {out1_eng}", f"{out2_name}: {out2_eng}"])
            else:
                # í™ë ¨ ë¨¼ì €
                out1, out1_eng, out1_name = generate_tts(younger, line2, "")
                out2, out2_eng, out2_name = generate_tts(older, line1, "")
                # ìˆœì°¨ì ìœ¼ë¡œ ì¬ìƒ (ê²¹ì¹˜ì§€ ì•Šê²Œ)
                play_audio_sequence([out1, out2], [f"{out1_name}: {out1_eng}", f"{out2_name}: {out2_eng}"])
        else:
            line = generate_action_line(cha1, CURRENT_BG_INFO)
            if not line:
                line = f"{CURRENT_BG_INFO.get('interaction', '')}, í•œë²ˆ í•´ë³¼ê¹Œ?"

            out_path, eng, name = generate_tts(cha1, line, "")
            # ìˆœì°¨ ì¬ìƒ (ë‹¨ì¼ íŒŒì¼ì´ì§€ë§Œ ì¼ê´€ì„±ì„ ìœ„í•´)
            play_audio_sequence([out_path], [f"{name}: {eng}"])
        return

    # -------------------------
    # 3) index 3: ì´ˆê¸° cha2 + ëŒ€í™”
    # -------------------------
    if index_in_sequence == 3:
        # (stop_all_audioëŠ” í•¨ìˆ˜ ì‹œì‘ ë¶€ë¶„ì—ì„œ ì´ë¯¸ í˜¸ì¶œë¨)
        if book_code not in ROLE_MAP:
            print(f"âš  ROLE_MAPì— ì—†ëŠ” book_code: {book_code}")
            return
        role_key = ROLE_MAP[book_code]["cha2"]
        if role_key is None:
            print(f"âš  {book_code}ì— cha2 ì •ì˜ ì—†ìŒ")
            return

        cha2 = build_character(book_code, role_key)
        CURRENT_CHA2_INFO = cha2
        
        # ch2 ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ì„¤ì • (ë°°ê²½ì— ë§ëŠ” í´ë”ì—ì„œ ì°¾ê¸°)
        if CURRENT_BG_BOOK_CODE:
            overlay_path2 = get_overlay_video_path(CURRENT_BG_BOOK_CODE, 2, book_code)
            if os.path.exists(overlay_path2):
                VIDEO_PLAYER.set_overlay_video2(overlay_path2)
                print(f"ğŸ¬ ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ch2 ì„¤ì •: {overlay_path2}")
                import time
                time.sleep(0.15)
                with VIDEO_PLAYER.lock:
                    is_set = VIDEO_PLAYER.overlay_video_cap2 is not None and VIDEO_PLAYER.overlay_video_cap2.isOpened()
                print(f"ğŸ¬ ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ch2 ì—…ë°ì´íŠ¸ ì™„ë£Œ: {overlay_path2} (ì„¤ì •ë¨: {is_set})")
            else:
                print(f"âš ï¸ ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ch2ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {overlay_path2}")

        if CURRENT_CHA1_INFO is None:
            print("âš  cha1ì´ ì•„ì§ ì„¤ì •ë˜ì§€ ì•Šì•„ cha2ë§Œ í•œ ì¤„ ëŒ€ì‚¬")
            line2 = generate_action_line(cha2, CURRENT_BG_INFO)
            out2, out2_eng, out2_name = generate_tts(cha2, line2, "")
            # ìˆœì°¨ ì¬ìƒ (ë‹¨ì¼ íŒŒì¼ì´ì§€ë§Œ ì¼ê´€ì„±ì„ ìœ„í•´)
            play_audio_sequence([out2], [f"{out2_name}: {out2_eng}"])
            return

        # ì¥í™”í™ë ¨ì „ì˜ ê²½ìš°: ìë§¤ê°€ ëœë¤ ìˆœì„œë¡œ ë§í•¨
        if CURRENT_CHA1_INFO is not None and CURRENT_CHA1_INFO.get('book_code') == "JHHRJ":
            older, younger = build_sisters_pair()
            
            # ëœë¤ìœ¼ë¡œ ìˆœì„œ ê²°ì • - ëª¨ë“  ëŒ€í™” ìƒì„± í›„ ìˆœì°¨ ì¬ìƒ
            if random.random() < 0.5:
                # ì¥í™” ë¨¼ì €
                line_older = generate_action_line(older, CURRENT_BG_INFO)
                out_older, out_older_eng, out_older_name = generate_tts(older, line_older, "")
                
                line_younger = generate_second_dialogue_line(younger, line_older, CURRENT_BG_INFO)
                out_younger, out_younger_eng, out_younger_name = generate_tts(younger, line_younger, "")
                
                # cha2ê°€ ìë§¤ì˜ ëŒ€í™”ì— ë°˜ì‘
                line_cha2 = generate_second_dialogue_line(cha2, line_older, CURRENT_BG_INFO)
                out_cha2, out_cha2_eng, out_cha2_name = generate_tts(cha2, line_cha2, "")
                
                # ìˆœì°¨ì ìœ¼ë¡œ ì¬ìƒ (ê²¹ì¹˜ì§€ ì•Šê²Œ)
                play_audio_sequence([out_older, out_younger, out_cha2], 
                                  [f"{out_older_name}: {out_older_eng}", 
                                   f"{out_younger_name}: {out_younger_eng}", 
                                   f"{out_cha2_name}: {out_cha2_eng}"])
            else:
                # í™ë ¨ ë¨¼ì €
                line_younger = generate_action_line(younger, CURRENT_BG_INFO)
                out_younger, out_younger_eng, out_younger_name = generate_tts(younger, line_younger, "")
                
                line_older = generate_second_dialogue_line(older, line_younger, CURRENT_BG_INFO)
                out_older, out_older_eng, out_older_name = generate_tts(older, line_older, "")
                
                # cha2ê°€ ìë§¤ì˜ ëŒ€í™”ì— ë°˜ì‘
                line_cha2 = generate_second_dialogue_line(cha2, line_younger, CURRENT_BG_INFO)
                out_cha2, out_cha2_eng, out_cha2_name = generate_tts(cha2, line_cha2, "")
                
                # ìˆœì°¨ì ìœ¼ë¡œ ì¬ìƒ (ê²¹ì¹˜ì§€ ì•Šê²Œ)
                play_audio_sequence([out_younger, out_older, out_cha2],
                                  [f"{out_younger_name}: {out_younger_eng}", 
                                   f"{out_older_name}: {out_older_eng}", 
                                   f"{out_cha2_name}: {out_cha2_eng}"])
        else:
            # ìƒˆë¡œ ë“±ì¥í•˜ëŠ” cha2ê°€ ë¨¼ì € ë§í•˜ê³ , cha1ì´ ëŒ€ë‹µí•˜ë„ë¡ ìˆœì„œ ë³€ê²½
            # ì²« ë²ˆì§¸ ëŒ€í™” ìƒì„±
            line2 = generate_first_dialogue_line(cha2, CURRENT_BG_INFO)
            out2, out2_eng, out2_name = generate_tts(cha2, line2, "")
            
            # ë‘ ë²ˆì§¸ ëŒ€í™” ìƒì„±
            line1 = generate_second_dialogue_line(CURRENT_CHA1_INFO, line2, CURRENT_BG_INFO)
            out1, out1_eng, out1_name = generate_tts(CURRENT_CHA1_INFO, line1, "")
            
            # ìˆœì°¨ì ìœ¼ë¡œ ì¬ìƒ (ê²¹ì¹˜ì§€ ì•Šê²Œ)
            play_audio_sequence([out2, out1], [f"{out2_name}: {out2_eng}", f"{out1_name}: {out1_eng}"])
        return

    # -------------------------
    # 4) ì´í›„: 3ê°œ ì£¼ê¸° (ë°°ê²½ / cha1 / cha2 êµì²´)
    # -------------------------
    if CURRENT_BG_INFO is None or CURRENT_CHA1_INFO is None or CURRENT_CHA2_INFO is None:
        print("âš  ì•„ì§ ì´ˆê¸° 1~3ë²ˆ ì…‹ì—…ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    offset = (index_in_sequence - 4) % 3  # 0,1,2 ë°˜ë³µ

    # ---- 4,7,10,... : ë°°ê²½ êµì²´ + ë‘ ìºë¦­í„° ë†€ëŒ ----
    if offset == 0:
        # ì´ì „ ì§„í–‰ ìƒí™© ì¤‘ë‹¨: ëª¨ë“  ì˜¤ë””ì˜¤ ë° bgm ì¤‘ë‹¨
        stop_all_audio()
        stop_background_music()
        bg = get_background(book_code)
        if bg is None:
            print(f"âš  BACKGROUNDSì— ì—†ëŠ” book_code: {book_code}")
            return

        CURRENT_BG_BOOK_CODE = book_code
        CURRENT_BG_INFO = bg

        print(f"[BACKGROUND SWAP] {book_code} â†’ {bg.get('background')}")
        # ë°°ê²½ êµì²´ ë° ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ë„ ìƒˆ ë°°ê²½ì— ë§ê²Œ ì—…ë°ì´íŠ¸
        play_background_video(book_code)  # ë°°ê²½ ë¹„ë””ì˜¤ êµì²´ (ë¬´í•œ ë£¨í”„, ì˜¤ë””ì˜¤ í¬í•¨, í˜ì´ë“œ íš¨ê³¼)
        play_background_music(book_code)  # ë°°ê²½ ìŒì•… êµì²´ (ë¬´í•œ ë£¨í”„)
        
        # í˜„ì¬ ìºë¦­í„°ë“¤ì˜ ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ë¥¼ ìƒˆ ë°°ê²½ì— ë§ê²Œ ì—…ë°ì´íŠ¸
        if CURRENT_CHA1_INFO is not None and CURRENT_CHA1_INFO.get('book_code'):
            try:
                overlay_path_ch1 = get_overlay_video_path(book_code, 1, CURRENT_CHA1_INFO['book_code'])
                print(f"ğŸ” [ë°°ê²½ êµì²´] ch1 ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ê²½ë¡œ: {overlay_path_ch1}")
                if os.path.exists(overlay_path_ch1):
                    print(f"âœ… íŒŒì¼ ì¡´ì¬ í™•ì¸, ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ì„¤ì • ì¤‘...")
                    VIDEO_PLAYER.set_overlay_video(overlay_path_ch1)
                    # ë¹„ë””ì˜¤ê°€ ì œëŒ€ë¡œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸
                    import time
                    time.sleep(0.15)  # ë¹„ë””ì˜¤ ì´ˆê¸°í™”ë¥¼ ìœ„í•œ ëŒ€ê¸°
                    with VIDEO_PLAYER.lock:
                        is_set = VIDEO_PLAYER.overlay_video_cap is not None and VIDEO_PLAYER.overlay_video_cap.isOpened()
                    print(f"ğŸ¬ ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ch1 ì—…ë°ì´íŠ¸ ì™„ë£Œ (ìƒˆ ë°°ê²½): {overlay_path_ch1} (ì„¤ì •ë¨: {is_set})")
                else:
                    print(f"âš ï¸ ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ch1ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {overlay_path_ch1}")
                    VIDEO_PLAYER.set_overlay_video(None)
            except Exception as e:
                print(f"âŒ ch1 ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ì„¤ì • ì¤‘ ì˜¤ë¥˜: {e}")
                import traceback
                traceback.print_exc()
                # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ ê³„ì† ì§„í–‰
                try:
                    VIDEO_PLAYER.set_overlay_video(None)
                except:
                    pass
        
        if CURRENT_CHA2_INFO is not None and CURRENT_CHA2_INFO.get('book_code'):
            try:
                overlay_path_ch2 = get_overlay_video_path(book_code, 2, CURRENT_CHA2_INFO['book_code'])
                print(f"ğŸ” [ë°°ê²½ êµì²´] ch2 ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ê²½ë¡œ: {overlay_path_ch2}")
                if os.path.exists(overlay_path_ch2):
                    print(f"âœ… íŒŒì¼ ì¡´ì¬ í™•ì¸, ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ì„¤ì • ì¤‘...")
                    VIDEO_PLAYER.set_overlay_video2(overlay_path_ch2)
                    # ë¹„ë””ì˜¤ê°€ ì œëŒ€ë¡œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸
                    import time
                    time.sleep(0.15)  # ë¹„ë””ì˜¤ ì´ˆê¸°í™”ë¥¼ ìœ„í•œ ëŒ€ê¸°
                    with VIDEO_PLAYER.lock:
                        is_set = VIDEO_PLAYER.overlay_video_cap2 is not None and VIDEO_PLAYER.overlay_video_cap2.isOpened()
                    print(f"ğŸ¬ ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ch2 ì—…ë°ì´íŠ¸ ì™„ë£Œ (ìƒˆ ë°°ê²½): {overlay_path_ch2} (ì„¤ì •ë¨: {is_set})")
                else:
                    print(f"âš ï¸ ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ch2ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {overlay_path_ch2}")
                    VIDEO_PLAYER.set_overlay_video2(None)
            except Exception as e:
                print(f"âŒ ch2 ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ì„¤ì • ì¤‘ ì˜¤ë¥˜: {e}")
                import traceback
                traceback.print_exc()
                # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ ê³„ì† ì§„í–‰
                try:
                    VIDEO_PLAYER.set_overlay_video2(None)
                except:
                    pass

        # ë°°ê²½ì´ ë°”ë€” ë•Œ ì‚¬ìš´ë“œ ì´í™íŠ¸ë§Œ ì¬ìƒ (ì œëª© ë§í•˜ê¸°ëŠ” ë§ˆì»¤ ê°ì§€ ì‹œì—ë§Œ ì¬ìƒ)
        sound_effect_path = "soundeffect/ES_Dream, Harp - Epidemic Sound.wav"
        
        def play_sound():
            # ES_Dream ì‚¬ìš´ë“œ ì´í™íŠ¸ë¥¼ ìŒëŸ‰ 20%ë¡œ ì²˜ë¦¬í•œ ì„ì‹œ íŒŒì¼ ìƒì„± ë° ì¬ìƒ
            if os.path.exists(sound_effect_path):
                try:
                    os.makedirs("title_saying", exist_ok=True)
                    temp_sound = f"title_saying/temp_sound_{book_code}.wav"
                    subprocess.run(
                        ["ffmpeg", "-y", "-i", sound_effect_path,
                         "-af", "volume=0.2",
                         temp_sound],
                        stdout=subprocess.DEVNULL,
                        stderr=subprocess.DEVNULL,
                        check=True
                    )
                    # ì‚¬ìš´ë“œ ì´í™íŠ¸ ì¬ìƒ
                    subprocess.run(["afplay", temp_sound],
                                 stdout=subprocess.DEVNULL,
                                 stderr=subprocess.DEVNULL)
                    os.remove(temp_sound)
                    print(f"ğŸ”Š ì‚¬ìš´ë“œ íš¨ê³¼ ì¬ìƒ (ìŒëŸ‰ 20%): {sound_effect_path}")
                except Exception as e:
                    print(f"âš ï¸ ì‚¬ìš´ë“œ íš¨ê³¼ ì¬ìƒ ì‹¤íŒ¨: {e}")
        
        # ë¹„ë™ê¸°ë¡œ ì¬ìƒ (ë¸”ë¡œí‚¹ ë°©ì§€)
        threading.Thread(target=play_sound, daemon=True).start()

        # ë°°ê²½ì´ ë°”ë€Œì—ˆì„ ë•Œ ë†€ë€ ëŒ€ì‚¬
        line1 = generate_surprised_line(CURRENT_CHA1_INFO, CURRENT_BG_INFO)
        line2 = generate_surprised_line(CURRENT_CHA2_INFO, CURRENT_BG_INFO)

        out1, out1_eng, out1_name = generate_tts(CURRENT_CHA1_INFO, line1, "")
        out2, out2_eng, out2_name = generate_tts(CURRENT_CHA2_INFO, line2, "")
        
        # ìˆœì°¨ì ìœ¼ë¡œ ì¬ìƒ (ê²¹ì¹˜ì§€ ì•Šê²Œ)
        play_audio_sequence([out1, out2], [f"{out1_name}: {out1_eng}", f"{out2_name}: {out2_eng}"])
        return

        # ---- 5,8,11,... : cha1 êµì²´ ----
    if offset == 1:
        # (stop_all_audioëŠ” í•¨ìˆ˜ ì‹œì‘ ë¶€ë¶„ì—ì„œ ì´ë¯¸ í˜¸ì¶œë¨)
        if book_code not in ROLE_MAP:
            print(f"âš  ROLE_MAPì— ì—†ëŠ” book_code: {book_code}")
            return
        role_key = ROLE_MAP[book_code]["cha1"]
        if role_key is None:
            print(f"âš  {book_code}ì— cha1 ì •ì˜ ì—†ìŒ")
            return

        cha1 = build_character(book_code, role_key)
        CURRENT_CHA1_INFO = cha1

        # ch1 ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ì—…ë°ì´íŠ¸ (ë°°ê²½ì— ë§ëŠ” í´ë”ì—ì„œ ì°¾ê¸°)
        if CURRENT_BG_BOOK_CODE:
            overlay_path = get_overlay_video_path(CURRENT_BG_BOOK_CODE, 1, book_code)
            print(f"ğŸ” [cha1 êµì²´] ch1 ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ê²½ë¡œ: {overlay_path}")
            print(f"ğŸ” [cha1 êµì²´] ë°°ê²½: {CURRENT_BG_BOOK_CODE}, ìƒˆ ìºë¦­í„°: {book_code}")
            if os.path.exists(overlay_path):
                print(f"âœ… íŒŒì¼ ì¡´ì¬ í™•ì¸ë¨, ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ì„¤ì • ì¤‘...")
                # ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ì¦‰ì‹œ ì„¤ì •
                VIDEO_PLAYER.set_overlay_video(overlay_path)
                import time
                time.sleep(0.1)
                print(f"ğŸ¬ ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ch1 ì—…ë°ì´íŠ¸ ì™„ë£Œ: {overlay_path}")
            else:
                print(f"âš ï¸ ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {overlay_path}")
                # íŒŒì¼ì´ ì—†ìœ¼ë©´ ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ë¥¼ Noneìœ¼ë¡œ ì„¤ì •
                VIDEO_PLAYER.set_overlay_video(None)

        # ğŸ”¸ ì¥í™”í™ë ¨ ìë§¤ì¸ ê²½ìš°: ëœë¤ ìˆœì„œë¡œ ê°ê° í•œ ì¤„ì”© ë§í•˜ê³ ,
        #    ê¸°ì¡´ cha2(ì˜ˆ: í† ë¼, ê·€ì‹  ë“±)ê°€ í•œ ì¤„ ë” ëŒ€ë‹µ.
        if book_code == "JHHRJ" and role_key == "sister_older":
            sister_older, sister_younger = build_sisters_pair()

            # ëœë¤ìœ¼ë¡œ ìˆœì„œ ê²°ì • - ëª¨ë“  ëŒ€í™” ìƒì„± í›„ ìˆœì°¨ ì¬ìƒ
            if random.random() < 0.5:
                # ì–¸ë‹ˆ â†’ ë™ìƒ ìˆœì„œ
                lineA = generate_first_dialogue_line(sister_older, CURRENT_BG_INFO)
                outA, outA_eng, outA_name = generate_tts(sister_older, lineA, "")
                
                lineB = generate_second_dialogue_line(sister_younger, lineA, CURRENT_BG_INFO)
                outB, outB_eng, outB_name = generate_tts(sister_younger, lineB, "")
                
                # cha2ê°€ ìë§¤ì˜ ëŒ€í™”ì— ë°˜ì‘
                reply = generate_second_dialogue_line(CURRENT_CHA2_INFO, lineA, CURRENT_BG_INFO)
                outC, outC_eng, outC_name = generate_tts(CURRENT_CHA2_INFO, reply, "")
                
                # ìˆœì°¨ì ìœ¼ë¡œ ì¬ìƒ (ê²¹ì¹˜ì§€ ì•Šê²Œ)
                play_audio_sequence([outA, outB, outC], [f"{outA_name}: {outA_eng}", f"{outB_name}: {outB_eng}", f"{outC_name}: {outC_eng}"])
            else:
                # ë™ìƒ â†’ ì–¸ë‹ˆ ìˆœì„œ
                lineB = generate_first_dialogue_line(sister_younger, CURRENT_BG_INFO)
                outB, outB_eng, outB_name = generate_tts(sister_younger, lineB, "")
                
                lineA = generate_second_dialogue_line(sister_older, lineB, CURRENT_BG_INFO)
                outA, outA_eng, outA_name = generate_tts(sister_older, lineA, "")
                
                # cha2ê°€ ìë§¤ì˜ ëŒ€í™”ì— ë°˜ì‘
                reply = generate_second_dialogue_line(CURRENT_CHA2_INFO, lineB, CURRENT_BG_INFO)
                outC, outC_eng, outC_name = generate_tts(CURRENT_CHA2_INFO, reply, "")

                # ìˆœì°¨ì ìœ¼ë¡œ ì¬ìƒ (ê²¹ì¹˜ì§€ ì•Šê²Œ)
                play_audio_sequence([outB, outA, outC], [f"{outB_name}: {outB_eng}", f"{outA_name}: {outA_eng}", f"{outC_name}: {outC_eng}"])
            return

        # ğŸ”¹ ê·¸ ì™¸ ì¼ë°˜ ìºë¦­í„°: ìƒˆ cha1 + ê¸°ì¡´ cha2ê°€ í•œ ì¤„ì”© ëŒ€í™”
        # ëª¨ë“  ëŒ€í™” ìƒì„± í›„ ìˆœì°¨ ì¬ìƒ
        line1 = generate_first_dialogue_line(cha1, CURRENT_BG_INFO)
        out1, out1_eng, out1_name = generate_tts(cha1, line1, "")
        
        line2 = generate_second_dialogue_line(CURRENT_CHA2_INFO, line1, CURRENT_BG_INFO)
        out2, out2_eng, out2_name = generate_tts(CURRENT_CHA2_INFO, line2, "")
        
        # ìˆœì°¨ì ìœ¼ë¡œ ì¬ìƒ (ê²¹ì¹˜ì§€ ì•Šê²Œ)
        play_audio_sequence([out1, out2], [f"{out1_name}: {out1_eng}", f"{out2_name}: {out2_eng}"])
        return

    # ---- 6,9,12,... : cha2 êµì²´ ----
    if offset == 2:
        # (stop_all_audioëŠ” í•¨ìˆ˜ ì‹œì‘ ë¶€ë¶„ì—ì„œ ì´ë¯¸ í˜¸ì¶œë¨)
        if book_code not in ROLE_MAP:
            print(f"âš  ROLE_MAPì— ì—†ëŠ” book_code: {book_code}")
            return
        role_key = ROLE_MAP[book_code]["cha2"]
        if role_key is None:
            print(f"âš  {book_code}ì— cha2 ì •ì˜ ì—†ìŒ")
            return

        cha2 = build_character(book_code, role_key)
        CURRENT_CHA2_INFO = cha2

        # ch2 ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ì—…ë°ì´íŠ¸ (ë°°ê²½ì— ë§ëŠ” í´ë”ì—ì„œ ì°¾ê¸°)
        if CURRENT_BG_BOOK_CODE:
            overlay_path2 = get_overlay_video_path(CURRENT_BG_BOOK_CODE, 2, book_code)
            print(f"ğŸ” [cha2 êµì²´] ch2 ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ê²½ë¡œ: {overlay_path2}")
            print(f"ğŸ” [cha2 êµì²´] ë°°ê²½: {CURRENT_BG_BOOK_CODE}, ìƒˆ ìºë¦­í„°: {book_code}")
            if os.path.exists(overlay_path2):
                print(f"âœ… íŒŒì¼ ì¡´ì¬ í™•ì¸, ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ì„¤ì • ì¤‘...")
                # ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ì¦‰ì‹œ ì„¤ì •
                VIDEO_PLAYER.set_overlay_video2(overlay_path2)
                import time
                time.sleep(0.15)
                with VIDEO_PLAYER.lock:
                    is_set = VIDEO_PLAYER.overlay_video_cap2 is not None and VIDEO_PLAYER.overlay_video_cap2.isOpened()
                print(f"ğŸ¬ ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ch2 ì—…ë°ì´íŠ¸ ì™„ë£Œ: {overlay_path2} (ì„¤ì •ë¨: {is_set})")
            else:
                print(f"âš ï¸ ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ch2ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {overlay_path2}")
                VIDEO_PLAYER.set_overlay_video2(None)

        # cha1ì´ ì¥í™”í™ë ¨ì¸ ê²½ìš°: cha2ê°€ ë¨¼ì € ë§í•˜ê³ , ìë§¤ê°€ ëœë¤ ìˆœì„œë¡œ ê°ê° í•œ ë²ˆì”© ë§í•¨
        if CURRENT_CHA1_INFO is not None and CURRENT_CHA1_INFO.get('book_code') == "JHHRJ":
            older, younger = build_sisters_pair()
            
            # cha2ê°€ ë¨¼ì € ë§í•¨
            line_cha2 = generate_first_dialogue_line(cha2, CURRENT_BG_INFO)
            out_cha2, out_cha2_eng, out_cha2_name = generate_tts(cha2, line_cha2, "")
            
            # ëœë¤ìœ¼ë¡œ ìˆœì„œ ê²°ì • - ëª¨ë“  ëŒ€í™” ìƒì„± í›„ ìˆœì°¨ ì¬ìƒ
            if random.random() < 0.5:
                # ì¥í™” ë¨¼ì €
                line_older = generate_second_dialogue_line(older, line_cha2, CURRENT_BG_INFO)
                out_older, out_older_eng, out_older_name = generate_tts(older, line_older, "")
                
                line_younger = generate_second_dialogue_line(younger, line_older, CURRENT_BG_INFO)
                out_younger, out_younger_eng, out_younger_name = generate_tts(younger, line_younger, "")
                
                # ìˆœì°¨ì ìœ¼ë¡œ ì¬ìƒ (ê²¹ì¹˜ì§€ ì•Šê²Œ): cha2 -> ì¥í™” -> í™ë ¨
                play_audio_sequence([out_cha2, out_older, out_younger], [f"{out_cha2_name}: {out_cha2_eng}", f"{out_older_name}: {out_older_eng}", f"{out_younger_name}: {out_younger_eng}"])
            else:
                # í™ë ¨ ë¨¼ì €
                line_younger = generate_second_dialogue_line(younger, line_cha2, CURRENT_BG_INFO)
                out_younger, out_younger_eng, out_younger_name = generate_tts(younger, line_younger, "")
                
                line_older = generate_second_dialogue_line(older, line_younger, CURRENT_BG_INFO)
                out_older, out_older_eng, out_older_name = generate_tts(older, line_older, "")
                
                # ìˆœì°¨ì ìœ¼ë¡œ ì¬ìƒ (ê²¹ì¹˜ì§€ ì•Šê²Œ): cha2 -> í™ë ¨ -> ì¥í™”
                play_audio_sequence([out_cha2, out_younger, out_older], [f"{out_cha2_name}: {out_cha2_eng}", f"{out_younger_name}: {out_younger_eng}", f"{out_older_name}: {out_older_eng}"])
        else:
            # cha2ê°€ ë¨¼ì € ë§í•˜ê³ , cha1ì´ ëŒ€ë‹µí•˜ë„ë¡ ìˆœì„œ ë³€ê²½
            # ì²« ë²ˆì§¸ ëŒ€í™” ìƒì„±
            line2 = generate_first_dialogue_line(cha2, CURRENT_BG_INFO)
            out2, out2_eng, out2_name = generate_tts(cha2, line2, "")
            
            # ë‘ ë²ˆì§¸ ëŒ€í™” ìƒì„±
            line1 = generate_second_dialogue_line(CURRENT_CHA1_INFO, line2, CURRENT_BG_INFO)
            out1, out1_eng, out1_name = generate_tts(CURRENT_CHA1_INFO, line1, "")
            
            # ìˆœì°¨ì ìœ¼ë¡œ ì¬ìƒ (ê²¹ì¹˜ì§€ ì•Šê²Œ)
            play_audio_sequence([out2, out1], [f"{out2_name}: {out2_eng}", f"{out1_name}: {out1_eng}"])
        return


# ============================================
# 7. ì›¹ìº  ArUco ë§ˆì»¤ ê°ì§€
# ============================================
def run_webcam_detection():
    """
    ì›¹ìº ìœ¼ë¡œ ArUco ë§ˆì»¤ë¥¼ ê°ì§€í•˜ê³ , ê°ì§€ëœ ë§ˆì»¤ì— ë”°ë¼ handle_book_inputì„ í˜¸ì¶œí•©ë‹ˆë‹¤.
    ë°°ê²½ ë¹„ë””ì˜¤ëŠ” ë³„ë„ì˜ ìœˆë„ìš°ì—ì„œ ë¶€ë“œëŸ½ê²Œ ì „í™˜ë˜ë©° ë¬´í•œ ë£¨í”„ë¡œ ì¬ìƒë©ë‹ˆë‹¤.
    TTS ìƒì„±ì€ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰ë˜ì–´ ë¹„ë””ì˜¤ê°€ ëŠê¸°ì§€ ì•ŠìŠµë‹ˆë‹¤.
    """
    global CURRENT_BG_BOOK_CODE
    
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("âŒ ì›¹ìº ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        return
    
    print("ğŸ“· Camera . Press 'q' to quit.")
    print("ğŸ“š Show your book to camera...")
    
    # ë¹„ë””ì˜¤ í”Œë ˆì´ì–´ ì‹œì‘
    VIDEO_PLAYER.start()
    
    detector_params = aruco.DetectorParameters()
    detector = aruco.ArucoDetector(ARUCO_DICTIONARY, detector_params)
    
    sequence_index = 0  # í˜„ì¬ ì‹œí€€ìŠ¤ ì¸ë±ìŠ¤
    last_detected_marker = None  # ë§ˆì§€ë§‰ìœ¼ë¡œ ê°ì§€ëœ ë§ˆì»¤ (ì¤‘ë³µ ë°©ì§€)
    handler_thread = None  # handle_book_input ì‹¤í–‰ ìŠ¤ë ˆë“œ
    is_processing = False  # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ì§€ ì—¬ë¶€
    last_marker_time = None  # ë§ˆì§€ë§‰ìœ¼ë¡œ ë§ˆì»¤ê°€ ê°ì§€ëœ ì‹œê°„
    no_marker_timeout = 3.0  # ë§ˆì»¤ê°€ ê°ì§€ë˜ì§€ ì•Šì„ ë•Œ í˜ì´ë“œ ì•„ì›ƒê¹Œì§€ì˜ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
    fade_out_triggered = False  # í˜ì´ë“œ ì•„ì›ƒì´ ì´ë¯¸ íŠ¸ë¦¬ê±°ë˜ì—ˆëŠ”ì§€ ì—¬ë¶€
    
    # ë¹„ë””ì˜¤ ìœˆë„ìš° ìƒì„± (íŒì—…ì°½)
    cv2.namedWindow("Background Video", cv2.WINDOW_NORMAL)
    # ì°½ í¬ê¸° ì„¤ì • (ì˜ˆ: 1280x720)
    cv2.resizeWindow("Background Video", 1280, 720)
    
    def run_handler_async(book_code, seq_idx):
        """handle_book_inputì„ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰"""
        nonlocal is_processing
        is_processing = True
        try:
            handle_book_input(book_code, seq_idx)
        finally:
            is_processing = False
    
    while True:
        ret, frame = cap.read()
        if not ret:
            print("âŒ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            break
        
        # ArUco ë§ˆì»¤ ê°ì§€
        corners, ids, rejected = detector.detectMarkers(frame)
        
        current_time = time.time()
        
        # ë§ˆì»¤ê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ì„ ë•Œ ì²˜ë¦¬ (íƒ€ì„ì•„ì›ƒ ë²„í¼ ì ìš©)
        if ids is None or len(ids) == 0:
            # ì´ì „ì— ë§ˆì»¤ê°€ ìˆì—ˆëŠ”ë° ì§€ê¸ˆ ì—†ìœ¼ë©´ íƒ€ì„ì•„ì›ƒ ì²´í¬
            if last_detected_marker is not None and not fade_out_triggered:
                # ë§ˆì»¤ê°€ ê°ì§€ë˜ì§€ ì•Šì€ ì‹œê°„ ê³„ì‚°
                if last_marker_time is None:
                    # ë§ˆì»¤ê°€ ì²˜ìŒìœ¼ë¡œ ì‚¬ë¼ì§„ ì‹œì  ê¸°ë¡
                    last_marker_time = current_time
                
                time_since_last_marker = current_time - last_marker_time
                
                # íƒ€ì„ì•„ì›ƒ ì‹œê°„ì´ ì§€ë‚¬ê³  ì•„ì§ í˜ì´ë“œ ì•„ì›ƒì´ íŠ¸ë¦¬ê±°ë˜ì§€ ì•Šì•˜ìœ¼ë©´ í˜ì´ë“œ ì•„ì›ƒ
                if time_since_last_marker >= no_marker_timeout:
                    # ëª¨ë“  ì˜¤ë””ì˜¤ ì¤‘ë‹¨
                    stop_all_audio()
                    stop_background_music()
                    # ë¹„ë””ì˜¤ í˜ì´ë“œ ì•„ì›ƒ (ê²€ì€ í™”ë©´ìœ¼ë¡œ)
                    VIDEO_PLAYER.set_video(None)  # Noneì„ ì „ë‹¬í•˜ë©´ í˜ì´ë“œ ì•„ì›ƒ
                    # ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ì œê±°
                    VIDEO_PLAYER.clear_overlay_video()
                    # ìƒíƒœ ì´ˆê¸°í™” (ì „ì—­ ë³€ìˆ˜ë„ ë¦¬ì…‹)
                    global CURRENT_BG_BOOK_CODE, CURRENT_BG_INFO, CURRENT_CHA1_INFO, CURRENT_CHA2_INFO
                    last_detected_marker = None
                    sequence_index = 0
                    fade_out_triggered = True
                    last_marker_time = None
                    CURRENT_BG_BOOK_CODE = None
                    CURRENT_BG_INFO = None
                    CURRENT_CHA1_INFO = None
                    CURRENT_CHA2_INFO = None
                    print(f"ğŸ”‡ ë§ˆì»¤ê°€ {no_marker_timeout}ì´ˆ ë™ì•ˆ ê°ì§€ë˜ì§€ ì•Šì•„ ëª¨ë“  ì˜¤ë””ì˜¤ ì¤‘ë‹¨ ë° í˜ì´ë“œ ì•„ì›ƒ (ë¦¬ì…‹ ì™„ë£Œ)")
        # ê°ì§€ëœ ë§ˆì»¤ê°€ ìˆìœ¼ë©´ í‘œì‹œ
        if ids is not None and len(ids) > 0:
            # ë§ˆì»¤ê°€ ê°ì§€ë˜ë©´ íƒ€ì„ì•„ì›ƒ ë¦¬ì…‹ (ê°™ì€ ë§ˆì»¤ë“  ìƒˆ ë§ˆì»¤ë“ )
            last_marker_time = current_time
            fade_out_triggered = False
            
            aruco.drawDetectedMarkers(frame, corners, ids)
            
            # ì²« ë²ˆì§¸ë¡œ ê°ì§€ëœ ë§ˆì»¤ ì²˜ë¦¬
            marker_id = ids[0][0]
            book_code = get_book_code_from_marker(marker_id)
            
            # ìƒˆ ë§ˆì»¤ ê°ì§€ ì²˜ë¦¬
            if book_code and marker_id != last_detected_marker:
                # 3n-2, 3n-1, 3në²ˆì§¸ ì±…ì€ ì¦‰ì‹œ ì „í™˜ (ì´ì „ ì§„í–‰ ìƒí™© ì¤‘ë‹¨)
                should_interrupt = (sequence_index + 1) % 3 in [1, 2, 0]  # 1,2,0 -> 3n-2, 3n-1, 3n
                
                if should_interrupt or not is_processing:
                    # ì¦‰ì‹œ ì „í™˜ì´ í•„ìš”í•œ ê²½ìš° ëª¨ë“  ì˜¤ë””ì˜¤ ì¤‘ë‹¨
                    if should_interrupt:
                        stop_all_audio()
                    
                    last_detected_marker = marker_id
                    sequence_index += 1
                    
                    # í•œê¸€ ì±… ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
                    book_info = BACKGROUNDS.get(book_code, {})
                    book_name_kr = book_info.get("book", book_code)
                    
                    print(f"\nğŸ¯ Marker Detected! ID: {marker_id} â†’ {book_name_kr} ({book_code}) (Num of books: {sequence_index})")
                    
                    # ë§ˆì»¤ ê°ì§€ ì¦‰ì‹œ ì œëª© ë§í•˜ê¸° ì¬ìƒ (ë°°ê²½ì´ ë°”ë€” ë•Œë§Œ ì‚¬ìš´ë“œ ì´í™íŠ¸ í¬í•¨)
                    title_saying_path = f"title_saying/{book_code}_title.wav"
                
                def play_title():
                    # ì œëª© ë§í•˜ê¸° ì¬ìƒ (ìŒëŸ‰ 150%)
                    if os.path.exists(title_saying_path):
                        # ìŒëŸ‰ 150%ë¡œ ì¡°ì •í•œ ì„ì‹œ íŒŒì¼ ìƒì„±
                        import tempfile
                        temp_dir = tempfile.gettempdir()
                        temp_title = os.path.join(temp_dir, f"title_{os.getpid()}_{id(title_saying_path)}.wav")
                        subprocess.run(
                            ["ffmpeg", "-y", "-i", title_saying_path,
                             "-af", "volume=1.5",
                             "-acodec", "pcm_s16le", "-ar", "44100", "-ac", "2",
                             temp_title],
                            stdout=subprocess.DEVNULL,
                            stderr=subprocess.DEVNULL,
                            check=True
                        )
                        # ì¡°ì •ëœ íŒŒì¼ ì¬ìƒ
                        subprocess.run(["afplay", temp_title],
                                      stdout=subprocess.DEVNULL,
                                      stderr=subprocess.DEVNULL)
                        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                        try:
                            os.remove(temp_title)
                        except:
                            pass
                        print(f"ğŸ“š ì œëª© ë§í•˜ê¸° ì¬ìƒ (ìŒëŸ‰ 150%): {title_saying_path}")
                
                # ë¹„ë™ê¸°ë¡œ ì¬ìƒ (ë¸”ë¡œí‚¹ ë°©ì§€)
                threading.Thread(target=play_title, daemon=True).start()
                
                # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ handle_book_input ì‹¤í–‰ (ë¹„ë””ì˜¤ê°€ ëŠê¸°ì§€ ì•Šë„ë¡)
                handler_thread = threading.Thread(
                    target=run_handler_async, 
                    args=(book_code, sequence_index),
                    daemon=True
                )
                handler_thread.start()
        
        # í™”ë©´ì— ì •ë³´ í‘œì‹œ (ì›¹ìº  ìœˆë„ìš°)
        cv2.putText(frame, f"Sequence: {sequence_index}", (10, 30), 
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        if last_detected_marker is not None:
            book = get_book_code_from_marker(last_detected_marker) or "Unknown"
            cv2.putText(frame, f"Last: {book}", (10, 70), 
                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        if is_processing:
            cv2.putText(frame, "Processing...", (10, 110), 
                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 165, 255), 2)
        
        cv2.imshow("ArUco Marker Detection", frame)
        
        # ë°°ê²½ ë¹„ë””ì˜¤ í”„ë ˆì„ í‘œì‹œ (ê°™ì€ ìœˆë„ìš°ì—ì„œ ë¶€ë“œëŸ½ê²Œ ì „í™˜)
        video_frame = VIDEO_PLAYER.get_frame()
        if video_frame is not None:
            cv2.imshow("Background Video", video_frame)
        else:
            # ë¹„ë””ì˜¤ê°€ ì—†ì„ ë•Œ ê¹Œë§Œ í™”ë©´ í‘œì‹œ (ì•„ë¬´ê²ƒë„ ê°ì§€ë˜ì§€ ì•Šì•˜ì„ ë•Œ)
            # ë¹„ë””ì˜¤ê°€ ì‹œì‘ë˜ê¸° ì „ì—ë„ ìœˆë„ìš°ë¥¼ ìœ ì§€í•˜ê¸° ìœ„í•´ ê¹Œë§Œ í™”ë©´ í‘œì‹œ
            black_frame = np.zeros((720, 1280, 3), dtype=np.uint8)  # ê¸°ë³¸ í•´ìƒë„
            cv2.imshow("Background Video", black_frame)
        
        # 'q' í‚¤ë¡œ ì¢…ë£Œ
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    
    # ì •ë¦¬
    cap.release()
    VIDEO_PLAYER.stop()
    stop_background_music()  # bgm ì¤‘ì§€
    cv2.destroyAllWindows()
    print("\nğŸ“· ì›¹ìº  ì¢…ë£Œë¨.")


# ============================================
# 8. ë‹¨ë… ì‹¤í–‰
# ============================================
if __name__ == "__main__":
    import sys
    
    # ArUco ë§ˆì»¤ ìƒì„± ì˜µì…˜
    if len(sys.argv) > 1 and sys.argv[1] == "--generate-markers":
        generate_aruco_markers()
        sys.exit(0)
    
    # ê¸°ë³¸: ì›¹ìº  ê°ì§€ ëª¨ë“œ ì‹¤í–‰
    run_webcam_detection()