#!/usr/bin/env python3
"""
characters_saying.jsonì˜ ì‹¤ì œ ëŒ€ì‚¬ë¥¼ ì‹¬ì¸µ ë¶„ì„í•˜ì—¬ 
characters_tone.jsonì˜ ë§íˆ¬ ì •ë³´ë¥¼ ì •í™•í•˜ê²Œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
"""

import json
import re
from collections import Counter
from typing import Dict, List

def extract_endings_and_expressions(dialogues: List[str]) -> Dict:
    """ëŒ€ì‚¬ì—ì„œ ì–´ë¯¸ì™€ ìì£¼ ì‚¬ìš©ë˜ëŠ” í‘œí˜„ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    all_endings = []
    all_expressions = []
    all_words = []
    
    for dialogue in dialogues:
        # ë¬¸ì¥ì„ ë¶„ë¦¬
        sentences = re.split(r'[.!?]\s*', dialogue)
        
        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:
                continue
            
            # ì–´ë¯¸ ì¶”ì¶œ (ë¬¸ì¥ ë ë¶€ë¶„)
            # ~ë‹¤, ~ìš”, ~ì§€, ~ëƒ, ~êµ¬ë‚˜, ~ë‹ˆ, ~ì–´, ~ì•„, ~ì˜¤, ~ì˜µë‹ˆë‹¤ ë“±
            ending_match = re.search(r'([ë‹¤ìš”ì§€ëƒêµ¬ë‚˜ë‹ˆì–´ì•„ì˜¤ì„œì†Œì„œì‰ë‹¹ê»˜ì§€ë¼ìš°ì˜µë‹ˆë‹¤ì„œì†Œì„œ]+)\s*$', sentence)
            if ending_match:
                all_endings.append(ending_match.group(1))
            
            # ìì£¼ ì‚¬ìš©ë˜ëŠ” í‘œí˜„ íŒ¨í„´ ì¶”ì¶œ
            # ~í•˜ê² ìŠµë‹ˆë‹¤, ~í•˜ì˜µë‹ˆë‹¤, ~í•˜ì§€ ë§ˆì„¸ìš”, ë¶€ë””, í‹€ë¦¼ì—†ì´ ë“±
            patterns = [
                r'~?í•˜ê² ìŠµë‹ˆë‹¤',
                r'~?í•˜ì˜µë‹ˆë‹¤',
                r'~?í•˜ì§€\s*ë§ˆì„¸ìš”',
                r'~?í•˜ì§€\s*ë§ì•„',
                r'ë¶€ë””',
                r'í‹€ë¦¼ì—†ì´',
                r'ë°˜ë“œì‹œ',
                r'ê¼­',
                r'ì œê°€\s*ì–´ë–»ê²Œë“ ',
                r'ì œê°€\s*ë°˜ë“œì‹œ',
                r'~?í•˜ì‹œì˜µì†Œì„œ',
                r'~?í•˜ì‹œì§€\s*ë§ˆ',
                r'~?í•˜ì‹œê² ìŠµë‹ˆê¹Œ',
                r'~?í•˜ëŠëƒ',
                r'~?í•˜ë¦¬ë¼',
                r'~?ë‹¨ë‹¤',
                r'~?êµ¬ë‚˜',
                r'~?ì§€ë¼ìš°',
                r'~?ë‹¹ê»˜',
                r'~?ìš”ì‰',
                r'~?í•˜ê±°ë¼',
                r'~?í•˜ë¼',
                r'ì´ë†ˆ',
                r'ê°íˆ',
                r'ì£„ì†¡',
                r'ê³ ë§™',
                r'ë¯¸ì•ˆ',
                r'ì–µìš¸',
                r'ìŠ¬í”„',
                r'ì œë°œ',
            ]
            
            for pattern in patterns:
                matches = re.findall(pattern, sentence, re.IGNORECASE)
                all_expressions.extend(matches)
            
            # ë‹¨ì–´ ì¶”ì¶œ
            words = sentence.split()
            all_words.extend(words)
    
    # ë¹ˆë„ìˆ˜ ê³„ì‚°
    ending_counter = Counter(all_endings)
    expression_counter = Counter(all_expressions)
    word_counter = Counter(all_words)
    
    return {
        "top_endings": [item[0] for item in ending_counter.most_common(15)],
        "top_expressions": [item[0] for item in expression_counter.most_common(25)],
        "top_words": [item[0] for item in word_counter.most_common(20)]
    }

def analyze_characteristics(dialogues: List[str]) -> Dict:
    """ëŒ€ì‚¬ì—ì„œ ë§íˆ¬ íŠ¹ì§•ì„ ì‹¬ì¸µ ë¶„ì„í•©ë‹ˆë‹¤."""
    if not dialogues:
        return {}
    
    full_text = ' '.join(dialogues)
    
    characteristics = {
        "formality_indicators": [],
        "politeness_indicators": [],
        "emotional_keywords": [],
        "dialect_indicators": [],
        "age_indicators": [],
        "sentence_patterns": [],
        "repetition_style": []
    }
    
    # ê³µì†ë„ ë¶„ì„
    very_formal = ['í•˜ì˜µë‹ˆë‹¤', 'í•˜ì‹œì˜µì†Œì„œ', 'í•˜ì‹œì˜µë‹ˆê¹Œ', 'í•˜ì˜µì†Œì„œ', 'ë¹„ë‚˜ì´ë‹¤']
    formal = ['í•˜ê² ìŠµë‹ˆë‹¤', 'í•˜ì„¸ìš”', 'í•˜ì‹œì§€', 'í•˜ì‹œë©´', 'í•˜ì‹œëŠ”']
    informal = ['í•œë‹¤', 'í•œë‹¤ëƒ', 'í•˜ê±°ë¼', 'í•˜ë¼', 'í•˜ëŠëƒ']
    
    for pattern in very_formal:
        if pattern in full_text:
            characteristics["formality_indicators"].append(f"very_formal: {pattern}")
    
    for pattern in formal:
        if pattern in full_text:
            characteristics["politeness_indicators"].append(f"polite: {pattern}")
    
    for pattern in informal:
        if pattern in full_text:
            characteristics["formality_indicators"].append(f"informal: {pattern}")
    
    # ê°ì • í‚¤ì›Œë“œ
    emotion_map = {
        "passionate": ['ë°˜ë“œì‹œ', 'í‹€ë¦¼ì—†ì´', 'ê¼­', 'ì œê°€ ì–´ë–»ê²Œë“ ', 'ë¶€ë””', 'ë¹„ë‚˜ì´ë‹¤', 'í•˜ê² ìŠµë‹ˆë‹¤', 'í•˜ë¦¬ë¼'],
        "sad": ['ìŠ¬í”„', 'ì–µìš¸', 'ë¯¸ì•ˆ', 'ë¶ˆìŒ', 'í•œ', 'ì›í†µ', 'ì•„ì´ê³ ', 'í‘í‘'],
        "angry": ['ì´ë†ˆ', 'ì£½ì¼', 'í™”ë‚˜', 'ì–µìš¸í•´', 'ë¶„í•˜ê³ ', 'ê°íˆ', 'ê°€ì†Œë¡­'],
        "fearful": ['ë¬´ì„œ', 'ë‘ë ¤', 'ê±±ì •', 'ì œë°œ', 'ë¶€ë””', 'ì•ˆ ë¼', 'ëª» ê°€'],
        "determined": ['ë°˜ë“œì‹œ', 'í‹€ë¦¼ì—†ì´', 'ê¼­', 'í•˜ê² ', 'í•˜ë¦¬ë¼', 'ê²Œ ì„°ê±°ë¼'],
        "gentle": ['~í•˜ì§€ ë§ˆ', '~í•˜ì§€ ë§ì•„', 'ë¶€ë””', 'ì œë°œ', '~í•˜ì‹œì§€ ë§ˆ'],
        "humble": ['ì£„ì†¡', 'ë¶€ì¡±', 'ëª»ë‚˜', 'ê³ ë§™', 'ê°ì‚¬'],
        "arrogant": ['ê°íˆ', 'ì–´ì°Œ', 'ê°€ì†Œë¡­', 'ë¯¸ë ¨í•œ', 'ì´ë†ˆì´'],
        "respectful": ['í•˜ì˜µë‹ˆë‹¤', 'í•˜ì‹œì˜µì†Œì„œ', '~ë‹˜', '~ê»˜ì„œ']
    }
    
    for emotion, keywords in emotion_map.items():
        count = sum(1 for kw in keywords if kw in full_text)
        if count > 0:
            characteristics["emotional_keywords"].append(f"{emotion}: {count}íšŒ")
    
    # ë°©ì–¸ íŠ¹ì§•
    dialect_map = {
        "rural": ['~ì§€ë¼ìš°', '~ë‹¹ê»˜', '~ìš”ì‰', '~ì§€ë¼', '~í•˜ì‹œì§€ë¼', 'ì•„ì´ì½”', 'ì•„ì´ê³ ', 'ì•„ë”°'],
        "old_fashioned": ['~í•˜ëŠëƒ', '~í•˜ë¦¬ë¼', '~ë‹¨ë‹¤', '~êµ¬ë‚˜', '~í•˜ì˜µë‹ˆë‹¤', '~í•˜ì‹œì˜µì†Œì„œ'],
        "modern": ['~ê±°ë“ ', '~ì–ì•„', '~ì§€ ë­', '~í•˜ì§€', '~í•˜ëŠ” ê±°ì•¼']
    }
    
    for dialect, patterns in dialect_map.items():
        count = sum(1 for p in patterns if p in full_text)
        if count > 0:
            characteristics["dialect_indicators"].append(f"{dialect}: {count}íšŒ")
    
    # ë¬¸ì¥ íŒ¨í„´
    if '?' in full_text:
        characteristics["sentence_patterns"].append("ì§ˆë¬¸ ë§ì´ ì‚¬ìš©")
    if '!' in full_text:
        characteristics["sentence_patterns"].append("ê°íƒ„ë¬¸ ì‚¬ìš©")
    if '...' in full_text or 'â€¦â€¦' in full_text:
        characteristics["sentence_patterns"].append("ë§ì¤„ì„í‘œ ì‚¬ìš© (ê°ì • í‘œí˜„)")
    
    # ë°˜ë³µ ìŠ¤íƒ€ì¼
    if re.search(r'(.)\1{2,}', full_text):
        characteristics["repetition_style"].append("ë‹¨ì–´ ë°˜ë³µ (ê°•ì¡°)")
    
    # í‰ê·  ë¬¸ì¥ ê¸¸ì´
    sentences = re.split(r'[.!?]\s*', full_text)
    avg_length = sum(len(s.split()) for s in sentences if s.strip()) / len([s for s in sentences if s.strip()]) if sentences else 0
    characteristics["sentence_patterns"].append(f"í‰ê·  ë¬¸ì¥ ê¸¸ì´: {avg_length:.1f}ë‹¨ì–´")
    
    return characteristics

def update_tone_from_sayings():
    """characters_saying.jsonì„ ì½ì–´ì„œ characters_tone.jsonì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
    
    # íŒŒì¼ ì½ê¸°
    with open('characters_saying.json', 'r', encoding='utf-8') as f:
        sayings_data = json.load(f)
    
    with open('characters_tone.json', 'r', encoding='utf-8') as f:
        tone_data = json.load(f)
    
    # ê° ìºë¦­í„°ë³„ë¡œ ë¶„ì„ ë° ì—…ë°ì´íŠ¸
    for book_code, characters in sayings_data.items():
        if book_code not in tone_data:
            continue
        
        for char_key, char_data in characters.items():
            if char_key not in tone_data[book_code]:
                continue
            
            dialogues = char_data.get('dialogues', [])
            if not dialogues:
                continue
            
            print(f"\nğŸ“ ë¶„ì„ ì¤‘: {book_code} - {char_key} ({len(dialogues)}ê°œ ëŒ€ì‚¬)")
            
            # ë§íˆ¬ íŒ¨í„´ ë¶„ì„
            patterns = extract_endings_and_expressions(dialogues)
            characteristics = analyze_characteristics(dialogues)
            
            # ê¸°ì¡´ ë°ì´í„° ì—…ë°ì´íŠ¸
            char_tone = tone_data[book_code][char_key]
            
            # speech_patterns ì—…ë°ì´íŠ¸
            if 'speech_patterns' not in char_tone:
                char_tone['speech_patterns'] = {}
            
            # ê¸°ì¡´ frequent_expressionsì™€ ë³‘í•©
            existing_expressions = char_tone.get('speech_patterns', {}).get('frequent_expressions', [])
            new_expressions = patterns.get('top_expressions', [])
            
            # ì¤‘ë³µ ì œê±°í•˜ê³  ë³‘í•© (ì‹¤ì œ ëŒ€ì‚¬ì—ì„œ ì¶”ì¶œí•œ ê²ƒì„ ìš°ì„ )
            merged_expressions = []
            seen = set()
            
            # ìƒˆë¡œ ì¶”ì¶œí•œ í‘œí˜„ì„ ë¨¼ì € ì¶”ê°€
            for expr in new_expressions:
                if expr not in seen:
                    merged_expressions.append(expr)
                    seen.add(expr)
            
            # ê¸°ì¡´ í‘œí˜„ ì¤‘ ì•„ì§ ì¶”ê°€ë˜ì§€ ì•Šì€ ê²ƒë§Œ ì¶”ê°€
            for expr in existing_expressions:
                if expr not in seen:
                    merged_expressions.append(expr)
                    seen.add(expr)
            
            char_tone['speech_patterns']['frequent_expressions'] = merged_expressions[:30]
            
            # ì¶”ê°€ ì •ë³´ ì €ì¥
            char_tone['speech_patterns']['endings_from_dialogues'] = patterns.get('top_endings', [])[:15]
            char_tone['speech_patterns']['common_words'] = patterns.get('top_words', [])[:15]
            
            # ë¶„ì„ ê²°ê³¼ë¥¼ ìƒˆë¡œìš´ í•„ë“œë¡œ ì¶”ê°€
            char_tone['analysis_from_dialogues'] = {
                "formality_indicators": characteristics.get('formality_indicators', [])[:5],
                "politeness_indicators": characteristics.get('politeness_indicators', [])[:5],
                "emotional_keywords": characteristics.get('emotional_keywords', [])[:8],
                "dialect_indicators": characteristics.get('dialect_indicators', []),
                "sentence_patterns": characteristics.get('sentence_patterns', []),
                "repetition_style": characteristics.get('repetition_style', [])
            }
            
            print(f"âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ: {char_key}")
            print(f"   - ìì£¼ ì‚¬ìš© í‘œí˜„: {len(merged_expressions)}ê°œ")
            print(f"   - ì–´ë¯¸ íŒ¨í„´: {len(patterns.get('top_endings', []))}ê°œ")
            print(f"   - ê°ì • í‚¤ì›Œë“œ: {len(characteristics.get('emotional_keywords', []))}ê°œ")
            if characteristics.get('dialect_indicators'):
                print(f"   - ë°©ì–¸ íŠ¹ì§•: {', '.join([d.split(':')[0] for d in characteristics['dialect_indicators']])}")
    
    # ì—…ë°ì´íŠ¸ëœ ë°ì´í„° ì €ì¥
    with open('characters_tone.json', 'w', encoding='utf-8') as f:
        json.dump(tone_data, f, ensure_ascii=False, indent=2)
    
    print("\nâœ¨ characters_tone.json ì—…ë°ì´íŠ¸ ì™„ë£Œ!")

if __name__ == '__main__':
    update_tone_from_sayings()

