#!/usr/bin/env python3
"""
characters_saying.jsonÏùò Ïã§Ï†ú ÎåÄÏÇ¨Î•º Î∂ÑÏÑùÌïòÏó¨ 
characters_tone.jsonÏùò ÎßêÌà¨ Ï†ïÎ≥¥Î•º ÏóÖÎç∞Ïù¥Ìä∏Ìï©ÎãàÎã§.
"""

import json
import re
from collections import Counter
from typing import Dict, List, Set

def analyze_speech_patterns(dialogues: List[str]) -> Dict:
    """ÎåÄÏÇ¨ Î™©Î°ùÏùÑ Î∂ÑÏÑùÌïòÏó¨ ÎßêÌà¨ Ìå®ÌÑ¥ÏùÑ Ï∂îÏ∂úÌï©ÎãàÎã§."""
    if not dialogues:
        return {}
    
    # Ïñ¥ÎØ∏ Ìå®ÌÑ¥ Ï∂îÏ∂ú
    endings = []
    frequent_expressions = []
    sentence_starters = []
    
    for dialogue in dialogues:
        # Î¨∏Ïû• ÎÅù Ïñ¥ÎØ∏ Ï∂îÏ∂ú
        # ~Îã§, ~Ïöî, ~ÏßÄ, ~ÎÉê, ~Íµ¨ÎÇò, ~Îãà, ~Ïñ¥, ~ÏïÑ Îì±
        endings_match = re.findall(r'[~]?([Îã§ÏöîÏßÄÎÉêÍµ¨ÎÇòÎãàÏñ¥ÏïÑÏò§ÏòµÎãàÎã§ÏÑúÏÜåÏÑúÏûâÎãπÍªòÏßÄÎùºÏö∞]+\s*[.!?]?)', dialogue)
        if endings_match:
            endings.extend(endings_match)
        
        # ÏûêÏ£º ÏÇ¨Ïö©ÎêòÎäî ÌëúÌòÑ Ï∂îÏ∂ú
        # ~ÌïòÍ≤†ÏäµÎãàÎã§, ~ÌïòÏòµÎãàÎã§, ~ÌïòÏßÄ ÎßàÏÑ∏Ïöî Îì±
        expressions = re.findall(r'[~]?([ÌïòÍ≤†ÏäµÎãàÌïòÏòµÎãàÌïòÏßÄÎßàÏãúÎ∂ÄÎîîÌãÄÎ¶ºÏóÜÎ∞òÎìúÏãúÍº≠Ï†úÍ∞Ä]+\s*[Îã§ÏöîÏßÄÎÉêÍµ¨ÎÇòÎãàÏñ¥ÏïÑÏò§ÏÑúÏÜåÏÑúÏûâÎãπÍªòÏßÄÎùºÏö∞]*)', dialogue)
        frequent_expressions.extend(expressions)
        
        # Î¨∏Ïû• ÏãúÏûë Ìå®ÌÑ¥
        if dialogue.strip():
            first_words = dialogue.strip().split()[:3]
            if first_words:
                sentence_starters.append(' '.join(first_words))
    
    # ÎπàÎèÑÏàò Í≥ÑÏÇ∞
    ending_counter = Counter(endings)
    expression_counter = Counter(frequent_expressions)
    starter_counter = Counter(sentence_starters)
    
    # ÏÉÅÏúÑ 20Í∞ú Ï∂îÏ∂ú
    top_endings = [item[0] for item in ending_counter.most_common(20)]
    top_expressions = [item[0] for item in expression_counter.most_common(20)]
    top_starters = [item[0] for item in starter_counter.most_common(10)]
    
    return {
        "endings": top_endings,
        "frequent_expressions": top_expressions,
        "sentence_starters": top_starters
    }

def extract_tone_characteristics(dialogues: List[str]) -> Dict:
    """ÎåÄÏÇ¨ÏóêÏÑú ÎßêÌà¨ ÌäπÏßïÏùÑ Ï∂îÏ∂úÌï©ÎãàÎã§."""
    if not dialogues:
        return {}
    
    characteristics = {
        "formality_level": "unknown",  # formal, informal, mixed
        "politeness_level": "unknown",  # very_polite, polite, casual, rude
        "emotional_tone": [],  # passionate, calm, sad, angry, etc.
        "dialect_features": [],  # regional dialect patterns
        "age_indicators": [],  # old-fashioned, modern, etc.
        "sentence_length": "unknown",  # short, medium, long
        "repetition_patterns": []
    }
    
    # Í≥µÏÜêÏñ¥ÎØ∏ Î∂ÑÏÑù
    formal_endings = ['ÌïòÏòµÎãàÎã§', 'ÌïòÏãúÏòµÏÜåÏÑú', 'ÌïòÏãúÏòµÎãàÍπå', 'ÌïòÏòµÏÜåÏÑú']
    informal_endings = ['ÌïúÎã§', 'ÌïúÎã§ÎÉê', 'ÌïòÍ±∞Îùº', 'ÌïòÎùº']
    polite_endings = ['ÌïòÍ≤†ÏäµÎãàÎã§', 'ÌïòÏÑ∏Ïöî', 'ÌïòÏãúÏßÄ', 'ÌïòÏãúÎ©¥']
    
    formal_count = sum(1 for d in dialogues if any(e in d for e in formal_endings))
    informal_count = sum(1 for d in dialogues if any(e in d for e in informal_endings))
    polite_count = sum(1 for d in dialogues if any(e in d for e in polite_endings))
    
    if formal_count > len(dialogues) * 0.5:
        characteristics["formality_level"] = "formal"
        characteristics["politeness_level"] = "very_polite"
    elif polite_count > len(dialogues) * 0.5:
        characteristics["formality_level"] = "polite"
        characteristics["politeness_level"] = "polite"
    elif informal_count > len(dialogues) * 0.5:
        characteristics["formality_level"] = "informal"
        characteristics["politeness_level"] = "casual"
    else:
        characteristics["formality_level"] = "mixed"
        characteristics["politeness_level"] = "mixed"
    
    # Í∞êÏ†ï ÌÜ§ Î∂ÑÏÑù
    emotional_keywords = {
        "passionate": ["Î∞òÎìúÏãú", "ÌãÄÎ¶ºÏóÜÏù¥", "Íº≠", "Ï†úÍ∞Ä Ïñ¥ÎñªÍ≤åÎì†", "Î∂ÄÎîî", "ÎπÑÎÇòÏù¥Îã§"],
        "sad": ["Ïä¨ÌîÑ", "ÏñµÏö∏", "ÎØ∏Ïïà", "Î∂àÏåç", "Ìïú", "ÏõêÌÜµ"],
        "angry": ["Ïù¥ÎÜà", "Ï£ΩÏùº", "ÌôîÎÇò", "ÏñµÏö∏Ìï¥", "Î∂ÑÌïòÍ≥†"],
        "fearful": ["Î¨¥ÏÑú", "ÎëêÎ†§", "Í±±Ï†ï", "Ï†úÎ∞ú", "Î∂ÄÎîî"],
        "determined": ["Î∞òÎìúÏãú", "ÌãÄÎ¶ºÏóÜÏù¥", "Íº≠", "ÌïòÍ≤†", "ÌïòÎ¶¨Îùº"],
        "gentle": ["~ÌïòÏßÄ Îßà", "~ÌïòÏßÄ ÎßêÏïÑ", "Î∂ÄÎîî", "Ï†úÎ∞ú"],
        "arrogant": ["Í∞êÌûà", "Ïñ¥Ï∞å", "Í∞ÄÏÜåÎ°≠", "ÎØ∏Î†®Ìïú"],
        "humble": ["Ï£ÑÏÜ°", "Î∂ÄÏ°±", "Î™ªÎÇò", "Í≥†Îßô"]
    }
    
    for emotion, keywords in emotional_keywords.items():
        count = sum(1 for d in dialogues if any(k in d for k in keywords))
        if count > len(dialogues) * 0.2:
            characteristics["emotional_tone"].append(emotion)
    
    # Î∞©Ïñ∏ ÌäπÏßï Î∂ÑÏÑù
    dialect_patterns = {
        "rural": ["~ÏßÄÎùºÏö∞", "~ÎãπÍªò", "~ÏöîÏûâ", "~ÏßÄÎùº", "~ÌïòÏãúÏßÄÎùº"],
        "old_fashioned": ["~ÌïòÎäêÎÉê", "~ÌïòÎ¶¨Îùº", "~Îã®Îã§", "~Íµ¨ÎÇò", "~ÌïòÏòµÎãàÎã§"],
        "modern": ["~Í±∞Îì†", "~ÏûñÏïÑ", "~ÏßÄ Î≠ê", "~ÌïòÏßÄ"]
    }
    
    for dialect, patterns in dialect_patterns.items():
        count = sum(1 for d in dialogues if any(p in d for p in patterns))
        if count > len(dialogues) * 0.2:
            characteristics["dialect_features"].append(dialect)
    
    # Î¨∏Ïû• Í∏∏Ïù¥ Î∂ÑÏÑù
    avg_length = sum(len(d.split()) for d in dialogues) / len(dialogues) if dialogues else 0
    if avg_length < 5:
        characteristics["sentence_length"] = "short"
    elif avg_length < 10:
        characteristics["sentence_length"] = "medium"
    else:
        characteristics["sentence_length"] = "long"
    
    # Î∞òÎ≥µ Ìå®ÌÑ¥ Î∂ÑÏÑù
    for dialogue in dialogues:
        # Î∞òÎ≥µÎêòÎäî Ïñ¥ÎØ∏ÎÇò ÌëúÌòÑ Ï∞æÍ∏∞
        repeated = re.findall(r'(.{2,5})\1+', dialogue)
        if repeated:
            characteristics["repetition_patterns"].extend(repeated)
    
    return characteristics

def update_tone_from_sayings():
    """characters_saying.jsonÏùÑ ÏùΩÏñ¥ÏÑú characters_tone.jsonÏùÑ ÏóÖÎç∞Ïù¥Ìä∏Ìï©ÎãàÎã§."""
    
    # ÌååÏùº ÏùΩÍ∏∞
    with open('characters_saying.json', 'r', encoding='utf-8') as f:
        sayings_data = json.load(f)
    
    with open('characters_tone.json', 'r', encoding='utf-8') as f:
        tone_data = json.load(f)
    
    # Í∞Å Ï∫êÎ¶≠ÌÑ∞Î≥ÑÎ°ú Î∂ÑÏÑù Î∞è ÏóÖÎç∞Ïù¥Ìä∏
    for book_code, characters in sayings_data.items():
        if book_code not in tone_data:
            continue
        
        for char_key, char_data in characters.items():
            if char_key not in tone_data[book_code]:
                continue
            
            dialogues = char_data.get('dialogues', [])
            if not dialogues:
                continue
            
            print(f"\nüìù Î∂ÑÏÑù Ï§ë: {book_code} - {char_key} ({len(dialogues)}Í∞ú ÎåÄÏÇ¨)")
            
            # ÎßêÌà¨ Ìå®ÌÑ¥ Î∂ÑÏÑù
            patterns = analyze_speech_patterns(dialogues)
            characteristics = extract_tone_characteristics(dialogues)
            
            # Í∏∞Ï°¥ Îç∞Ïù¥ÌÑ∞ ÏóÖÎç∞Ïù¥Ìä∏
            char_tone = tone_data[book_code][char_key]
            
            # frequent_expressions ÏóÖÎç∞Ïù¥Ìä∏ (Ïã§Ï†ú ÎåÄÏÇ¨ÏóêÏÑú Ï∂îÏ∂úÌïú Í≤ÉÍ≥º Í∏∞Ï°¥ Í≤É Î≥ëÌï©)
            existing_expressions = char_tone.get('speech_patterns', {}).get('frequent_expressions', [])
            new_expressions = patterns.get('frequent_expressions', [])
            
            # Ï§ëÎ≥µ Ï†úÍ±∞ÌïòÍ≥† Î≥ëÌï©
            merged_expressions = list(dict.fromkeys(existing_expressions + new_expressions))[:30]
            
            # speech_patterns ÏóÖÎç∞Ïù¥Ìä∏
            if 'speech_patterns' not in char_tone:
                char_tone['speech_patterns'] = {}
            
            char_tone['speech_patterns']['frequent_expressions'] = merged_expressions
            char_tone['speech_patterns']['endings'] = patterns.get('endings', [])[:20]
            char_tone['speech_patterns']['sentence_starters'] = patterns.get('sentence_starters', [])[:10]
            
            # tone_characteristicsÏóê Î∂ÑÏÑù Í≤∞Í≥º Ï∂îÍ∞Ä
            if 'tone_characteristics' not in char_tone:
                char_tone['tone_characteristics'] = ""
            
            # Í∏∞Ï°¥ tone_characteristicsÏóê Î∂ÑÏÑùÎêú ÌäπÏßï Ï∂îÍ∞Ä
            existing_tone = char_tone['tone_characteristics']
            
            # Î∂ÑÏÑù Í≤∞Í≥ºÎ•º ÌÖçÏä§Ìä∏Î°ú Ï∂îÍ∞Ä
            analysis_text = f"\n\n[Ïã§Ï†ú ÎåÄÏÇ¨ Î∂ÑÏÑù Í≤∞Í≥º]\n"
            analysis_text += f"- Í≥µÏÜêÎèÑ: {characteristics['politeness_level']}\n"
            analysis_text += f"- Í≤©Ïãù: {characteristics['formality_level']}\n"
            analysis_text += f"- Í∞êÏ†ï ÌÜ§: {', '.join(characteristics['emotional_tone']) if characteristics['emotional_tone'] else 'ÏóÜÏùå'}\n"
            analysis_text += f"- Î∞©Ïñ∏ ÌäπÏßï: {', '.join(characteristics['dialect_features']) if characteristics['dialect_features'] else 'ÏóÜÏùå'}\n"
            analysis_text += f"- Î¨∏Ïû• Í∏∏Ïù¥: {characteristics['sentence_length']}\n"
            
            if characteristics['repetition_patterns']:
                analysis_text += f"- Î∞òÎ≥µ Ìå®ÌÑ¥: {', '.join(set(characteristics['repetition_patterns'][:5]))}\n"
            
            char_tone['tone_characteristics'] = existing_tone + analysis_text
            
            print(f"‚úÖ ÏóÖÎç∞Ïù¥Ìä∏ ÏôÑÎ£å: {char_key}")
            print(f"   - ÏûêÏ£º ÏÇ¨Ïö© ÌëúÌòÑ: {len(merged_expressions)}Í∞ú")
            print(f"   - Ïñ¥ÎØ∏ Ìå®ÌÑ¥: {len(patterns.get('endings', []))}Í∞ú")
            print(f"   - Í∞êÏ†ï ÌÜ§: {', '.join(characteristics['emotional_tone'][:3]) if characteristics['emotional_tone'] else 'ÏóÜÏùå'}")
    
    # ÏóÖÎç∞Ïù¥Ìä∏Îêú Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•
    with open('characters_tone.json', 'w', encoding='utf-8') as f:
        json.dump(tone_data, f, ensure_ascii=False, indent=2)
    
    print("\n‚ú® characters_tone.json ÏóÖÎç∞Ïù¥Ìä∏ ÏôÑÎ£å!")

if __name__ == '__main__':
    update_tone_from_sayings()

